{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import json\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/crawler_util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data folder\n",
    "data_folder = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crawl the data folder and extract text from PDFs\n",
    "pdf_documents = crawl_pdfs_with_content(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'document_name': '1-s2.0-S2001037014000464-main.pdf', 'file_path': '../data\\\\Folder1\\\\1-s2.0-S2001037014000464-main.pdf', 'content': \"Mini Review\\nMachine learning applications in cancer prognosis and prediction\\nKonstantina Kouroua, Themis P. Exarchosa,b, Konstantinos P. Exarchosa,\\nMichalis V. Karamouzisc, Dimitrios I. Fotiadisa,b,⁎\\naUnit of Medical Technology and Intelligent Information Systems, Dept. of Materials Science and Engineering, University of Ioannina, Ioannina, Gre ece\\nbIMBB—FORTH, Dept. of Biomedical Research, Ioannina, Greece\\ncMolecular Oncology Unit, Department of Biological Chemistry, Medical School, University of Athens, Athens, Greece\\nabstract article info\\nAvailable online 15 November 2014\\nKeywords:\\nMachine learningCancer susceptibilityPredictive models\\nCancer recurrence\\nCancer survivalCancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis\\nand prognosis of a cancer type have become a necessity in canc er research, as it can facilitate the subsequent clinical\\nmanagement of patients. The im portance of classifying cancer patients i nto high or low risk groups has led many re-\\nsearch teams, from the biomedical and the bioinformatics ﬁeld, to study the applicatio n of machine learning (ML)\\nmethods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of can-\\ncerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their im-\\nportance. A variety of these techniques, including Arti ﬁcial Neural Networks (ANNs), Bayesian Networks (BNs),\\nSupport Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the de-\\nvelopment of predictive models, resulting in effective and accurate decision making. E ven though it is evident that\\nthe use of ML methods can improve our understanding of can cer progression, an appropriate level of validation is\\nneeded in order for these methods to be considered in the everyday clinical practice. In this work, we present a re-\\nview of recent ML approaches employed in the modeling of c ancer progression. The predictive models discussed\\nhere are based on various supervised ML techniques as well as on different input features and data samples.Given the growing trend on the application of ML methods i n cancer research, we present here the most recent pub-\\nlications that employ these techniques as an aim to model cancer risk or patient outcomes.\\n© 2014 Kourou et al. Published by Elsevier B.V. on behalf of the Research Network of Computational and\\nStructural Biotechnology. This is an open access article under the CC BY license\\n(http://creativecommons.org/licenses/by/3.0/ ).\\nContents\\n1 . I n t r o d u c t i o n............................................................... 9\\n2 . M L t e c h n i q u e s.............................................................. 9\\n3 . M L a n d c a n c e r p r e d i c t i o n / p r o g n o s i s ....................................................1 1\\n4 . S u r v e y o f M L a p p l i c a t i o n s i n c a n c e r ....................................................1 2\\n4 . 1 . P r e d i c t i o n o f c a n c e r s u s c e p t i b i l i t y..................................................1 3\\n4 . 2 . P r e d i c t i o n o f c a n c e r r e c u r r e n c e...................................................1 3\\n4 . 3 . P r e d i c t i o n o f c a n c e r s u r v i v a l ....................................................1 5\\n5 . D i s c u s s i o n................................................................1 56 . C o n c l u s i o n s ...............................................................1 6\\nA c k n o w l e d g e m e n t s ..............................................................1 6\\nR e f e r e n c e s ..................................................................1 6Computational and Structural Biotechnology Journal 13 (2015) 8 –17\\nAbbreviations: ML,MachineLearning;ANN,Arti ﬁcialNeuralNetwork;SVM,SupportVectorMachine;DT,DecisionTree;BN,BayesianNetwork;SSL,Semi-supervisedLearning;TCGA,The\\nCancer Genome Atlas Research Network; HTT, High-throughput Technologies; OSCC, Oral Squamous Cell Carcinoma; CFS, Correlation based Feature Sele ction; AUC, Area Under Curve; ROC,\\nReceiver Operating Characteristic; BCRSVM, Breast Cancer Support Vector Machine; PPI, Protein –Protein Interaction; GEO, Gene Expression Omnibus; LCS, Learning Classifying Systems; ES,\\nEarly Stopping algorithm; SEER, Surveillance, Epidemiology and End results Database; NSCLC, Non-small Cell Lung Cancer; NCI caArray, National Can cer Institute Array Data Management\\nSystem.\\n⁎Corresponding author at: Unit of Medical Technology and Intelligent Information Systems, Dept. of Materials Science and Engineering, University o f Ioannina, Ioannina, Greece.\\nE-mail addresses: konstadina.kourou@googlemail.com (K. Kourou), themis.exarchos@gmail.com (T.P. Exarchos), kexarcho@gmail.com (K.P. Exarchos), mkaramouz@med.uoa.gr\\n(M.V. Karamouzis), fotiadis@cc.uoi.gr (D.I. Fotiadis).\\nhttp://dx.doi.org/10.1016/j.csbj.2014.11.005\\n2001-0370/© 2014 Kourou et al. Published by Elsevier B.V. on behalf of the Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY\\nlicense ( http://creativecommons.org/licenses/by/3.0/ ).\\nContents lists available at ScienceDirect\\njournal homepage: www.elsevier.com/locate/csbj1. Introduction\\nOver the past decades, a continuous evolution related to cancer re-\\nsearch has been performed [1]. Scientists applied different methods,\\nsuch as screening in early stage, in order to ﬁnd types of cancer before\\nthey cause symptoms. Moreover, they have developed new strategies\\nfor the early prediction of cancer treatment outcome. With the adventof new technologies in the ﬁeld of medicine, large amounts of cancer\\ndata have been collected and are available to the medical research\\ncommunity. However, the accurate prediction of a disease outcome is\\none of the most interesting and challenging tasks for physicians. As a re-\\nsult, ML methods have become a popular tool for medical researchers.\\nThese techniques can discover and identify patterns and relationships\\nbetween them, from complex datasets, while they are able to effectively\\npredict future outcomes of a cancer type.\\nGiven the signi ﬁcance of personalized medicine and the growing\\ntrend on the application of ML techniques, we here present a review\\nof studies that make use of these methods regarding the cancer predic-\\ntion and prognosis. In these studies prognostic and predictive features\\nare considered which may be independent of a certain treatment or\\nare integrated in order to guide therapy for cancer patients, respectively\\n[2]. In addition, we discuss the types of ML methods being used, the\\ntypes of data they integrate, the overall performance of each proposed\\nscheme while we also discuss their pros and cons.\\nAn obvious trend in the proposed works includes the integration of\\nmixed data, such as clinical and genomic. However, a common problem\\nthat we noticed in several works is the lack of external validation or\\ntesting regarding the predictive performance of their models. It is clear\\nthat the application of ML methods could improve the accuracy of cancer\\nsusceptibility, recurrence and survival prediction. Based on [3], the\\naccuracy of cancer prediction outcome has signi ﬁcantly improved by\\n15%–20% the last years, with the application of ML techniques.\\nSeveral studies have been reported in the literature and are based on\\ndifferent strategies that could enable the early cancer diagnosis and\\nprognosis [4–7].S p e c i ﬁcally, these studies describe approaches related\\nto the pro ﬁling of circulating miRNAs that have been proven a promis-\\ning class for cancer detection and identi ﬁcation. However, these\\nmethods suffer from low sensitivity regarding their use in screening at\\nearly stages and their dif ﬁculty to discriminate benign from malignant\\ntumors. Various aspects regarding the prediction of cancer outcomebased on gene expression signatures are discussed in [8,9] .T h e s e\\nstudies list the potential as well as the limitations of microarrays for\\nthe prediction of cancer outcome. Even though gene signatures could\\nsigniﬁcantly improve our ability for prognosis in cancer patients, poor\\nprogress has been made for their application in the clinics. However,\\nbefore gene expression pro ﬁling can be used in clinical practice, studies\\nwith larger data samples and more adequate validation are needed.\\nIn the present work only studies that employed ML techniques for\\nmodeling cancer diagnosis and prognosis are presented.\\n2. ML techniques\\nML, a branch of Arti ﬁcial Intelligence, relates the problem of learning\\nfrom data samples to the general concept of inference [10–12]. Every\\nlearning process consists of two phases: (i) estimation of unknown de-\\npendencies in a system from a given dataset and (ii) use of estimated\\ndependencies to predict new outputs of the system. ML has also been\\nproven an interesting area in biomedical research with many applica-\\ntions, where an acceptable generalization is obtained by searching\\nthrough an n-dimensional space for a given set of biological samples,\\nusing different techniques and algorithms [13].T h e r ea r et w om a i n\\ncommon types of ML methods known as (i) supervised learning and\\n(ii) unsupervised learning. In supervised learning a labeled set of train-\\ning data is used to estimate or map the input data to the desired output.\\nIn contrast, under the unsupervised learning methods no labeled exam-\\nples are provided and there is no notion of the output during thelearning process. As a result, it is up to the learning scheme/model to\\nﬁnd patterns or discover the groups of the input data. In supervised\\nlearning this procedure can be thought as a classi ﬁcation problem. The\\ntask of classi ﬁcation refers to a learning process that categorizes the\\ndata into a set of ﬁnite classes. Two other common ML tasks are regres-\\nsion and clustering. In the case of regression problems, a learning\\nfunction maps the data into a real-value variable. Subsequently, foreach new sample the value of a predictive variable can be estimated,\\nbased on this process. Clustering is a common unsupervised task in\\nwhich one tries to ﬁnd the categories or clusters in order to describe\\nthe data items. Based on this process each new sample can be assigned\\nto one of the identi ﬁed clusters concerning the similar characteristics\\nthat they share.\\nSuppose for example that we have collected medical records\\nrelevant to breast cancer and we try to predict if a tumor is malignant\\nor benign based on its size. The ML question would be referred to the es-\\ntimation of the probability that the tumor is malignant or no (1 = Yes,\\n0=N o ) . Fig. 1 depicts the classi ﬁcation process of a tumor being malig-\\nnant or not. The circled records depict any misclassi ﬁcation of the type\\nof a tumor produced by the procedure.\\nAnother type of ML methods that have been widely applied is\\nsemi-supervised learning, which is a combination of supervised and\\nunsupervised learning. It combines labeled and unlabeled data in\\norder to construct an accurate learning model. Usually, this type of\\nlearning is used when there are more unlabeled datasets than labeled.\\nWhen applying a ML method, data samples constitute the basic\\ncomponents. Every sample is described with several features and\\nevery feature consists of different types of values. Furthermore, know-\\ning in advance the speci ﬁc type of data being used allows the right selec-\\ntion of tools and techniques that can be used for their analysis. Some\\ndata-related issues refer to the quality of the data and the preprocessing\\nsteps to make them more suitable for ML. Data quality issues include the\\npresence of noise, outliers, missing or duplicate data and data that is\\nbiased-unrepresentative. When improving the data quality, typically\\nthe quality of the resulting analysis is also improved. In addition, in\\norder to make the raw data more suitable for further analysis, prepro-\\ncessing steps should be applied that focus on the modi ﬁcation of the\\ndata. A number of different techniques and strategies exist, relevant to\\ndata preprocessing that focus on modifying the data for better ﬁtting\\nin a speci ﬁc ML method. Among these techniques some of the most im-\\nportant approaches include (i) dimensionality reduction (ii) feature se-\\nlection and (iii) feature extraction. There are many bene ﬁts regarding\\nthe dimensionality reduction when the datasets have a large number\\nof features. ML algorithms work better when the dimensionality is\\nlower [14]. Additionally, the reduction of dimensionality can eliminate\\nirrelevant features, reduce noise and can produce more robust learning\\nmodels due to the involvement of fewer features. In general, the dimen-\\nsionality reduction by selecting new features which are a subset of the\\nold ones is known as feature selection. Three main approaches exist\\nfor feature selection namely embedded, ﬁlter and wrapper approaches\\n[14]. In the case of feature extraction, a new set of features can be\\nFig. 1. Classi ﬁcation task in supervised learning. Tumors are represented as X and classi ﬁed\\nas benign or malignant. The circled examples depict those tumors that have beenmisclassi ﬁed.9 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17created from the initial set that captures all the signi ﬁcant information\\nin a dataset. The creation of new sets of features allows for gathering\\nthe described bene ﬁts of dimensionality reduction.\\nHowever, the application of feature selection techniques may result\\nin speci ﬁcﬂuctuations concerning the creation of predictive feature\\nlists. Several studies in the literature discuss the phenomenon of lack\\nof agreement between the predictive gene lists discovered by differentgroups, the need of thousands of samples in order to achieve the desired\\noutcomes, the lack of biological interpretation of predictive signatures\\nand the dangers of information leak recorded in published studies\\n[15–18].\\nThe main objective of ML techniques is to produce a model which\\ncan be used to perform classi ﬁcation, prediction, estimation or any\\nother similar task. The most common task in learning process is classi ﬁ-\\ncation. As mentioned previously, this learning function classi ﬁes the\\ndata item into one of several prede ﬁned classes. When a classi ﬁcation\\nmodel is developed, by means of ML techniques, training and generali-\\nzation errors can be produced. The former refers to misclassi ﬁcation\\nerrors on the training data while the latter on the expected errors on\\ntesting data. A good classi ﬁcation model should ﬁt the training set\\nwell and accurately classify all the instances. If the test error rates of a\\nmodel begin to increase even though the training error rates decrease\\nthen the phenomenon of model over ﬁtting occurs. This situation is\\nrelated to model complexity meaning that the training errors of a\\nmodel can be reduced if the model complexity increases. Obviously,\\nthe ideal complexity of a model not susceptible to over ﬁtting is the\\none that produces the lowest generalization error. A formal method\\nfor analyzing the expected generalization error of a learning algorithm\\nis the bias –variance decomposition. The bias component of a particular\\nlearning algorithm measures the error rate of that algorithm. Addition-\\nally, a second source of error over all possible training sets of given size\\nand all possible test sets is called variance of the learning method. The\\noverall expected error of a classi ﬁcation model is constituted of the\\nsum of bias and variance, namely the bias –variance decomposition.\\nOnce a classi ﬁcation model is obtained using one or more ML tech-\\nniques, it is important to estimate the classi ﬁer's performance. The per-\\nformance analysis of each proposed model is measured in terms of\\nsensitivity, speci ﬁcity, accuracy and area under the curve (AUC).\\nSensitivity is de ﬁned as the proportion of true positives that are correct-\\nly observed by the classi ﬁer, whereas speci ﬁcity is given by the propor-\\ntion of true negatives that are correctly identi ﬁed. The quantitative\\nmetrics of accuracy and AUC are used for assessing the overallperformance of a classi ﬁer. Speci ﬁcally, accuracy is a measure related\\nto the total number of correct predictions. On the contrary, AUC is a\\nmeasure of the model's performance which is based on the ROC curve\\nthat plots the tradeoffs between sensitivity and 1-speci ﬁ\\ncity ( Fig. 2 ).\\nThe predictive accuracy of the model is computed from the testing\\nset which provides an estimation of the generalization errors. In order\\nto obtain reliable results regarding the predicting performance of amodel, training and testing samples should be suf ﬁciently large and in-\\ndependent while the labels of the testing sets should be known. Among\\nthe most commonly used methods for evaluating the performance of\\na classi ﬁer by splitting the initial labeled data into subsets are:\\n(i) Holdout Method, (ii) Random Sampling, (iii) Cross-Validation and\\n(iv) Bootstrap. In the Holdout method, the data samples are partitioned\\ninto two separate sets, namely the training and the test sets. A classi ﬁca-\\ntion model is then generated from the training set while its performance\\nis estimated on the test set. Random sampling is a similar approach to\\nthe Holdout method. In this case, in order to better estimate the accura-\\ncy, the Holdout method is repeated several times, choosing the training\\nand test instances randomly. In the third approach, namely cross-\\nvalidation, each sample is used the same number of times for training\\nand only once for testing. As a result, the original data set is covered\\nsuccessfully both in the training and in the test set. The accuracy results\\nare calculated as the average of all different validation cycles. In the last\\napproach, bootstrap, the samples are separated with replacement into\\ntraining and test sets, i.e. they are placed again into the entire data set\\nafter they have been chosen for training.\\nWhen the data are preprocessed and we have de ﬁned the kind of\\nlearning task, a list of ML methods including (i) ANNs, (ii) DTs,\\n(iii) SVMs and (iv) BNs is available. Based on the intension of this review\\npaper, we will refer only to these ML techniques that have been applied\\nwidely in the literature for the case study of cancer prediction and prog-\\nnosis. We identify the trends regarding the types of ML methods that are\\nused, the types of data that are integrated as well as the evaluation\\nmethods employed for assessing the overall performance of the\\nmethods used for cancer prediction or disease outcomes.\\nANNs handle a variety of classi ﬁcation or pattern recognition prob-\\nlems. They are trained to generate an output as a combination between\\nthe input variables. Multiple hidden layers that represent the neural\\nconnections mathematically are typically used for this process. Even\\nthough ANNs serve as a gold standard method in several classi ﬁcation\\ntasks [19] they suffer from certain drawbacks. Their generic layered\\nstructure proves to be time-consuming while it can lead to very poor\\nFig. 2. An indicative ROC curve of two classi ﬁers: (a) Random Guess classi ﬁer (red curve) and (b) A classi ﬁer providing more robust predictions (blue dotted curve).10 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17performance. Additionally, this speci ﬁc technique is characterized as a\\n“black-box ”technology. Trying to ﬁnd out how it performs the classi ﬁ-\\ncation process or why an ANN did not work is almost impossible to de-\\ntect. Fig. 3 depicts the structure of an ANN with its interconnected group\\nof nodes.\\nDTs follow a tree-structured classi ﬁcation scheme where the nodes\\nrepresent the input variables and the leaves correspond to decision out-\\ncomes. DTs are one of the earliest and most prominent ML methods that\\nhave been widely applied for classi ﬁcation purposes. Based on the archi-\\ntecture of the DTs, they are simple to interpret and “quick ”to learn.\\nWhen traversing the tree for the classi ﬁcation of a new sample we are\\nable to conjecture about its class. The decisions resulted from their\\nspeciﬁc architecture allow for adequate reasoning which makes them\\nan appealing technique. Fig. 4 depicts an illustration of a DT with its\\nelements and rules.\\nSVMs are a more recent approach of ML methods applied in the ﬁeld\\nof cancer prediction/prognosis. Initially SVMs map the input vector into\\na feature space of higher dimensionality and identify the hyperplane\\nthat separates the data points into two classes. The marginal distance\\nbetween the decision hyperplane and the instances that are closest to\\nboundary is maximized. The resulting classi ﬁer achieves considerable\\ngeneralizability and can therefore be used for the reliable classi ﬁcationof new samples. It is worth noting that probabilistic outputs can also\\nbe obtained for SVMs [20].Fig. 5 illustrates how an SVM might work\\nin order to classify tumors among benign and malignant based on\\ntheir size and patients' age. The identi ﬁed hyperplane can be thought\\nas a decision boundary between the two clusters. Obviously, the exis-\\ntence of a decision boundary allows for the detection of any misclassi ﬁ-\\ncation produced by the method.\\nBN classi ﬁers produce probability estimations rather than predic-\\ntions. As their name reveals, they are used to represent knowledge\\ncoupled with probabilistic dependencies among the variables of interest\\nvia a directed acyclic graph. BNs have been applied widely to several\\nclassi ﬁcation tasks as well as for knowledge representation and reason-\\ning purposes.\\nFig. 6 depicts an illustration of a BN across with the calculated condi-\\ntional probability for each variable.\\n3. ML and cancer prediction/prognosis\\nThe last two decades a variety of different ML techniques and feature\\nselection algorithms have been widely applied to disease prognosis and\\nprediction [3,22 –27]. Most of these works employ ML methods for\\nmodeling the progression of cancer and identify informative factors\\nthat are utilized afterwards in a classi ﬁcation scheme. Furthermore, in\\nalmost all the studies gene expression pro ﬁles, clinical variables as\\nwell as histological parameters are encompassed in a complementary\\nmanner in order to be fed as input to the prognostic procedure. Fig. 7\\ndepicts the distribution in published papers using ML techniques to\\npredict (i) cancer susceptibility, (ii) recurrence and (iii) survival. The in-\\nformation was collected based on a variety of query searches in theScopus biomedical database. More speci ﬁcally, queries like “cancer\\nrisk assessment ”AND “Machine Learning ”,“cancer recurrence ”AND\\n“Machine Learning ”,“cancer survival ”AND “Machine Learning ”as\\nwell as “cancer prediction ”AND “Machine Learning ”yielded the num-\\nber of papers that are depicted in Fig. 3 . No limitations were imposed\\nin the resulted hits except the exclusion of articles published before\\n2010. As mentioned above, the number of papers presented in Fig. 7\\nrefers to the exact numbers yielded from the databases without any\\nreﬁnement except the date that they were published.\\nThe success of a disease prognosis is undoubtedly dependent on the\\nquality of a medical diagnosis; however, a prognostic prediction should\\ntake into account more than a simple diagnostic decision. When dealing\\nwith cancer prognosis/prediction one is concerned with three predic-\\ntive tasks: (i) the prediction of cancer susceptibility (risk assessment),\\n(ii) the prediction of cancer recurrence/local control and (iii) the predic-\\ntion of cancer survival. In the ﬁrst two cases one is trying to ﬁnd (i) the\\nlikelihood of developing a type of cancer and (ii) the likelihood of\\nredeveloping a type of cancer after complete or partial remission. In\\nthe last case, the prediction of a survival outcome such as disease-\\nspeci ﬁc or overall survival after cancer diagnosis or treatment is the\\nmain objective. The prediction of cancer outcome usually refers to the\\ncases of (i) life expectancy, (ii) survivability, (iii) progression and\\n(iv) treatment sensitivity [3].Fig. 3. An illustration of the ANN structure. The arrows connect the output of one node to\\nthe input of another.\\nFig. 4. An illustration of a DT showing the tree structure. Each variable (X, Y, Z) is repre-\\nsented by a circle and the decision outcomes by squares (Class A, Class B). T(1 –3) repre-\\nsents the thresholds (classi ﬁcation rules) in order to successfully classify each variable\\nto a class label.\\nFig. 5. A simpli ﬁed illustration of a linear SVM classi ﬁcation of the input data. Figure was\\nreproduced from the ML lectures of [21]. Tumors are classi ﬁed according to their size\\nand the patient's age. The depicted arrows display the misclassi ﬁed tumors.11 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17Major types of ML techniques including ANNs and DTs have been\\nused for nearly three decades in cancer detection [22,28 –30]. According\\nto the recent PubMed results regarding the subject of ML and cancer\\nmore than 7510 articles have been published until today. The vast ma-\\njority of these publications makes use of one or more ML algorithms\\nand integrates data from heterogeneous sources for the detection of\\ntumors as well as for the prediction/prognosis of a cancer type. A grow-\\ning trend is noted the last decade in the use of other supervised learning\\ntechniques, namely SVMs and BNs, towards cancer prediction and prog-\\nnosis [24,31 –36].A l lo ft h e s ec l a s s i ﬁcation algorithms have been widely\\nused in a wide range of problems posed in cancer research.\\nIn the past, the typical information used by the physicians conclude\\nwith a reasonable decision regarding cancer prognosis and included his-\\ntological, clinical and population-based data [23,37] . The integration of\\nfeatures such as family history, age, diet, weight, high-risk habits and\\nexposure to environmental carcinogens play a critical role in predicting\\nthe development of cancer [38–40]. Even though this type of macro-\\nscale information referred to a small number of variables so that stan-dard statistical methods could be used for prediction purposes, however\\nthese types of parameters do not provide suf ﬁcient information for\\nmaking robust decisions. With the rapid advent of genomic, proteomic\\nand imaging technologies a new kind of molecular information can be\\nobtained. Molecular biomarkers, cellular parameters as well as the ex-\\npression of certain genes have been proven as very informative indica-\\ntors for cancer prediction. The presence of such High ThroughputTechnologies (HTTs) nowadays has produced huge amounts of cancer\\ndata that are collected and are available to the medical research com-\\nmunity. However, the accurate prediction of a disease outcome is one\\nof the most interesting and challenging tasks for physicians. As a result,\\nML methods have become a popular tool for medical researchers. These\\ntechniques can discover and identify patterns and relationships be-\\ntween them, from complex datasets, while they are able to effectively\\npredict future outcomes of a cancer type. Additionally, feature selection\\nmethods have been published in the literature with their application in\\ncancer [41–43]. The proposed computational tools aim at identifying\\ninformative features for accurately identi ﬁcation of disease class.\\nThere are nowadays separate subgroups among the same type of\\ncancer based on speci ﬁc genetic defects that have different treatment\\napproaches and options as well as different clinical outcomes. This is\\nthe foundation of the individualized treatment approach, in which com-\\nputational techniques could help by identifying less costly and effectively\\nsuch small groups of patients. Furth ermore, the development of a com-\\nmunity resource project, namely The Cancer Genome Atlas ResearchNetwork (TCGA) has the potential support for personal medicine as it\\nprovides large scale genomic data about speci ﬁc tumor types. TCGA pro-\\nvides with the ability to better understand the molecular basis of cancer\\nthrough the application of high-throughput genome technologies.\\n4. Survey of ML applications in cancer\\nAn extensive search was conducted relevant to the use of ML tech-\\nniques in cancer susceptibility, recurrence and survivability prediction.\\nTwo electronic databases were accessed namely PubMed, Scopus. Due\\nto the vast number of articles returned by the search queries, further\\nscrutinization was needed in order to maintain the most relevant arti-\\ncles. The relevance of each publication was assessed based on the key-\\nwords of the three predictive tasks found in their titles and abstracts.\\nSpeci ﬁcally, after reading their titles and abstracts we only selected\\nthose publications that study one of the three foci of cancer prediction\\nand included it in their titles. The majority of these studies use different\\ntypes of input data: genomic, clinical, histological, imaging, demograph-\\nic, epidemiological data or combination of these. Papers that focus on\\nthe prediction of cancer development by means of conventional statisti-\\ncal methods (e.g. chi-square, Cox regression) were excluded as were pa-\\npers that use techniques for tumor classi ﬁcation or identi ﬁcation of\\npredictive factors. According to [3]and their survey based on ML appli-\\ncations in cancer prediction, we noted a rapid increase in papers\\nthat have been published in the last decade. Although it is impossible\\nto achieve a complete coverage of the literature, we believe that a\\nFig. 6. An illustration of a BN. Nodes (A –D) represent a set of random variables across with their conditional probabilities which are calculated in each table.\\nFig. 7. Distribution of published studies, within the last 5 years, that employ ML techniques\\nfor cancer prediction.12 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17signiﬁcant number of relevant papers were extracted and are presented\\nin this review. As mentioned above, from the initial group of papers we\\nselected a representative list that follows a well-organized structure.\\nSpeci ﬁcally, we selected these studies that make use of recognizable\\nML techniques and integrated data from heterogeneous sources in\\norder to predict the desirable outcome. We focused mainly on studies\\nthat have been published the last 5 years as an aim to present themost recent state of the art in the ﬁeld and their advances in comparison\\nto older publications. Tables 1a, 1b, and 1c depict some of the publica-\\ntions presented in this review. Cancer type, ML method, number of\\npatients, type of data as well as the overall accuracy achieved by each\\nproposed method are presented. Each sub-table corresponds to studies\\nregarding a speci ﬁc scenario (i.e. cancer susceptibility prediction, cancer\\nrecurrence prediction and cancer survival prediction). It should be\\nnoted that in articles that more than one ML techniques are applied\\nfor prediction, we decided to present here the most accurate predictive\\nmodel.\\nA detailed analysis of more recent studies revealed that there is a\\ngrowing trend in risk assessment as well as the prediction of recurrence\\nof a cancer type regardless the ML technique used. Many research\\ngroups have tried to predict the possibility of redeveloping cancer\\nafter remission and appeared to improve the accuracy of predictions\\ncompared to alternative statistical techniques. Moreover, the vast\\nmajority of these publications used molecular and clinical data in\\norder to make their predictions. The use of such measurable features\\nas input data is a growing trend based on the advent of HTTs.\\nIn the following, we are going to discuss one case for each of the ob-\\njectives of predicting (i) susceptibility, (ii) recurrence and (iii) survival,\\nall by means of ML techniques. Each sub-section summarizes the repre-\\nsentative studies we have selected based on their predictive outcomes.\\nWe only selected those publications that have been accepted the last 5\\nyears and make use of distinguishable ML methods. We provide the\\nreaders with the appropriate details of the most recent techniques\\nused for the prediction and prognosis of most frequent cancer types.\\n4.1. Prediction of cancer susceptibility\\nWe performed a Scopus and a PubMed advanced search which was\\nlimited to the last 5 years. Out of these results one of the publications\\nemploys ML techniques for the prediction of susceptibility in a cancer\\ntype [55]. The authors perform a genetic epidemiology study of bladder\\ncancer susceptibility in terms of Learning Classifying Systems (LCSs).\\nWe decided to exclude this work from the present case study as it\\ndeals with genetic information and examines further genetic problems.\\nBased on these limitations we continued our search to the speci ﬁcb i o -\\nmedical databases. Most of these titles neither referred to the speci ﬁed\\nkeywords that are mentioned in the relevant survey nor used ML\\ntechniques for their predictions. Among the most recent publications\\nthat resulted after our limited literature search regarding the cancer\\nrisk assessment prediction [19,56 –58], we selected a recent and very in-\\nteresting study to present relevant to the breast cancer risk estimation\\nby means of ANNs [19]. It is a different study among the others present-\\ned in this review article regarding the data type used. Although all of thepublications selected make use of molecular, clinical or population-\\nbased data, this work encompasses mammographic ﬁndings and demo-\\ngraphic characteristics to the model. Even though this work doesn't ﬁt\\nour general statement regarding our search criteria, we decided to\\ninclude it in this case study because no other search result met our\\nneeds. We excluded this work from our general statement because no\\nother search result met our needs. The major intense in developingdecision-making tools that can discriminate among benign and malig-\\nnant ﬁndings in breast cancer is commented by the authors. They also\\nmention that when developing prediction models, risk strati ﬁcation is\\nof major interest. According to their knowledge, existing studies\\nbased on the use of computer models, have also utilized speci ﬁcM L\\ntechniques, such as ANNs, in order to assess the risk of breast cancer pa-\\ntients. In their work, ANNs are employed in order to develop a predic-\\ntion model that could classify malignant mammographic ﬁndings from\\nbenign. They built their model with a large number of hidden layers\\nwhich generalizes better than networks with small number of hidden\\nnodes. Regarding the collected data in this study, 48.774 mammograph-\\nicﬁndings as well as demographic risks factors and tumor characteris-\\ntics were considered. All of the mammographic records were\\nreviewed by radiologists and the reading information was obtained.\\nThis dataset was then fed as input to the ANN model. Its performance\\nwas estimated by means of ten-fold cross validation. Additionally, in\\norder to prevent the case of over ﬁtting the authors used the ES ap-\\nproach. This procedure, generally, controls the network error during\\ntraining and stops it if over ﬁtting occurs. The calculated AUC of their\\nmodel was 0.965 following training and testing by means of ten-fold\\ncross validation. The authors claimed that their model can accurately\\nestimate the risk assessment of breast cancer patients by integrating a\\nlarge data sample. They also declared that their model is unique\\namong others if we consider that the most important factors they\\nused to train the ANN model are the mammography ﬁndings with\\ntumor registry outcomes. One very interesting characteristic in this\\nstudy is the calculation of two main components of accuracy, namely\\ndiscrimination and calibration. Discrimination is a metric that someone\\ncalculates in order to separate benign abnormalities from malignant\\nones, while calibration is a measurement used when a risk prediction\\nmodel aims to stratify patients into high or low risk categories. The\\nauthors plotted (i) a ROC curve in order to evaluate the discriminative\\nability of their model and (ii) a calibration curve for comparing after-wards their model's calibration to the perfect calibration of predicting\\nbreast cancer risk. Apart from these ﬁndings, the authors also noted\\nthat the use of a mix of screening and diagnostic datasets cannot be\\nreliably separated when feeding as input to the ANN. So, in order to\\novercome such limitations the authors should consider the purpose of\\npreprocessing steps for transforming the raw data into appropriate for-\\nmats for subsequent analysis.\\n4.2. Prediction of cancer recurrence\\nBased on our survey, we here present the most relevant and recent\\npublications that proposed the use of ML techniques for cancer recur-\\nrence prediction. A work which studies the recurrence prediction of\\nTable 1a\\nPublications relevant to ML methods used for cancer susceptibility prediction.\\nPublication Method Cancer type No of\\npatientsType of data Accuracy Validation method Important features\\nAyer T et al. [19] ANN Breast cancer 62,219 Mammographic,\\ndemographicAUC = 0.965 10-fold cross validation Age, mammography ﬁndings\\nWaddell M et al. [44] SVM Multiple myeloma 80 SNPs 71% Leave-one-out cross\\nvalidationsnp739514, snp521522, snp994532\\nListgarten J et al. [45] SVM Breast cancer 174 SNPs 69% 20-fold cross validation snpCY11B2 (+) 4536 T/C snpCYP1B1\\n(+) 4328 C/G\\nStajadinovic et al. [46] BN Colon carcinomatosis 53 Clinical, pathologic AUC = 0.71 Cross-validation Primary tumor histology, nodal staging,\\nextent of peritoneal cancer13 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17oral squamous cell carcinoma (OSCC) is proposed in [24]. They sug-\\ngested a multiparametric Decision Support System in order to analyze\\nthe basis of OSCC evolvement after total remission of cancer patients.\\nThey exploited heterogeneous sources of data (clinical, imaging and\\ngenomic) in order to predict a possible relapse of OSCC and thus a\\nsubsequent recurrence. A total number of 86 patients were considered\\nin this study, 13 of which have been identi ﬁed with a relapse while\\nthe remaining was disease free. A speci ﬁc feature selection procedure\\nwas followed with the employment of two feature selection algorithms,\\nnamely CFS [59]and wrapper algorithm [60]. As a result, any bias could\\nbe avoided when selecting the most informative features of their refer-\\nence heterogeneous dataset. Then the selected important variables\\ncould be used as input vectors to speci ﬁcc l a s s i ﬁers. Before the employ-\\nment of the feature selection techniques the total number of the clinical,\\nimaging and genomic features was 65, 17 and 40 in each category. Sub-\\nsequently, after the employment of the CFS algorithm the total number\\nof clinical, imaging and genomic data used in each classi ﬁer was 8, 6 and\\n7, respectively. More speci ﬁcally, among the clinical variables the most\\ninformative ones, for each classi ﬁcation algorithm, were the smoker,\\ntumor thickness and p53 stain. Concerning the imaging and the geno-\\nmic features, after the utilization of the CFS algorithm, the most impor-\\ntant were the extra-tumor spreading, the number of lymph nodes and\\nthe SOD2, TCAM and OXCT2 genes.\\nThe basic idea in this study is summarized in the discrimination of\\npatients into those with a disease relapse and those without after the\\nperformance of ﬁve classi ﬁcation algorithms. The employed algorithms\\ninclude the BNs, ANNs, SVMs, DTs and RF classi ﬁers. After the perfor-\\nmance of each ML method an evaluation technique, namely ten-foldcross-validation, was employed for evaluation purposes. Additionally,\\naccuracy, sensitivity and speci ﬁcity were also calculated for comparison\\nreasons among the employed classi ﬁcation schemes. The analysis of\\nROC curve was considered by the authors for evaluation purposes as\\nwell. Their predictive results regarding the classi ﬁcation schemes\\nemployed were obtained based on the classi ﬁcation of data without\\nperforming feature selection and on the classi ﬁcation of data after\\nemploying a feature selection algorithm. Regarding their outputs the\\nauthors claimed that the BN classi ﬁer without applying any featureselection scheme performed better in the discrimination with directly\\ninput of the clinical and imaging features (78.6% and 82.8% accuracy, re-\\nspectively). In a similar manner, genomic-based classi ﬁcation results re-\\nvealed that the best performing classi ﬁer was the BN in conjunction\\nwith the CFS algorithm (91.7% accuracy). In the ﬁnal stage of their\\nstudy, the authors combined the more accurate individual predictors\\n(i.e. BN and BN coupled with the CFS) in order to yield a consensus de-\\ncision for discrimination between patients with and without an OSCC\\nrelapse. A comparison of this approach to other studies in the literature\\nrevealed that this proposal yields robust results than other methodolo-\\ngies. The proposed study illustrated in an explanatory way how the in-\\ntegration of heterogeneous sources of data, by means of ML classi ﬁers,\\ncan produce accurate results regarding the prediction of cancer recur-\\nrence. Furthermore, the authors used more than one classi ﬁcation tech-\\nnique in order to obtain robust results. It is clear that when you estimate\\nthe performance of a classi ﬁ\\ner predictor among others, then you are\\nable to ﬁnd the most optimal tool. However, we should highlight an\\nimportant aspect of this work regarding the small sample size. Only\\n86 patients were considered with their clinical, imaging and genomic\\nfeatures. Although their classi ﬁcation results were very promising, we\\nshould consider that a relatively small sample size compared to data\\ndimensionality can lead to misclassi ﬁcation and biased predictors. An-\\nother interesting article published in the same year with [24]proposed\\nan SVM-based model for the prediction of breast cancer recurrence,\\ncalled BCRSVM [47]. The authors support the idea that the classi ﬁcation\\nof cancer patients into high-risk or low-risk groups allows experts to ad-\\njust a better treatment and follow-up planning. Their study is based on\\nthe development of a predictive model regarding the breast cancerrecurrence within ﬁve years after surgery. SVM, ANN as well as\\nCox-proportional hazard regression were employed for producing the\\nmodels and ﬁnd the optimal one. The authors claimed that after\\ncomparing the three models based on their resulted accuracies, they\\nfound that the BCRSVM model outperformed the other two. From the\\ninitial set of 193 available variables in their dataset, only 14 features\\nwere selected based on their clinical knowledge. These data refer to\\nclinical, epidemiological and pathological variables of 733 patients con-\\nsidered out of 1.541. In the ﬁnal stage of the feature selection, Kaplan –Table 1b\\nPublications relevant to ML methods used for cancer recurrence prediction.\\nPublication ML method Cancer type No of patients Type of data Accuracy Validation method Important features\\nExarchos K et al. [24] BN Oral cancer 86 Clinical, imaging tissue genomic,\\nblood genomic100% 10-fold cross validation Smoker, p53 stain, extra-tumor\\nspreading, TCAM, SOD2\\nKim W et al. [47] SVM Breast cancer 679 Clinical, pathologic, epidemiologic 89% Hold-out Local invasion of tumor\\nPark C et al. [48] Graph-based SSL\\nalgorithmColon cancer,\\nbreast cancer437\\n374Gene expression, PPIs 76.7%\\n80.7%10-fold cross validation BRCA1, CCND1, STAT1, CCNB1\\nTseng C-J et al. [49] SVM Cervical cancer 168 Clinical, pathologic 68% Hold-out pathologic_S, pathologic_T, cell\\ntype RT target summary\\nEshlaghy A et al. [34] SVM Breast cancer 547 Clinical, population 95% 10-fold cross validation Age at diagnosis, age at menarche\\nTable 1c\\nPublications relevant to ML methods used for cancer survival prediction.\\nPublication ML method Cancer type No of patients Type of data Accuracy Validation method Important features\\nChen Y-C et al. [50] ANN Lung cancer 440 Clinical, gene expression 83.5% Cross validation Sex, age, T_stage, N_stage\\nLCK and ERBB2 genes\\nPark K et al. [26] Graph-based SSL\\nalgorithmBreast cancer 162,500 SEER 71% 5-fold cross validation Tumor size, age at diagnosis,\\nnumber of nodes\\nChang S-W et al. [32] SVM Oral cancer 31 Clinical, genomic 75% Cross validation Drink, invasion, p63 gene\\nXu X et al. [51] SVM Breast cancer 295 Genomic 97% Leave-one-out cross\\nvalidation50-gene signature\\nGevaert O et al. [52] BN Breast cancer 97 Clinical, microarray AUC = 0.851 Hold-Out Age, angioinvasion, grade\\nMMP9, HRASLA and RAB27B genes\\nRosado P et al. [53] SVM Oral cancer 69 Clinical, molecular 98% Cross validation TNM_stage, number of recurrences\\nDelen D et al. [54] DT Breast cancer 200,000 SEER 93% Cross validation Age at diagnosis, tumor size,\\nnumber of nodes, histology\\nKim J et al. [36] SSL Co-training\\nalgorithmBreast cancer 162,500 SEER 76% 5-fold cross validation Age at diagnosis, tumor size,\\nnumber of nodes, extension of tumor14 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17Meier analysis and Cox regression were applied which resulted in 7\\nvariables as most informative. These features were then entered as\\ninput to the SVM and ANN classi ﬁers as well as to the Cox regression sta-\\ntistical model. In order to evaluate the performance of the models, the\\nauthors employed the hold-out method, which splits the data sample\\ninto two sub-sets, namely training and testing set. As in most studies\\nin the literature, accuracy, sensitivity and speci ﬁcity were calculated\\nfor a reliable estimation of the models. Based on these metrics, the au-\\nthors claimed that BCRSVM outperformed the ANN and Cox regression\\nmodels with accuracy 84.6%, 81.4% and 72.6%, respectively. Comparison\\namong the performance of other previously established recurrence pre-\\ndiction models revealed that BCRSVM has superior performance. It\\nshould be noted that this study estimated also the importance of prog-\\nnostic factors by means of normalized mutual information index (NMI)\\n[61]. Based on these calculations for each of the three predictive models,\\nthey suggest that the most signi ﬁcant factor regarding the prediction of\\nbreast cancer recurrence was the local invasion of tumor. However, if\\nsomeone reviews this work would certainly mention some major limi-\\ntations. As the authors noted, the exclusion of a large number of patients\\n(n = 808) due to the lack of clinical data in the research registry, in ﬂu-\\nenced the performance of their models. Furthermore, the fact that the\\nauthors used only their clinical knowledge to select 14 out of 193 vari-\\nables may have resulted in signi ﬁcant bias, thus giving no robust results.\\nApart from this limitation, the authors could also improve the perfor-\\nmance of their proposed model, namely BCRSVM, by validating it with\\nexternal datasets from other sources. Among the initial list of publica-\\ntions resulted from our literature survey, we noticed a growing trend\\nthe last years regarding the prediction of cancer disease by means of\\nSSL learning. So, we believed it would be of interest to present the\\nmost recent study that makes use of this type of ML techniques for the\\nanalysis of breast cancer recurrence [48]. The proposed algorithm is\\nbased on the use of SSL for the construction of a graph model while it\\nintegrates gene expression data with gene network information in\\norder to predict cancer recurrence. Based on biological knowledge, the\\nauthors selected gene pairs that indicate strong biological interactions.\\nThe sub-gene network identi ﬁed by the proposed method is constituted\\nof the BRCA1, CCND1, STAT1 and CCNB1 genes. Their methodology is\\ndivided in three sections including: (i) the determination of gene pairs\\nfor building the graph model with only labeled samples, (ii) the devel-\\nopment of sample graphs based on informative genes and (iii) the reg-ularization of the graph resulting in ﬁnding the labels of unlabeled\\nsamples. The dataset used through this study consists of gene expres-\\nsion pro ﬁles found in the GEO repository [62]as well as of PPIs derived\\nfrom the I2D database [63]. Speci ﬁcally, ﬁve gene expression datasets\\nwere downloaded from GEO including 125, 145, 181, 249 and 111\\nlabeled samples. These samples were classi ﬁed into three groups:\\n(i) recurrence, (ii) non-recurrence and (iii) unlabeled samples and re-\\nferred to cancer types like breast and colon cancer. Additionally, they\\ndownloaded from the I2D database a sample of human PPIs composed\\nof 194.988 known, experimental and predicted interactions. After\\nremoving the duplicated PPIs and the interactions that do not contain\\nproteins mapped to a gene they resulted in an amount of 108,544 inter-\\nactions. Based on the results of this study, the authors showed that the\\ngene networks derived from the SSL learning method include many im-\\nportant genes related to cancer recurrence. They also claimed that their\\napproach outperforms other existing methods in the case of breast can-\\ncer recurrence prediction. The estimated performance of the proposed\\nmethod compared to other known methods that make use of PPIs for\\nthe identi ﬁcation of informative genes showed an accuracy of 80.7%\\nand 76.7% in the breast and colon cancer samples, respectively.\\nTen-fold cross validation was used for estimating the experimental re-\\nsults. Although this type of ML methods differs considerably from\\nthese of supervised and unsupervised learning on the algorithms that\\nthey employ, it is clear that it provides more advantages relevant to\\nthe collection of datasets and their sizes. Unlabeled data are cheap and\\ncan be easier extracted. On the contrary, labeled samples may requireexperts and special devices in order to be collected. This study reveals\\nthat SSL can be an alternative to supervised approaches which usually\\nsuffers from small labeled samples.\\n4.3. Prediction of cancer survival\\nIn\\n[26]a predictive model is developed for the evaluation of survival\\nin women that have been diagnosed with breast cancer, while they ad-\\ndressed the importance of robustness under the model's parameter var-\\niation. They compared three classi ﬁcation models namely SVM, ANN\\nand SSL based on the SEER cancer database [64]. The dataset is com-\\nposed of 162,500 records with 16 key features. A class variable was\\nalso considered, namely survivability, referring to patients that had\\nnot survived and those that had survived. Among the most informative\\nfeatures are (i) the tumor size, (ii) the number of nodes and (iii) the age\\nat diagnosis. By comparing the best performance of each of the three\\nmodels they found that the calculated accuracy for ANN, SVM and SSL\\nwas 65%, 51% and 71% respectively. Five-fold cross validation was used\\nfor evaluating the performance of the predictive models. Concerning\\nthose ﬁndings the authors proposed the SSL model as a good candidate\\nfor survival analysis by the clinical experts. We should note that no pre-\\nprocessing steps were mentioned by the authors regarding the collec-tion of the most informative features. They proceeded with the entire\\nSEER datasets and the box-whisper-plot was used for estimating the\\nperformance variation across 25 combinations of model parameters. A\\nsmall box area of a speci ﬁc model indicates more robustness and stabil-\\nity under parameter combination. The small boxes of the SSL model re-\\nvealed its better accuracy than the other models. A relevant study was\\npublished the next year which attempts to assess the survival prediction\\nof non-small cell lung cancer (NSCLC) patients through the use of ANNs\\n[50]. Their dataset consists of NSCLC patients' gene expression raw data\\nand clinical data obtained from the NCI caArray database [65].A f t e rt h e\\npreprocessing steps in their approach, the authors selected the most in-\\nformative survival-associated gene signatures; LCK and ERBB2 genes,\\nwhich were then used for training the ANN network. Four clinical vari-\\nables, namely sex, age, T_stage and N_stage were also considered as\\ninput variables in the ANN model. They also performed several types\\nof ANN architectures in order to ﬁnd the optimal one for the prediction\\nof cancer survival. An overall accuracy of 83% was provided regarding\\nthe predictive performance of the classi ﬁcation scheme. Furthermore,\\ntheir results revealed that all patients were classi ﬁed in different groups\\nregarding their treatment protocol while 50% of them had not survived.\\nThe evaluation of the model outcomes was done based on the Kaplan –\\nMeier survival analysis. They estimated the survival of patients for the\\ntraining set, the test set and the validation set with p-value b0.00001,\\nwhile they showed that the patients in the high-risk group exhibited a\\nlower median overall survival in comparison to low-risk patients. Com-\\npared to other studies in the literature relevant to NSCLC survival pre-\\ndiction, this work provided more stable results. However, existing\\nlimitations of the current article are related to the fact that the impact\\nof other variables related to death (such as blood clots) is not consid-\\nered, which may have led to misclassi ﬁcation results. Furthermore, the\\nauthors claim that their model could not be applied to other cancer\\ntypes except NSCLC. This assumption is considered as a major limitation\\nin studies that the predictive models may not generalize to differentcancer types.\\n5. Discussion\\nIn the present review, the most recent works relevant to cancer pre-\\ndiction/prognosis by means of ML techniques are presented. After a\\nbrief description of the ML branch and the concepts of the data prepro-\\ncessing methods, the feature selection techniques and the classi ﬁcation\\nalgorithms being used, we outlined three speci ﬁc case studies regarding\\nthe prediction of cancer susceptibility, cancer recurrence and cancer\\nsurvival based on popular ML tools. Obviously, there is a large amount15 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17of ML studies published in the last decade that provide accurate results\\nconcerning the speci ﬁc predictive cancer outcomes. However, the iden-\\ntiﬁcation of potential drawbacks including the experimental design, the\\ncollection of appropriate data samples and the validation of the classi-\\nﬁed results, is critical for the extraction of clinical decisions.\\nMoreover, it should be mentioned that in spite of the claims that\\nthese ML classi ﬁcation techniques can result in adequate and effective\\ndecision making, very few have actually penetrated the clinical practice.\\nRecent advances in omics technologies paved the way to further im-\\nprove our understanding of a variety of diseases; however more accu-\\nrate validation results are needed before gene expression signatures\\ncan be useful in the clinics.\\nA growing trend was noted in the studies published the last 2 years\\nthat applied semi-supervised ML techniques for modeling cancer sur-\\nvival. This type of algorithms employs labeled and unlabeled data for\\ntheir predictions while it has been proven that they improved the esti-\\nmated performance compared to existing supervised techniques [26].\\nSSL can be though as a great alternative to the other two types of ML\\nmethods (i.e. supervised learning and unsupervised learning) that use,\\nin general, only a few labeled samples.\\nOne of the most common limitations noted in the studies surveyed\\nin this review is the small amount of data samples. A basic requirement\\nwhen using classi ﬁcation schemes for modeling a disease is the size of\\nthe training datasets that needs to be suf ﬁciently large. A relatively\\nlarge dataset allows the suf ﬁcient partitioning into training and testing\\nsets, thus leading to reasonable validation of the estimators. A small\\nsized training sample, compared to data dimensionality, can result in\\nmisclassi ﬁcations while the estimators may produce unstable and\\nbiased models. It is obvious that a richer set of patients used for their\\nsurvival prediction can enhance the generalizability of the predictive\\nmodel.\\nExcept the data size, the dataset quality as well as the careful feature\\nselection schemes are of great importance for effective ML and subse-\\nquently for accurate cancer predictions. Choosing the most informative\\nfeature subset for training a model, by means of feature selection\\nmethods, could result in robust models. Additionally, feature sets that\\nconsist of histological or pathological assessments are characterized by\\nreproducible values. Due to the lack of static entities when dealing\\nwith clinical variables it is important for a ML technique to be adjusted\\nto different feature sets over time.\\nIt should be noted that almost all of the works presented here, per-\\nformed validation tests for estimating the performance of their learning\\nalgorithms. They employed well-known evaluation techniques that\\nsplit the initial datasets into subsets. As mentioned above, in order to\\nobtain accurate results for their predictive models, the authors should\\nselect large and independent features that could result in better valida-\\ntion. Internal and external validation was performed in these studies\\nthat would enable the extraction of more accurate and reliable predic-\\ntions while it would minimize any bias [47].\\nA key point to several studies, regarding their promising results, was\\nthe fact that several ML techniques were employed as an aim to ﬁnd the\\nmost optimal one [34]. Apart from this, the combination of multiple data\\ntypes that would be fed as input to the models is also a trend. Looking\\nback to the previous decade, only molecular and clinical information\\nwas exploited for making predictions of cancer outcomes. With the\\nrapid development of HTTs, including genomic, proteomic and imaging\\ntechnologies, new types of input parameters have been collected. We\\nfound that almost all the predictions was made by integrating either\\ngenomic, clinical, histological, imaging, demographic, epidemiological\\ndata and proteomic data or different combinations of these types\\n[24,26,48,50,53] .\\nAdditionally, there has been considerable activity regarding the inte-\\ngration of different types of data in the ﬁeld of breast cancer [66,67] .I n\\nthe DREAM project [68], several attempts to combine clinical treatment\\nscores with signatures based on immunohistochemistry [69]as well as\\nexpression-based signatures such as PAM50 [70] and Oncotype DX[71]reveal the extensive work done for improving treatment based on\\nthe incorporation of different features.\\nAmong the most common applied ML algorithms relevant to the\\nprediction outcomes of cancer patients, we found that SVM and ANN\\nclassi ﬁers were widely used. As mentioned to our introductory section,\\nANNs have been used extensively for nearly 30 years [30].I na d d i t i o n ,\\nSVMs constitute a more recent approach in the cancer prediction/prognosis and have been used widely due to its accurate predictive\\nperformance. However, the choice of the most appropriate algorithm\\ndepends on many parameters including the types of data collected,\\nthe size of the data samples, the time limitations as well as the type of\\nprediction outcomes.\\nConcerning the future of cancer modeling new methods should be\\nstudied for overcoming the limitations discussed above. A better statis-\\ntical analysis of the heterogeneous datasets used would provide more\\naccurate results and would give reasoning to disease outcomes. Further\\nresearch is required based on the construction of more public databases\\nthat would collect valid cancer dataset of all patients that have been\\ndiagnosed with the disease. Their exploitation by the researchers\\nwould facilitate their modeling studies resulting in more valid results\\nand integrated clinical decision making.\\n6. Conclusions\\nIn this review, we discussed the concepts of ML while we outlined\\ntheir application in cancer prediction/prognosis. Most of the studies\\nthat have been proposed the last years and focus on the development\\nof predictive models using supervised ML methods and classi ﬁcation\\nalgorithms aiming to predict valid disease outcomes. Based on the anal-\\nysis of their results, it is evident that the integration of multidimensional\\nheterogeneous data, combined with the application of different tech-\\nniques for feature selection and classi ﬁcation can provide promising\\ntools for inference in the cancer domain.\\nAcknowledgements\\nThis work was part funded by the project NEOMARK (FP7-ICT\\n224483, ICT Enabled Prediction of Cancer Reoccurrence).\\nReferences\\n[1]Hanahan D, Weinberg RA. Hallmarks of cancer: the next generation. Cell 2011;144:\\n646–74.\\n[2]Polley M-YC, Freidlin B, Korn EL, Conley BA, Abrams JS, McShane LM. Statistical and\\npractical considerations for clinical evaluation of predictive biomarkers. J Natl Cancer\\nInst 2013;105:1677 –83.\\n[3]Cruz JA, Wishart DS. Applications of machine learning in cancer prediction and\\nprognosis. Cancer Informat 2006;2:59.\\n[4]Fortunato O, Boeri M, Verri C, Conte D, Mensah M, Suatoni P, et al. Assessment of cir-\\nculating microRNAs in plasma of lung cancer patients. Molecules 2014;19:3038 –54.\\n[5]Heneghan HM, Miller N, Kerin MJ. MiRNAs as biomarkers and therapeutic targets in\\ncancer. Curr Opin Pharmacol 2010;10:543 –50.\\n[6]Madhavan D, Cuk K, Burwinkel B, Yang R. Cancer diagnosis and prognosis decoded\\nby blood-based circulating microRNA signatures. Front Genet 2013;4.\\n[7]Zen K, Zhang CY. Circulating microRNAs: a novel class of biomarkers to diagnose and\\nmonitor human cancers. Med Res Rev 2012;32:326 –48.\\n[8]Koscielny S. Why most gene expression signatures of tumors have not been useful in\\nthe clinic. Sci Transl Med 2010;2 [14 ps12-14 ps12].\\n[9]Michiels S, Koscielny S, Hill C. Prediction of cancer outcome with microarrays: a\\nmultiple random validation strategy. Lancet 2005;365:488 –92.\\n[10] Bishop CM. Pattern recognition and machine learning. New York: Springer; 2006.\\n[11] Mitchell TM. The discipline of machine learning: Carnegie Mellon University. Carnegie\\nMellon University, School of Computer Sc ience, Machine Learning Department; 2006.\\n[12] Witten IH, Frank E. Data mining: practical machine learning tools and techniques.\\nMorgan Kaufmann; 2005.\\n[13] Niknejad A, Petrovic D. Introduction to computational intelligence techniques and\\nareas of their applications in medicine. Med Appl Artif Intell 2013;51.\\n[14] Pang-Ning T, Steinbach M, Kumar V. Introduction to data mining; 2006.\\n[15] Drier Y, Domany E. Do two machine-learning based prognostic signatures for breast\\ncancer capture the same biological processes? PLoS One 2011;6:e17795.\\n[16] Dupuy A, Simon RM. Critical review of published microarray studies for cancer\\noutcome and guidelines on statistical analysis and reporting. J Natl Cancer Inst\\n2007;99:147 –57.16 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17[17] Ein-Dor L, Kela I, Getz G, Givol D, Domany E. Outcome signature genes in breast\\ncancer: is there a unique set? Bioinformatics 2005;21:171 –8.\\n[18] Ein-Dor L, Zuk O, Domany E. Thousands of samples are needed to generate a robust\\ngene list for predicting outcome in cancer. Proc Natl Acad Sci 2006;103:5923 –8.\\n[19] Ayer T, Alagoz O, Chhatwal J, Shavlik JW, Kahn CE, Burnside ES. Breast cancer risk es-\\ntimation with arti ﬁcial neural networks revisited. Cancer 2010;116:3310 –21.\\n[20] Platt JC, Cristianini N, Shawe-Taylor J. Large margin DAGs for multiclass classi ﬁca-\\ntion; 1999 547 –53.\\n[21] Adams S. Is Coursera the beginning of the end for traditional higher education?\\nHigher Education; 2012.\\n[22] Cicchetti D. Neural networks and diagnosis in the clinical laboratory: state of the art.\\nClin Chem 1992;38:9 –10.\\n[23] Cochran AJ. Prediction of outcome for patients with cutaneous melanoma. Pigment\\nCell Res 1997;10:162 –7.\\n[24] Exarchos KP, Goletsis Y, Fotiadis DI. Multiparametric decision support system for the\\nprediction of oral cancer reoccurrence. IEEE Trans Inf Technol Biomed 2012;16:\\n1127 –34.\\n[25] Kononenko I. Machine learning for medical diagnosis: history, state of the art and\\nperspective. Artif Intell Med 2001;23:89 –109.\\n[26] Park K, Ali A, Kim D, An Y, Kim M, Shin H. Robust predictive model for evaluating\\nbreast cancer survivability. Engl Appl Artif Intell 2013;26:2194 –205.\\n[27] Sun Y, Goodison S, Li J, Liu L, Farmerie W. Improved breast cancer prognosis through\\nthe combination of clinical and genetic markers. Bioinformatics 2007;23:30 –7.\\n[28] Bottaci L, Drew PJ, Hartley JE, Had ﬁeld MB, Farouk R, Lee PWR, et al. Arti ﬁcial neural\\nnetworks applied to outcome prediction for colorectal cancer patients in separate in-stitutions. Lancet 1997;350:469 –72.\\n[29] Maclin PS, Dempsey J, Brooks J, Rand J. Using neural networks to diagnose cancer. J\\nMed Syst 1991;15:11 –9.\\n[30] Simes RJ. Treatment selection for cancer patients: application of statistical decision\\ntheory to the treatment of advanced ovarian cancer. J Chronic Dis 1985;38:171 –86.\\n[31] Akay MF. Support vector machines combined with feature selection for breast\\ncancer diagnosis. Expert Syst Appl 2009;36:3240 –7.\\n[32] Chang S-W, Abdul-Kareem S, Merican AF, Zain RB. Oral cancer prognosis based on\\nclinicopathologic and genomic markers using a hybrid of feature selection and\\nmachine learning methods. BMC Bioinforma 2013;14:170.\\n[33] Chuang L-Y, Wu K-C, Chang H-W, Yang C-H. Support vector machine-based\\nprediction for oral cancer using four snps in DNA repair genes; 2011 16 –8.\\n[34] Eshlaghy AT, Poorebrahimi A, Ebrahimi M, Razavi AR, Ahmad LG. Using three\\nmachine learning techniques for predicting breast cancer recurrence. J Health Med\\nInform 2013;4:124.\\n[35] Exarchos KP, Goletsis Y, Fotiadis DI. A multiscale and multiparametric approach for\\nmodeling the progression of oral cancer. BMC Med Inform Decis Mak 2012;12:136.\\n[36] Kim J, Shin H. Breast cancer survivability prediction using labeled, unlabeled, and\\npseudo-labeled patient data. J Am Med Inform Assoc 2013;20:613\\n–8.\\n[37] Fielding LP, Fenoglio ‐Preiser CM, Freedman LS. The future of prognostic factors in\\noutcome prediction for patients with cancer. Cancer 1992;70:2367 –77.\\n[38] Bach PB, Kattan MW, Thornquist MD, Kris MG, Tate RC, Barnett MJ, et al. Variations\\nin lung cancer risk among smokers. J Natl Cancer Inst 2003;95:470 –8.\\n[39] Domchek SM, Eisen A, Calzone K, Stopfer J, Blackwood A, Weber BL. Application of\\nbreast cancer risk prediction models in clinical practice. J Clin Oncol 2003;21:\\n593–601.\\n[40] Gascon F, Valle M, Martos R, Zafra M, Morales R, Castano MA. Childhood obesity and\\nhormonal abnormalities associated with cancer risk. Eur J Cancer Prev 2004;13:\\n193–7.\\n[41] Ren X, Wang Y, Chen L, Zhang X-S, Jin Q. ellipsoidFN: a tool for identifying a hetero-\\ngeneous set of cancer biomarkers based on gene expressions. Nucleic Acids Res\\n2013;41:e53.\\n[42] Ren X, Wang Y, Zhang X-S, Jin Q. iPcc: a novel feature extraction method for accurate\\ndisease class discovery and prediction. Nucleic Acids Res 2013:gkt343.\\n[43] Wang Y, Wu Q-F, Chen C, Wu L-Y, Yan X-Z, Yu S-G, et al. Revealing metabolite bio-\\nmarkers for acupuncture treatment by linear programming based feature selection.\\nBMC Syst Biol 2012;6:S15.\\n[44] Waddell M, Page D, Shaughnessy Jr J. Predicting cancer susceptibility from\\nsingle-nucleotide polymorphism data: a case study in multiple myeloma. ACM\\n2005:21 –8.\\n[45] Listgarten J, Damaraju S, Poulin B, Cook L, Dufour J, Driga A, et al. Predictive models\\nfor breast cancer susceptibility from multiple single nucleotide polymorphisms. Clin\\nCancer Res 2004;10:2725 –37.[46] Stojadinovic A, Nissan A, Eberhardt J, Chua TC, Pelz JOW, Esquivel J. Development of\\na Bayesian belief network model for personalized prognostic risk assessment in\\ncolon carcinomatosis. Am Surg 2011;77:221 –30.\\n[47] Kim W, Kim KS, Lee JE, Noh D-Y, Kim S-W, Jung YS, et al. Development of novel\\nbreast cancer recurrence prediction model using support vector machine. J Breast\\nCancer 2012;15:230 –8.\\n[48] Park C, Ahn J, Kim H, Park S. Integrative gene network construction to analyze cancer\\nrecurrence using semi-supervised learning. PLoS One 2014;9:e86309.\\n[49] Tseng C-J, Lu C-J, Chang C-C, Chen G-D. Application of machine learning to predict\\nthe recurrence-proneness for cervical cancer. Neural Comput & Applic 2014;24:\\n1311 –6.\\n[50] Chen Y-C, Ke W-C, Chiu H-W. Risk classi ﬁcation of cancer survival using ANN with\\ngene expression data from multiple laboratories. Comput Biol Med 2014;48:1 –7.\\n[51] Xu X, Zhang Y, Zou L, Wang M, Li A. A gene signature for breast cancer prognosis\\nusing support vector machine. IEEE 2012:928 –31.\\n[52] Gevaert O, De Smet F, Timmerman D, Moreau Y, De Moor B. Predicting the prognosis\\nof breast cancer by integrating clinical and microarray data with Bayesian networks.\\nBioinformatics 2006;22:e184 –90.\\n[53] Rosado P, Lequerica-Fernández P, Villallaín L, Peña I, Sanchez-Lasheras F, de Vicente\\nJC. Survival model in oral squamous cell carcinoma based on clinicopathological\\nparameters, molecular markers and support vector machines. Expert Syst Appl\\n2013;40:4770 –6.\\n[54] Delen D, Walker G, Kadam A. Predicting breast cancer survivability: a comparison of\\nthree data mining methods. Artif Intell Med 2005;34:113 –27.\\n[55] Urbanowicz RJ, Andrew AS, Karagas MR, Moore JH. Role of genetic heterogeneityand epistasis in bladder cancer susceptibility and outcome: a learning classi ﬁer sys-\\ntem approach. J Am Med Inform Assoc 2013;20:603 –12.\\n[56] Bochare A, Gangopadhyay A, Yesha Y, Joshi A, Yesha Y, Brady M, et al. Integrating do-\\nmain knowledge in supervised machine learning to assess the risk of breast cancer.\\nInt J Med Eng Inform 2014;6:87 –99.\\n[57] Gilmore S, Hofmann ‐Wellenhof R, Soyer HP. A support vector machine for decision\\nsupport in melanoma recognition. Exp Dermatol 2010;19:830 –5.\\n[58] Mac Parthaláin N, Zwiggelaar R. Machine learning techniques and mammographic\\nrisk assessment. Digital mammography. Springer; 2010. pp. 664 –672.\\n[59] Hall MA. Feature selection for discrete and numeric class machine learning; 1999.\\n[60] Kohavi R, John GH. Wrappers for feature subset selection. Artif Intell 1997;97:\\n273–324.\\n[61] Estévez PA, Tesmer M, Perez CA, Zurada JM. Normalized mutual information feature\\nselection. IEEE Trans Neural Netw 2009;20:189 –201.\\n[62] Barrett T, Troup DB, Wilhite SE, Ledoux P, Rudnev D, Evangelista C, et al. NCBI GEO:\\nmining tens of millions of expression pro ﬁles—database and tools update. Nucleic\\nAcids Res 2007;35:D760 –5.\\n[63] Niu Y, Otasek D, Jurisica I. Evaluation of linguistic features useful in extraction of\\ninteractions from PubMed; application to annotating known, high-throughput and\\npredicted interactions in I2D. Bioinformatics 2010;26:111 –9.\\n[64] Howlader N, Noone A, Krapcho M, Garshell J, Neyman N, Aletkruse S. SEER Cancer\\nStatistics Review, 1975 –2010, [Online] National Cancer Institute. Bethesda, MD: Na-\\ntional Cancer Institute; 2013 [Online].\\n[65] Bian X, Klemm J, Basu A, Had ﬁeld J, Srinivasa R, Parnell T, et al. Data submission and\\ncuration for caArray, a standard based microarray data repository system; 2009.\\n[66] Papadopoulos A, Fotiadis DI, Costaridou L. Improvement of microcalci ﬁcation cluster\\ndetection in mammography utilizing image enhancement techniques. Comput Biol\\nMed 2008;38:1045 –55.\\n[67] Papadopoulos A, Fotiadis DI, Likas A. Characterization of clustered microcalci ﬁcations in\\ndigitized mammograms using neural networks and support vector machines. Artif Intell\\nMed 2005;34:141 –50.\\n[68] Bilal E, Dutkowski J, Guinney J, Jang IS, Logsdon BA, Pandey G, et al. Improving breast\\ncancer survival analysis through competition-based multidimensional modeling.\\nPLoS Comput Biol 2013;9:e1003047.\\n[69] Cuzick J, Dowsett M, Pineda S, Wale C, Salter J, Quinn E, et al. Prognostic value of a\\ncombined estrogen receptor, progesterone receptor, Ki-67, and human epidermal\\ngrowth factor receptor 2 immunohistochemical score and comparison with the Ge-\\nnomic Health recurrence score in early breast cancer. J Clin Oncol 2011;29:4273 –8.\\n[70] Parker JS, Mullins M, Cheang MC, Leung S, Voduc D, Vickery T, et al. Supervised risk\\npredictor of breast cancer based on intrinsic subtypes. J Clin Oncol 2009;27:1160 –7.\\n[71] Paik S, Shak S, Tang G, Kim C, Baker J, Cronin M, et al. A multigene assay to predict\\nrecurrence of tamoxifen-treated, node-negative breast cancer. N Engl J Med 2004;\\n351:2817 –26.17 K. Kourou et al. / Computational and Structural Biotechnology Journal 13 (2015) 8 –17\"}, {'document_name': 'AI technologies for education_ Recent research & future directions.pdf', 'file_path': '../data\\\\Folder1\\\\AI technologies for education_ Recent research & future directions.pdf', 'content': 'Computers and Education: Artificial Intelligence 2 (2021) 100025\\nAvailable online 9 June 2021\\n2666-920X/© 2021 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license\\n(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).AI technologies for education: Recent research & future directions \\nKe Zhanga,*, Ayse Begum Aslanb \\na385Education, Wayne State University, Detroit, MI, 48202, USA \\nb203Boone Hall, Eastern Michigan University, Ypsilanti, MI, 48197, USA   \\nARTICLE INFO  \\nKeywords: \\nArtificial intelligence \\nAI \\nAI in Education ABSTRACT  \\nFrom unique educational perspectives, this article reports a comprehensive review of selected empirical studies \\non artificial intelligence in education (AIEd) published in 1993 –2020, as collected in the Web of Sciences \\ndatabase and selected AIEd-specialized journals. A total of 40 empirical studies met all selection criteria, and \\nwere fully reviewed using multiple methods, including selected bibliometrics, content analysis and categorical \\nmeta-trends analysis. This article reports the current state of AIEd research, highlights selected AIEd technologies \\nand applications, reviews their proven and potential benefits for education, bridges the gaps between AI tech-\\nnological innovations and their educational applications, and generates practical examples and inspirations for \\nboth technological experts that create AIEd technologies and educators who spearhead AI innovations in edu-\\ncation. It also provides rich discussions on practical implications and future research directions from multiple \\nperspectives. The advancement of AIEd calls for critical initiatives to address AI ethics and privacy concerns, and \\nrequires interdisciplinary and transdisciplinary collaborations in large-scaled, longitudinal research and devel -\\nopment efforts.   \\nSince Alan Turing first articulated the promising vision of “thinking \\nmachines ” in 1950, artificial intelligence (AI) research has been \\nadvanced in many different fields and generated an increasing body of \\nliterature (e.g., Andriessen and Sandberg, 1999 ; Beck et al., 1996 ; Bur-\\nleson & Lewis, 2016 ; Clancey et al., 1979 ; Kaplan & Haenlein, 2019 ; \\nKurzweil, 1985 ; Kurzweil & Kapor, 2002; Kurzweil, 2002; Legg & Hut-\\nter, 2007 ; Simmons & Chappell, 1988 ; Zdenek, 2003 ). In education, \\nemerging technologies have also been transforming ways of teaching \\nand learning. The AI market in US Education Sector is expected to grow \\nby 48% in 2018 –2022 (BusinessWire.com , 2018). With the thrive of AI \\ntechnology, its applications in education have been increasing, with \\npromising potentials to provide customized learning, to offer dynamic \\nassessments, and to facilitate meaningful interactions in online, mobile \\nor blended learning experiences. More provocatively, in response to the \\nteacher shortage in USA, for example, scholars (Edwards & Cheok, \\n2018) have proposed to replace some roles of teachers with robots with \\nAI. \\nThe increasing applications of AI in education (AIEd) demand \\ninterdisciplinary approaches, while most AI research is carried out only \\nin STEM fields (Zawacki-Richter, Marin, Bond & Gouverneur, 2019 ). \\nConsistently, a few recent literature reviews have highlighted the lack of \\neducational perspectives in AIEd research (e.g., Chen, Xie, Zou, & Hwang, 2020 ; Hinojo-Lucena, Aznar-Díaz, C˘aceres-Reche, & Romer -\\no-Rodríguez, 2019 ; Zawacki-Richter, Marín, Bond, & Gouverneur, \\n2019 ). In addition, researchers have voiced concerns about the absence \\nof educational theories and models, as found in AI-enabled e-learning \\nresearch published in the past two decades (Tang, Chang, & Hwang, \\n2021 ). It is also worth noting that AIEd innovations remain at the early, \\nexperimental stage, and there is few collaboration with educational in-\\nstitutions in related interventions such as AI enabled adaptive systems \\n(Kabudi, Pappas, & Olsen, 2021 ). As a result, there has been a critical \\ngap between what AIEd technologies could do and how they are actually \\nimplemented in authentic educational settings (Bates et al., 2020 ; \\nKabudi et al., 2021 ). \\nAs an effort to further advance AI technologies for education, this \\narticle intends to help the broader AIEd community, including educa -\\ntors, educational researchers, AI technology creators and other stake -\\nholders to build a deeper understanding in AIEd, including its current \\nstate, potentials, challenges and future directions. Specifically, this \\ncomprehensive review of related literature aims to achieve the following \\ngoals through multiple analysis methods:  \\n≡to map the landscape of AIEd research publications in recent \\ndecades, \\n*Corresponding author. \\nE-mail addresses: Ke.zhang@wayne.edu (K. Zhang), aaydinol@emich.edu (A.B. Aslan).  \\nContents lists available at ScienceDirect \\nComputers and Education: Artificial Intelligence \\nu{�~zkw! s{yo|kr o>!ÐÐÐ1�mt ozmont~om�1 m{y2u{�~zk w2m{y|��o~�/k zn/on�mk�t {z/k~�tˆmtkw /tz�owwtrozmo!\\nhttps://doi.org/10.1016/j.caeai.2021.100025 \\nReceived 10 December 2020; Received in revised form 3 May 2021; Accepted 30 May 2021   \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n2≡to identify AI technologies and their educational applications and \\nbenefits, as reported in empirical research,  \\n≡to generate practical guidelines, examples, inspirations and other \\ntakeaways for both educators and AI technological experts, \\n≡to facilitate communications and collaborations amongst stake -\\nholders with different areas of expertise (e.g., technological skills vs. \\nlearning theories and pedagogies), \\n≡to understand AIEd research and development from different per-\\nspectives (e.g., technology advancement, teaching and learning, \\nadministrations of educational systems, educational research, etc.)  \\n≡to shape fruitful collaborations in AIEd research, development, \\nimplementation and evaluation. \\nThus, with a unique focus on education, this article reports a \\ncomprehensive review of eligible empirical studies on AIEd, applying \\nmixed methods, including selected bibliometrics (Okubo, 1997 ; Thel-\\nwall, 2008 ), a categorical meta-trends analysis (e.g., Hung & Zhang, \\n2012 ; Thelwall, 2008 ) and inductive content analysis (Gao, Luo, & \\nZhang, 2012 ; Mogil, Simmonds, & Simmonds, 2009 ). This study in-\\nvestigates the longitudinal growth of empirical studies on AIEd, gener -\\nates the macro, as well as micro viewpoints on AIEd research. Through a \\nbroad overview on the current state of AIEd research, this review also \\ncreates a solid foundation for historical or meta analyses of the \\nincreasing body of research literature on AIEd. More importantly, this \\narticle provides practical takeaways for varied AIEd stakeholders and \\nidentifies new directions for AIEd practice, research, development, \\nimplementation and evaluations. From educational perspectives, this \\nstudy stands out from many other related reviews with the following \\ndifferences:  \\n(a) the scope, as defined by the research questions and inclusion and \\nexclusion criteria,  \\n(b) the selected mixed methods for varied analyses,  \\n(c) highly focused analyses as related to education, and  \\n(d) the implications and discussions from multiple perspectives. \\nThe following research questions guided the multi-phased search, \\nreview and analyses of AIEd research publications in this study:  \\n1. What is the landscape of research publications on AIEd in the Web of \\nScience Database and selected AIEd specialized journals?  \\n2. What are the AIEd Technology applications and their educational \\nbenefits, as reported in eligible research publications?  \\n3. What implications does current research have on future research and \\npractice of AIEd? \\n1.Research methods and process \\nThis multi-phase study critically examines refereed research publi -\\ncations on AI in education. Multi-phase searches and selections were \\nconducted to identify eligible publications for full analyses. \\n1.1. Source databases \\nWith the surge of online publications and open access resources, it is \\nvirtually impossible to conduct an exhaustive search even with well- \\ndefined criteria. This investigation was carefully designed to focus on \\nresearch publications collected in one of the most widely used web- \\nbased databases, the Web of Science (SCI/SSCI). Web of Science (SCI/ \\nSSCI) was chosen as the source database for the following reasons: (1) it \\ncollects journals in both Science Citation Index (SCI) and Social Science \\nCitation Index (SSCI); (2) the database is highly selective, including \\nregarded journals in both sciences and social sciences; and (3) it is one of \\nthe few comprehensive web-based databases that allow detailed bib-\\nliometric analysis (Okubo, 1997 ). As newer journals may not be included in Web of Science database, \\nadditional search efforts were made to locate more, recent publications \\non AIEd-specialized journals. The following three specialized journals \\nwere selected as additional source databases, International Journal of \\nArtificial Intelligence in Education , International Journal of Learning Ana-\\nlytics and Artificial Intelligence for Education and Computers & Education: \\nArtificial Intelligence . \\n1.2. Searches and selections \\nMultiple rounds of searches were conducted on the source database \\nusing different combinations of key words and search strategies, such as \\n“AI”, “artificial intelligence ”, and “education ”. Three rounds of searches \\non Web of Science yielded a total of 507 articles initially, from which 27 \\nduplicates, one conference paper, and two non-English articles were \\nexcluded in the initial screening. In addition, searches were conducted \\non the three selected journals ’ websites for research articles published \\ntill 2020, using the same search strategies. \\n1.2.1. Selection criteria and results \\nIn order to achieve the specified research goals, a set of selection \\ncriteria were established and applied for inclusion and exclusion. Only \\nEnglish, refereed journal articles reporting empirical, evidence-based \\nstudies were selected for further analyses. The following were \\nexcluded: (a) non-English publications, (b) conference proceedings or \\npresentations, (c) theoretical or conceptual articles, (d) reports of per-\\nsonal user experiences, (e) articles reporting no data or without enough \\ndata, (f) research without human participants, (g) studies not related to \\neducation or artificial intelligence, and (h) quantitative studies with less \\nthan 20 participants. \\nIn addition, the following criteria were followed strictly in the \\nscreening and selection process: 1. Research must focus on AI in \\neducational settings. Published research on AI in the consumer market, \\nengineering, health care systems and other non-educational settings was \\nthus excluded; 2. Research must be data-supported empirical studies. \\nArticles that were solely based on personal opinions or anecdotal ex-\\nperiences were excluded; 3. Research must have investigated educa -\\ntional effects of AI by reporting relevant qualitative or quantitative data. \\nPapers that did not provide any evidence on learning were excluded; 4. \\nResearch must have sufficient participants with a large enough sample \\nsize. Experimental or quasi experimental studies or survey research with \\nless than 20 participants were thus excluded; 5. Theoretical, conceptual \\nand literature review papers were also excluded for full analyses, but \\nthey were carefully read to strengthen our background knowledge and \\nto broaden the theoretical foundation for developing a general under -\\nstanding of AI in education. \\nThe researchers reviewed all search results together and reached \\nconsensus on inclusion or exclusion of each article. After careful \\nscreenings and initial analyses, a total of 40 research articles were \\nselected for full analyses, including 34 articles from Web of Science, five \\nfrom International Journal of Artificial Intelligence in Education, and one \\nfrom Computers & Education: Artificial Intelligence . No eligible articles \\nwere identified from the International Journal of Learning Analytics and \\nArtificial Intelligence for Education . \\n1.3. Analysis methods \\nBibliometrics have been widely applied to evaluate research publi -\\ncations through quantitative analyses to measure varied indicators (e.g., \\nKeshaval & Gowda 2008; Okubo, 1997 ; Thelwall, 2008 ). More recently, \\nresearchers have also conducted content analysis to address the \\ndisparity between quantitative and qualitative approaches in reviewing \\nresearch publications (e.g., Gao et al., 2012 ; Hung & Zhang, 2012 ; Mogil \\net al., 2009 ). Thus, in this study, selected bibliometrics (Okubo, 1997 ), \\ncategorical meta-trend analysis (Hung & Zhang, 2012 ; Thelwall, 2008 ) \\nand inductive content analysis (Gao et al., 2012 ; Mogil et al., 2009 ) were K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n3conducted. \\nThe researchers reviewed each eligible article and analyzed them to \\nidentify the followings: bibliometrics, setting of the study, participants \\nprofile, sample size, country of the study, AI technology applications and \\neffects in education, and implications on AIEd. The researchers collab -\\noratively developed a coding system for this review. Major codes \\nincluded bibliometrics of the publication (e.g., year of publication, name \\nof the journal, etc.), countries where studies were carried out, educa -\\ntional setting of the study, (e.g., K-12 or higher education), subject area \\nin which a particular AI technology was implemented and researched (e. \\ng., engineering, psychology, etc.), participants profile (e.g., grade level, \\nage, demographics, etc.), number of participants, specific AI technology \\napplications and their educational benefits as reported in the study. Both \\nresearchers discussed on the coding, categorization and themes emerged \\nin the process and resolved any disagreements through discussions to \\nbuild shared understandings. The collaborative approach throughout \\nmultiple analyses ensured a high reliability and trustworthiness of the \\nreview. \\n2.Results \\n2.1. The landscape of AIEd research publications \\nBibliometric analyses (e.g. Keshaval & Gowda 2008; Okubo, 1997 ; \\nThelwall, 2008 ), categorical meta-trend analysis (Hung & Zhang, 2012 ; \\nThelwall, 2008 ) and inductive content analysis were conducted on all \\neligible research articles. The following summarizes the AIEd research \\nanalyzed in this study. \\n2.1 Prolific countries. Artificial intelligence in education (AIEd) \\nresearch has been conducted in many countries around the world. The \\n40 articles reported AIEd research studies in 16 countries (See Table 1). \\nUSA was so far the most prolific, with nine articles meeting all criteria \\napplied in this study, and noticeably seven of them were conducted in K- \\n12. Followed was China with seven AIEd articles. Two of them were \\nconducted in Hong Kong Special Administrative Region in the early \\n2000s (i.e., Cheung, Hui, Zhang, & Yiu, 2003 ; Xu & Wang, 2006 ), and \\ntwo took place in Taiwan (Hwang, Sung, Chang, & Huang, 2020 ; Shih, \\nChang, Chen, Chen, & Liang, 2012 ), including one study in 2012, a few \\nyears before the global research community caught up with the surge of \\nAIEd publications in 2015. More recently, scholars in mainland China \\nalso conducted large-scaled AIEd research in 2017 (Xie, Zheng, Zhang, & \\nQu, 2017 ) and 2018 (Wei, Yang, Chen, & Hu, 2018 ). \\nTurkey and Spain tied as the third most prolific countries, each with \\nfive AIEd studies, and they were all in the recent years. Interestingly to \\nnote, while UK had the first AIEd study (Kelly, Sleeman, & Gilhooly, \\n1993 ) in 1993, that was also the only one from UK. Other countries \\ncontributing to the increasing body of AIEd research included Australia, \\nBrazil, Canada, France, Greece, Japan, Korea, Pakistan, Slovenia, Swe-\\nden, UAE and UK. Remarkably, the Global South is well represented in \\nAIEd research publications. In addition, there was one multinational \\nstudy that took place in United Arab Emirates and Spain (Rapanta & \\nWalton, 2016 ). One AIEd study was executed at a high school in Europe, \\nbut it did not specify which country (Moridis & Economides, 2009 ). \\n2.2. Educational settings \\nThe reviewed articles reported various empirical studies in both K-12 \\n(n \\x8817) and higher education systems (n \\x8821). Articles did not specify \\nthe educational settings in which they were carried out were not \\nincluded in Table 2. \\n2.3. Subject areas \\nAI was implemented and examined in a wide variety of subject areas, \\nsuch as science, medicine, arts, sports, engineering, mathematics, \\ntechnologies, foreign language, business, history and more (See Table 1 \\nA summary of countries and participants of AIEd research.  \\nCountry/ \\nPlace of Study n Article Participants \\nAustralia 1 Ijaz, Bogdanovych, and \\nTrescak (2017) 60 undergraduate students \\nBrazil 1 Santos and Notargiacomo \\n(2018) 21 volunteers \\nCanada 1 a. Xiao and Hu (2019) 203 primary school ESL \\nstudents (177 high-achieving \\nand 36 low-achieving \\nstudents) \\nChina 7 1. a. Wei et al. (2018) 169 undergraduate students \\nin School of International \\nStudies majoring in English \\n2. b. Xie et al. (2017) 7341 students in \\nengineering, medical \\nscience, and business science \\n3. Zheng, Zhang, Xu, Peng, \\nand Wu (2018) 20 elementary students \\n4. b. Cheung et al. (2003) \\n(Hong Kong) 40 university students for \\ninitial evaluation; & 1300 \\nstudents for full scale \\nevaluation \\n5. a. Xu and Wang (2006) \\n(Hong Kong) 228 online undergraduate \\nstudents taking the \\n“Introduction to the Oracle \\nDatabase ” course \\n6. Shih et al. (2012) (Taiwan) 49 sixth grade students from \\na school with lower \\nsocioeconomic status \\ncompared to other schools in \\nthe region \\n7. a. Hwang et al. (2020) \\n(Taiwan) 162 5th graders (53 (26 \\nmale, 27 female) in the \\nexperimental group, 53 (26 \\nmale, 27 female) and 56 (26 \\nmale, 30 female) in the other \\ntwo groups \\nEurope \\n(country \\nnot \\nspecified) 1 a. Moridis and Economides \\n(2009) 153 high school students \\nFrance 1 Loup-Escande et al. (2017) 76 participants learning \\ncalligraphy \\nGreece 2 1. Samarakou, Fylladitakis, \\nFruh, Hatziapostolou, & \\nGelengenis (2015) 60 postgraduate students \\npursuing a master ’s degree \\non Energy Technology \\n2. Samarakou, Tsaganou, \\nand Papadakis (2018) 28 undergraduate students \\nstudying Informatics (16 \\nfrom third grade, 12 from \\nsecond grade) \\nJapan 1 a. Fryer, Ainley, Thompson, \\nGibson, and Sherlock (2017) 122 first and second-year \\nuniversity students \\nPakistan 1 a. Munawar, Toor, Aslam, \\nand Hamid (2018) 161 postgraduate and \\nundergraduate students \\nSlovenia 1 b. Flogie and Abersek (2015) 4473 students in 7th-9th \\ngrades in total: (4373 in the \\ncontrol group and 100 in the \\nexperimental group) & 20 \\nteachers in the qualitative \\nresearch \\nSpain 5 1. Griol, Molina, and Callejas \\n(2014) 56 undergraduate students in \\ncomputer science \\n2. a. Leony, Munoz-Merino, \\nPardo, & Kloos (2013) 334 s-year undergraduate \\nengineering students in a \\nprogramming course \\n3. a. Mas-Sanso and \\nManresa-Yee (2016) 160 undergraduate \\nengineering students \\n4. a. Montalvo, Palomo, and \\nde la Orden (2018) 138 undergraduate students \\nin Business Administration \\nprogram \\n5. a. Rapanta and Walton \\n(2016) (UAE & Spain) 205 university students – 112 \\nwere undergraduates in \\nDubai, UAE and 93 were \\nundergraduates in Barcelona, \\nSpain \\n(continued on next page) K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n4Table 3). The largest number of AIEd research studies (n \\x8814) were in \\nengineering, computer science, information technology (IT), or infor-\\nmatics, followed by mathematics (n \\x888), foreign language (n \\x884), \\nscience (n \\x883), and business (n \\x883). In total, 25 of the 40 research \\nstudies were conducted in STEM fields. Three studies investigated AIEd \\nin multiple disciplines (i.e., Cheung et al., 2003 ; Dias et al., 2015 ; Xie \\net al., 2017 ). Articles did not specify the subject areas addressed in the \\nstudy were not in Table 3. \\n2.4. Collaborations in AIEd research \\nMost of the AIEd research articles were outcomes of collaborative work with two or more authors. Among the 40 research articles \\nreviewed in this study, only two empirical studies were single authored \\n(Arpaci, 2019 ; K\\x7fose, 2017 ). Collaborative research on AIEd involved not \\nonly multiple authors but also multiple disciplines (e.g., Cheung et al., \\n2003 ; Dias et al., 2015 ; Xie et al., 2017 ), and sometimes in multiple \\ncountries (e.g., Rapanta & Walton, 2016 ) as well. \\n2.5. Participants and sample sizes \\nThe sample sizes of the AIED research varied greatly, ranging from \\n20 (Zheng, Zhang Xu, Peng, & Wu, 2018 ) to 7341 (Xie et al., 2017 ), as \\nnoted in Table 1. Most of the studies had a sample size of 100–500 (n \\x88\\n24), and three studies had sample sizes larger than 1000 (i.e., Dias et al., \\n2015 , Flogie & Abersek, 2015 ; Xie et al., 2017 ). \\nParticipants profiles also varied by study. AIEd research involved \\nparticipants from K-12 schools or higher education institutions (see \\nTable 2), from different countries (see Table 1), in distinct academic \\nprograms or courses (Table 3), and of various social economic states \\n(Table 1). Participants in a study were from different grade levels (e.g., \\nChin et al., 2010 ; Flogie & Abersek, 2015 ; Samarakou et al., 2018 ), from \\nmultiple disciplines (e.g., Cheung et al., 2003 ; Dias et al., 2015 ; Xie \\net al., 2017 ), in different countries (e.g., Rapanta & Walton, 2016 ), \\nincluded both adults and children (e.g., Keshav et al., 2017 ), or involved \\nboth faculty and students (e.g., Cheung et al., 2003 ). \\nStudent diversity was also examined in some AIEd research studies. Table 1 (continued ) \\nCountry/ \\nPlace of Study n Article Participants \\nSweden 2 1. a. Tarning, Silvervarg, \\nGulz, & Haake (2019) 166 students – ages 10-11 \\n2. Gulz, Londos, and Haake \\n(2020) 36 children – ages 4–6 years \\nold from three different \\npreschools \\nTurkey 5 1. a. Arpaci (2019) 308 undergraduate students \\nin IT classes \\n2. a. Bahçeci and Gürol \\n(2016) 162 undergraduate software \\nengineering students \\n3. a. K\\x7fose and Arslan (2016) 110 undergraduate students \\nin computer technologies \\n4. a. K\\x7fose (2017) 453 university students \\n5. a. Peker, Guruler, Sen, and \\nIstanbullu (2017) 300 9th grade students \\nUAE 1 a. Rapanta and Walton \\n(2016) (UAE & Portugal) 205 university students – 112 \\nwere undergraduates in \\nDubai, UAE and 93 were \\nundergraduates in Barcelona, \\nSpain \\nUK 1 Kelly et al. (1993) 38 first year undergraduate \\npsychology students     \\nUSA 9 1. a. Chin et al. (2010) First study: 28 and 30 \\nstudents in 6th grade; \\nSecond study: 104 Fifth \\nGrade students \\n2. a. Chin, Dohmen, and \\nSchwartz (2013) 153 fourth-grade students in \\na small public school \\n3. Gonzalez, Hollister, \\nDeMara, Leigh, Lanman, Lee, \\nParker, Walls, Parker, Wong, \\nBarham, & Wilder (2017) Middle school students who \\nvisited the museum; \\nResponses to survey \\nquestions vary: 48 responses \\nto Q11, and 56 responses to \\nQ12 \\n4. a. McCarthy, Likens, \\nJohnson, Guerrero, and \\nMcNamara (2018) 234 high school students and \\nrecent high school graduates \\n5. a. McLaren, DeLeeuw, & \\nMayer (2011 ) 132 urban high school \\nstudents in five chemistry \\nclasses \\n6.Keshav, Salisbury, \\nVahabzadeh, and Sahin \\n(2017) 21 adults and children with \\nautism \\n7. a. Atilola et al. (2014) Freshmen engineering \\nstudents: Spring 2011 \\nsemester n \\x8864, Fall 2011 \\nsemester: Honors section n \\x88\\n36 & Regular section n \\x8886, \\nFall 2012 semester n \\x8849 \\n8. a. Walkington & Bernacki \\n(2019) 106 high school students \\n9. a. Matsuda, Weng, and \\nWall (2020) 208 6th, 7th and 8th grade \\nstudents \\nNote. \\nastudy with a sample size larger than 100 but smaller than 1000.  \\nbstudy with a sample size larger than 1000.  Table 2 \\nAIEd research articles by setting.  \\nEducational \\nSetting n Articles \\nHigher \\neducation 21 1. Arpaci (2019) \\n2. Atilola et al. (2014) \\n3. Bahçeci and Gürol (2016) \\n4. Cheung et al. (2003) \\n5. Dias, Hadjileontiadou, Hadjileontiadis, and Diniz \\n(2015) \\n6. Fryer et al. (2017) \\n7. Griol et al. (2014) \\n8. Ijaz et al. (2017) \\n9. Kelly et al. (1993) \\n10. K\\x7fose and Arslan (2016) \\n11. K\\x7fose (2017) \\n12. Leony, Munoz-Merino, Pardo, & Kloos (2013) \\n13. Mas-Sanso and Manresa-Yee (2016) \\n14. Montalvo et al. (2018) \\n15. Munawar et al. (2018) \\n16. Rapanta and Walton (2016) \\n17. Samarakou, Fylladitakis, Fruh, Hatziapostolou, & \\nGelengenis (2015) \\n18. Samarakou et al. (2018) \\n19. Wei et al. (2018) \\n20. Xie et al. (2017) \\n21. Xu and Wang (2006) \\nK-12 education 17 1. Chin et al. (2013) \\n2. Chin et al. (2010) \\n3. Flogie and Abersek (2015) \\n4. Gonzalez, Hollister, DeMara, Leigh, Lanman, Lee, \\nParker, Walls, Parker, Wong, Barham, & Wilder (2017) \\n5. Gulz et al. (2020) \\n6. Keshav et al. (2017) \\n7. Matsuda et al. (2020) \\n8. McCarthy, Likens, Johnson, Guerrero, & McNamara \\n(2018) \\n9. McLaren, DeLeeuw, & Mayer (2011) \\n10. Moridis and Economides (2009) \\n11. Peker et al. (2017) \\n12. Shih et al. (2012) \\n13. Tarning, Silvervarg, Gulz, & Haake (2019) \\n14. Walkington & Bernacki (2019) \\n15. Xiao and Hu (2019) \\n16. Zheng et al. (2018) \\n17. Hwang et al. (2020)  K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n5For instance, in a recent study in Canada (Xiao & Hu, 2019 ), researchers \\nanalyzed possible differences between high achieving and low achieving \\nstudents. In an earlier study in Taiwan, Shih and colleagues (Shih et al., \\n2012 ) studied sixth graders from a school with lower socioeconomic \\nstatus, in comparison to other schools in the same region. Also, in some \\nresearch, both teachers and students were studied. For example, in a \\nstudy in Slovenia, the researchers examined the effects of a trans -\\ndisciplinary cognitive neuro-educational model on the attitudes of both \\nstudents and teachers toward school (Flogie & Abersek, 2015 ). In sum, \\nAIEd research was conducted with participants representing diverse \\npopulations in different countries, in various educational settings and in \\nan array of subject areas. \\n3.AIEd technology applications & educational benefits \\nAI technology brings virtually unlimited possibilities to education. \\nThe 40 articles investigated a wide variety of AI applications in educa -\\ntion, including the following types of learning technology: \\n≡Chatbot (Fryer et al., 2017 ); \\n≡Expert systems (Dias et al., 2015 ; Hwang et al., 2020 ); \\n≡Intelligent tutors or agents (Cheung et al., 2003 ; Chin et al., 2010 ; \\nChin et al., 2013 ; Cung, Xu, Eichhorn, & Warschauer, 2019 ; Gulz et al., \\n2020 ; K\\x7fose & Arslan, 2016 ; Matsuda et al., 2020 ; McCarthy et al., 2018 ; \\nMcLaren, DeLeeuw, & Mayer, 2011 ; T\\x7farning, Silvervarg, Gulz, & Haake, \\n2019 ); \\n≡Machine learning (Arpaci, 2019 ; Wei, et a., 2018 ); ≡Personalized learning systems or environments (PLS/E) (Bahçeci & \\nGürol, 2016 ; Griol et al., 2014 ; K\\x7fose, 2017 ; Montalvo et al., 2018 ; \\nSamarakou et al., 2018 ; Santos & Notargiacomo, 2018 ; Xu & Wang, \\n2006 ; Walkington & Bernacki, 2019 ); \\n≡Visualizations (Keshav et al., 2017 ; Leony, Munoz-Merino, Pardo, & \\nKloos, 2013 ; Lou-Escande, Frenoy, Poplimont, Thouvenin Gapenne, & \\nMegalakaki, 2017 ) \\n3.1. Chatbot \\nOnly one study focused solely on chatbot in education and it was not \\ndirectly linked to learning outcomes. Through a twelve-week experi -\\nment, researchers tested the effects of chatbot partners, compared to \\nhuman partners, on students ’ course interest in foreign language classes \\nwith 122 students (Fryer et al., 2017 ). The study found that students ’ \\ninterests dropped after one week with chatbot, and the Structural \\nEquation Modelling indicated that task interest predicted future course \\ninterest in human partner conditions, while under Chatbot partner \\nconditions it did not. While researchers attributed the decrease in in-\\nterest to a novelty effect (Fryer et al.), it calls for more empirical studies \\nto examine effects of chatbot in education. \\n3.2. Expert system \\nAIEd research suggested that dynamic, holistic expert systems can \\nhelp with pedagogical planning and fully unleash the potentials of \\nlearning management systems (LMS) for teaching and learning (Dias \\net al., 2015 ). For example, Dias and colleagues researched on the quality \\nof interactions in a blended learning environment with 1037 students \\nand 75 professors in an LMS through multiple courses in an academic \\nyear (Dias et al., 2015 ). Their study proved that the structural charac -\\nteristics of an expert system can model how LMS users interact with it \\n(Dias et al., 2015 ), and thus to facilitate and improve the teaching and \\nlearning experiences on the LMS. In a recent study (Hwang et al., 2020 ), \\nresearchers investigated the effects of a fussy expert system on \\nelementary students ’ math learning outcomes in Taiwan. In this study, \\nstudents in the experimental group outperformed those in the other two \\ngroups in mathematics learning achievement. In addition, the adaptive \\nlearning model with affective and cognitive performance analysis was \\nfound effective in reducing math anxiety amongst the fifth graders in \\nTaiwan (Hwang et al., 2020 ). \\n3.3. Intelligent tutors or agents \\nIntelligent tutors or agents provide customized, timely, and appro -\\npriate materials, guidance, and feedback to learners. With great poten -\\ntials, research indicates mixed implications regarding its effects on \\nlearning. For example, a few studies examined the effects of Teachable \\nAgent (TA) (Chin et al, 2010 , 2013 ; Matsuda et al., 2020 ; T\\x7farning et al., \\n2019 ). Research indicated that TA promoted learning for elementary \\nstudents in different grades (Chin et al, 2010 , 2013 ; Matsuda et al., \\n2020 ) and prepared students to learn new science content from their \\nregular lessons, even when they were not using the AI software (Chin \\net al., 2010 ). More recently, researchers in Sweden (Gulz et al., 2020) \\nstudied preschoolers ’ understanding of a TA-based math game as re-\\nflected in their gaze behaviors. The study indicated that young children \\nperceived the TA as an independent entity, and researchers thus sug-\\ngested that TA was promising in facilitating metacognitive scaffolding \\n(Gulz et al., 2020). In another study, researchers examined the effects of \\nmetacognitive scaffolding by teaching a TA on 7th & 8th graders ’ \\nlearning outcomes (Matsuda et al., 2020 ). They found that students ’ \\nability to solve problems increased with the three TA interventions, but \\nthere was no difference amongst the three different conditions (Matsuda \\net al., 2020 ). Research also suggested that TA with a similar level of \\nself-efficacy with target students may help improve learners ’ perfor -\\nmance in math (T\\x7farning et al., 2019 ). McCarthy and colleagues (2018) Table 3 \\nA Summary of subject areas addressed in AIEd research articles.  \\nSubject Area(s) n Articles \\nEngineering/computer \\nscience/IT/Informatics 14 1. Arpaci (2019) \\n2. Atilola et al. (2014) \\n3. Bahçeci and Gürol (2016) \\n4. Griol et al. (2014) \\n5. K\\x7fose and Arslan (2016) \\n6. K\\x7fose (2017) \\n7. Leony, Munoz-Merino, Pardo, & Kloos \\n(2013) \\n8. Mas-Sanso and Manresa-Yee (2016) \\n9. Moridis and Economides (2009) \\n10. Munawar et al. (2018) \\n11. Samarakou, Fylladitakis, Fruh, \\nHatziapostolou, & Gelengenis (2015) \\n12. Samarakou et al. (2018) \\n13. Xie et al. (2017) \\n14. Xu and Wang (2006) \\nMathematics 8 1. Gulz, Londos, & Haake (2020) \\n2. Kelly et al. (1993) \\n3. Matsuda et al. (2020) \\n4. Shih et al. (2012) \\n5. Tarning, Silvervarg, Gulz, & Haake (2019) \\n6. Walkington & Bernacki (2019) \\n7. Hwang et al. (2020) \\n8. Xie et al. (2017) \\nForeign Language/ESL 4 1. Fryer et al. (2017) \\n2. Wei et al. (2018) \\n3. Xiao and Hu (2019) \\n4. Zheng et al. (2018) \\nSciences 3 1. Chin et al. (2013) \\n2. Chin et al. (2010) \\n3. McLaren, DeLeeuw, & Mayer (2011) \\nBusiness/economics 3 1. Montalvo et al. (2018) \\n2. Rapanta and Walton (2016) \\n3. Xie et al. (2017) \\nCalligraphy 1 Loup-Escande et al. (2017) \\nHistory 1 Ijaz et al. (2017) \\nHealth Assessment 1 Xie et al. (2017) \\nReading 1 McCarthy, Likens, Johnson, Guerrero, & \\nMcNamara (2018) \\nMultiple disciplines 3 1. Dias et al. (2015) \\n2. Xie et al. (2017) \\n3. Cheung et al., 2003  K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n6found that metacognitive prompts provided by an intelligent tutoring \\nsystem did not improve student performance, but practice and action -\\nable feedback were essential in the intelligent tutoring system for \\nimproving reading comprehension. In another study, McLaren and col-\\nleagues (McLaren et al., 2011 ) found that for students with low prior \\nknowledge, a polite web-based tutor led to more learning as compared to \\nthe regular web-based tutor. \\n3.4. Machine learning \\nDespite the wide applications of machine learning, a small number of \\nresearch studies met all criteria for full analyses in this study. This \\nimportant AI technology was effective in assessing the changes of \\nlearning styles in ESL/EFL in multiple grades (Wei et al., 2018 ). In \\nanother study, machine learning algorithms were used to predict un-\\ndergraduate students ’ attitudes toward educational applications of \\ncloud-based mobile computing services by their information manage -\\nment behaviors with 74% accuracy (Arpaci, 2019 ). \\n3.5. Personalized learning systems or environments (PLS/E) \\nPersonalized learning systems or environments (PLS/E) were found \\neffective in facilitating interactions (Xu & Wang, 2006 ) and improving \\ne-learning experiences (Cheung et al., 2003 ; K\\x7fose, 2017 ; K\\x7fose & Arslan, \\n2016 ; Xu & Wang, 2006 ). Turkish researchers, K\\x7fose and Arslan (2016) \\nstudied the effects of PLS, with 110 undergraduate students through two \\nsemesters in computer programming courses. They found the PLS system \\nhelped learners to achieve desirable learning outcomes and reportedly \\nimproved their learning experiences as well. In another study, K\\x7fose \\n(2017) also found that personalized mobile learning, via AI and \\nAugmented Reality (AR), improved learning experiences as well as \\nlearning outcomes in open computer education. A study with over 1300 \\nparticipants in Hong Kong investigated an AI-enhanced e-learning sys-\\ntem called SmartTutor (Cheung et al., 2003 ). And, it was found that \\ncustomized learning materials and resources were well received and \\nboth students and faculty confirmed that they were helpful in the \\nteaching/learning process (Cheung et al., 2003 ). A study with high \\nschool students in USA (Walkington & Bernacki, 2019 ) found that \\nconnecting math to students ’ personal interests that were not \\nschool-related would increase learning in an intelligent tutoring system, \\nand thus highly customized personalization could promote learning and \\nthus may lead to student success. \\n3.6. Visualizations and virtual learning environments (VLE) \\nTogether with the surge of virtual reality (VR) technologies, research \\nhas started exploring the potential benefits of visualizations and VLE \\nwith AI in education. Evidently, students enjoyed the learning experi -\\nence in VLE and reported that it facilitated learning and collaborations \\n(Griol et al., 2014 ). Similarly, teachers also noted that students were \\nbetter engaged in learning (Griol, Molina, & Callejas). A technology \\ncombining both AI and virtual reality (VR) was found effective in \\nimproving the learning experience and engaging the young generation \\nof learners in Australia (Ijaz et al., 2017 ). Undergraduate students \\nlearning with AI and VR also performed better in comprehensions as \\nmeasured in this study (Ijaz et al., 2017 ). A study on a smart glass system \\nalso confirmed that AI technology with visualizations helped both \\nchildren and adults with autism, by serving as a social communication \\naid (Keshav et al., 2017 ). However, supplementary visual feedback in a \\nmixed reality (MR) environment led to a cognitive load for participants \\nwhen learning calligraphy, yet without effect on user experience (Lou-\\np-Escande et al., 2017 ). The inconsistent research results call for im-\\nprovements in this type of AI technology and demand more research on \\nAI visualizations and VLE. 4.Discussions \\n4.1. AI in education: technologies & benefits \\nAs early as 1991, Garito has stressed that AI is changing the tradi-\\ntional role of a teacher (Garito, 1991 ). Lately, more scholars point out \\nthat AI empowers educators with better ways to teaching and learning \\n(Cope, Kalantzis, & Searsmith, 2020). With scalable applications, AI is \\ntransforming educational practices with profound impacts across the \\nworld, including the Global South and in emergent forms of education \\nlike MOOCs, blended learning, flipped classrooms and more (e.g., Al \\nBraiki, Harous, Zaki, & Alnajjar, 2020 ; Reynolds, Reeves, Bonk, & \\nZhang, 2020 ; Roschelle, Lester, & Fusco, 2020 ; Zhang, Bonk, Reeves, & \\nReynolds, 2020 ). \\nA recent review (Zawacki-Richter et al., 2019 ) summarizes an array \\nof AIEd applications for varied purposes, such as learner profiling, \\nperformance prediction, assessment, evaluation, personalization, adap-\\ntive learning and more. Evidently, AI systems can analyze student input \\nand provide corrective feedback instantly (Mirzaeian, Kohzadi, & \\nAzizmohammadi, 2016 ; Roschelle, Lester, & Fusco, 2020 ), generate \\nautomatic scoring and formative assessments (Zhu, Liu, & Lee, 2020 ), \\nand help students with revisions during in the learning process (Lee \\net al., 2019 ). Intelligent tutoring systems can help identify learners ’ \\nstrengths and gaps in their current knowledge base (Zawacki-Richter, \\nMarin, Bond, & Gouverneur, 2019 ). More importantly, intelligent \\nfeedback systems can also measure how people learn, in addition to \\nwhat is learned (Cutumisu, Chin, & Schwartz, 2019 ). Machine learning \\nfor example, can predict at-risk or marginal college students (Chui, \\nFung, Lytras, & Lam, 2020 ) as well as gifted students (Hodges & Mohan, \\n2019 ) with high accuracy, which then empowers educators to intervene \\naccordingly for student successes. \\nAIEd advancement calls for more empirical studies with a particular \\nfocus on AI technologies in real teaching and learning settings (Kabudi \\net al., 2021 ), serving educational needs and purposes. As researchers \\npoint out in a recent literature review, there has been a severe \\ndiscrepancy between the potentials of AIEd and their actual imple -\\nmentations in education (Kabudi et al., 2021 ). To illustrate how AI \\ntechnologies are currently leveraged for various teaching and learning \\npurposes, Fig. 1 highlights some practical examples of AIEd applications \\nfrom the research articles reviewed in this study. It may also serve as a \\nsnapshot of the current practice of AIEd with educational aspirations, \\nwhich in turn may also stimulate more research on AIEd. \\nWith educational goals and objectives in mind, the examples in Fig. 1 \\nshowcase how students and educators may benefit from AI-enhanced \\nlearning systems or experiences. \\n4.2. Practical implications for AIEd \\nWith a wide range of technologies, features and functions, the \\nadvancement of AI brings exciting opportunities to education. To realize \\nits full potential for education, it is critical to bridge the gaps between AI \\ntechnological innovations and its educational applications. Fig. 2 sum-\\nmarizes some of the most widely applied AIEd technologies and their \\nproven or potential benefits for education. For learners, AIEd may \\nfacilitate varied interactions, increase learner engagement, generate \\nadaptive learning materials, offer meta-cognitive prompts, provide \\nenriched learning environments, and improve learning outcomes. For \\neducators and administrators, AIEd may provide predictive models, \\nidentify gifted or at-risk students, monitor the learning progress, create \\npersonalized learning materials, assessments and feedback, and analyze \\nscaled data instantly for evaluation or administrative purposes. AI- \\nenhanced learning environments may improve the LMS for both in-\\nstructors and students through expert systems, generate visual feedback, \\nand enrich the learning experience with visualization and immersive \\ntechnologies. \\nWith highlighted practical takeaways, Fig. 2 can serve in multiple K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n7ways to guide both technological experts that create AI technologies for \\neducation as well as educators and educational researchers, who \\nspearhead AI innovations in educational systems through practice, \\nevaluation and research. AI technology inventers, for instance may note \\nits educational benefits and collaborate with educators to leverage AI \\ntechnologies with specific goals to improve learning and teaching on a \\nlarge scale. Likewise, educators, or educational institutions, may iden-\\ntify appropriate AI technologies from the figure for varied educational \\nneeds or goals, without being overwhelmed by the technical details. \\nAlso highlighted in Fig. 2 are some key challenges in promoting \\nAIEd, such as costs & scalability, ethics & privacy, the lack of actionable \\nguidelines for educators, and limited AI expertise among educators. The \\nfigure may further facilitate meaningful communications amongst \\nstakeholders with different areas of expertise (e.g., technological skills \\nvs. learning theories and pedagogies), from different perspectives (e.g., \\ntechnology advancement, teaching and learning, administrations of \\neducational systems, educational research, etc.) and thus lead to fruitful collaborations in AIEd research, development, implementation and \\nevaluation. \\nRecent research has found that students ’ task engagement and per-\\nformance increased when AI-supported systems also attended to their \\naffective status in addition to cognitive aspects (Hwang et al., 2020 ). The \\nstudy demonstrates the potential of AI in addressing learners ’ affective \\nor emotional needs, which in turn may improve learning. It also suggests \\nthe need for more inclusive designs of AIEd technologies to address \\nstudents ’ varied needs and preferences. \\nRecent reviews on AIEd related research have consistently empha -\\nsized the lack of educational perspectives in AIEd research, development \\nor implementations (Chen et al., 2020 ; Hinojo-Lucena et al., 2019 ; \\nKabudi et al., 2021 ; Tang et al., 2021 , ; Zawacki-Richter et al., 2019 ). \\nThus, to further advance AI technologies for education, perhaps the most \\nimportant initiative is to invite educators and educational researchers to \\nfully participate in the technological innovation process, to proactively \\nseek input from the educational communities, and to integrate \\nFig. 1.Practical Examples of AIEd applications.  K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n8theoretical, conceptual, practical and empirical support from educa -\\ntional literature. \\n4.3. Directions for future research on AIEd \\nThe booming of AI technology in 2016 highlighted with tech com-\\npanies bringing AI home and the famous AlphaGo with an over-\\nwhelming win over a professional world champion in the Go game (Dee \\npmind.com , n. d.). AIEd research has yet to catch up with the rapid \\nadvancement of AI technology to provide evidence-based guidelines and \\nsupport for AI applications in education. Despite the advancement of \\nAIEd technologies, there is still a lack of educational perspectives in \\nAIEd research, as recent literature reviews have stressed (e.g., Chen \\net al., 2020 ; Hinojo-Lucena et al., 2019 ; Zawacki-Richter et al., 2019 ). \\nInterdisciplinary research with educators and educational researchers \\nwill more likely result in feasible practical guidelines and good examples \\nfor fellow educators. In addition, to reach the full potentials of AI in education, collaborative research focusing on AI technology applica -\\ntions that may result in direct or indirect effects on learning outcomes in \\nreal educational settings is particularly vital. \\nResearch also needs to scale up to examine AIEd on the institutional, \\nregional and national levels, and for longer time durations. In addition, \\nemerging methods like educational data mining, text mining, learning \\nanalytics, data visualizations are also imperative to advance AIEd \\nresearch. In particular, emerging educational research methods, such as \\neducational design research (EDR) (McKenney & Reeves, 2018 ), is \\nhighly recommended for research on innovative technologies like AIEd, \\nbecause it empowers educators to incorporate their research inquiries as \\npart of the technology development and implementation cycle in \\nauthentic settings. EDR can be particularly powerful when educators \\nparticipate during the stages of AI technology creation, development or \\nevaluations for educational purposes. \\nAmongst the range of AIEd technologies, some have been studied \\nmore frequently than others. For example, a lot of research focused on \\nFig. 2.Proven and potential educational benefits of AI technologies.  K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n9intelligent tutors or personalized learning systems/environments, while \\nonly a very limited number of research publications examined the effect \\nof chatbot or machine learning in education, as found in this review. \\nThus, future research should cover more AIEd technologies, especially \\nthose have not received much attention in research. \\nAs emerging technologies such as VR, AR or MR being integrated \\nwith AI for various learning supports (e.g., K\\x7fose, 2017 ; Ijaz et al., 2017 ; \\nLoup-Escande et al., 2017 ), it is also vital to conduct research through \\ninterdisciplinary and transdisciplinary collaborations as researchers \\nhave suggested (Zhang & Aslan, 2020 ) for successful AIEd development, \\nimplementation and research. \\n4.4. AIEd ethics & privacy \\nAs educational systems experiment with AI in traditional classrooms, \\nonline or via mobile learning management systems (e.g., Roschelle et al., \\n2020 ; Zhang et al., 2020 ), it is imperative to balance efficiency, benefits, \\nsecurity and many more (Hagendorff, 2019 ; Etzioni and Etzioni, 2017 ; \\nAbrams, Abrams, Cullen, & Goldstein, 2019 ). About 20 years ago, \\nscholars have already started conversations about AIEd ethics (Aiken \\nand Epstein, 2000 ), and giant tech companies are forming their own AI \\nethics panels (Lee, 2019 ). But new educational AI technology requires \\nspecific AI ethics for education. Likewise, privacy is a critical issue yet to \\nbe carefully addressed in AIEd. A recent semi-systematic evaluation of \\n22 AI ethics guidelines has revealed that current guidelines have severe \\nflaws and a range of AI ethics that are critical for AI research, devel -\\nopment and implementation are actually missing or overlooked in such \\nguidelines (Hagendroff, 2020 ). The critical and urgent needs for AIEd \\nethics also call for collaborative efforts from all stakeholders, including \\neducators, administrators, researchers, technology innovators and all \\nsocietal members. \\n4.5. Limitation of this review \\nAs typical with any search engines or strategies, a methodological \\nlimitation of this review is tied to the selection of source database and \\njournals, as well as the specific identifiers used in the search efforts, such \\nas “artificial intelligence ” or “AI”. Research publications that do not \\ninclude AI or “artificial intelligence ” as a descriptor in its title, abstract, \\nsummary or keyword list, as well as those not indexed in the source \\ndatabase thus can be excluded in this review. While conference pro-\\nceedings may include more recent or even ongoing research projects, \\nconsidering their very different selection criteria and review processes, \\nconference proceedings are also excluded in this review. Thus, this re-\\nview is limited in its scope. \\n4.6. Suggestions for future reviews \\nFuture reviews may extend the search scope to include other repu-\\ntable databases, specialized journals, or peer-reviewed conference pro-\\nceedings. Additional key words, such as specific AI technology (e.g., \\nmachine learning) or its educational applications may retrieve more \\nrelevant publications. However, future reviews should also be mindful \\nof the search results, as sometimes publications on other topics, such as \\ngame-based learning also appear in the search results (e.g., Yoon & Kim, \\n2015 ), even though they are not AI-related. Another important consid -\\neration is to carefully differentiate AIEd studies without human subjects \\n(e.g., Liu, Rus, & Liu, 2017 ) or otherwise focus on system development \\nor model testing from research with teachers, students or other human \\nparticipants involved, as such in this review. \\nAs an interdisciplinary field, AIEd has overlaps with a few emerging \\nsub-fields, such as educational data mining, learning analytics and \\ncomputer-based education (Chen et al., 2020 ; Romero & Ventura, 2013 \\n). Future reviews may also choose to alter the scope by focusing on \\nspecific AI technologies or their applications in education, or a sub-field \\nof AIEd, or applying different search strategies and selection criteria, or exploring conference proceedings in addition to peer-reviewed journal \\narticles. Given the integrations of emerging technologies like VR, AR and \\nMR (Zhang & Aslan, 2020 ) and AI (e.g., Keshav et al., 2017 ; Ijaz et al., \\n2017 ), future reviews may also explore both of them together. \\n5.Conclusion \\nAI technology is rapidly advancing and its application in education is \\nexpected to grow rapidly in the near future. In the USA, for example, \\neducation sectors are predicted with an approximate 48% of growth in \\nAI market in the near future, from 2018 to 2022 (BusinessWire.com , \\n2018). AI technologies have great potentials in education, in particular, \\nto increase access to learning opportunities, to scale up personally \\ncustomized learning experiences, and to optimize methods and strate -\\ngies for desired learning outcomes (Reynolds et al., 2020 ; Roschelle \\net al., 2020 ; Zawacki-Richter et al., 2019 ). Some scholars have publicly \\nproposed to replace teachers or certain roles of teachers with AI robots \\n((Edwards & Cheok, 2018 ). While their article, Why Not Robot Teachers: \\nArtificial Intelligence for Addressing Teacher Shortage (Edwards & Cheok, \\n2018 ) may cause some uneasiness, discomfort or even fear for many \\npeople; it is gradually becoming a reality. In addition to the intelligent \\ntutors and teachable agents in online or blended learning as reported in \\nAIEd studies (e.g., Cheung et al., 2003 ; Chin et al., 2010 , 2013 ; Cung \\net al., 2019 ; K\\x7fose & Arslan, 2016 ; Mclaren et al., 2011 ), the first AI \\nteaching assistant robots, named Happy Numbers have been working in \\nthe classrooms in USA already. \\nAs Finn has emphasized back in the 1960s, technology is “more than \\nan invention – more than machines. It is a process and a way of thinking ” \\n(Fin, 1960 , p. 6). The integration of AIEd calls for critical awareness of \\nAI ethics and requires interdisciplinary and transdisciplinary collabo -\\nrations in large-scaled, longitudinal research. The growing AIEd \\nresearch would result in more practical guidelines and examples for \\neducators, together with new ways of teaching and learning. Despite \\nskepticism, doubts or fears, AIEd continues to open up new possibilities \\nfor innovations in education. \\nStatements on open data and ethics \\nThis literature review article collected all data (i.e., eligible publi -\\ncations) from selected databases from the internet. The datasets created \\nfor the current study (the bibliography of included studies) are available \\nfrom the corresponding author upon request. \\nAs the research does not involve human participants, there is no need \\nto seek ethical approval from a research review committee in the au-\\nthors ’ affiliations. \\nDeclaration of competing interest \\nNone. \\nReferences \\nAbram, M., Abram, J., Cullen, P., & Goldstein, L. (2019). Artificial intelligence, ethics, \\nand enhanced data stewardship. IEEE Security & Privacy, 17(2), 17–30. https://doi- \\norg.proxy.lib.wayne.edu/10.1109/MSEC.2018.2888778 . \\nAiken, R. M., & Epstein, R. G. (2000). Ethical guidelines for AI in education: Starting a \\nconversation. International Journal of Artificial Intelligence in Education, 11, 163–176. \\nAl Braiki, B, Harous, S., Zaki, N., & Alnajjar, F. (2020). Artificial intelligence in education \\nand assessment methods. Bulletin of Electrical Engineering and Informatics, 9(5), \\n1998 –2007 . \\nAndriessen, J., & Sandberg, J. (1999). Where is education heading and how about AI. \\nInternational Journal of Artificial Intelligence in Education, 10(2), 130–150. \\nArpaci, I. (2019). A hybrid modeling approach for predicting the educational use of \\nmobile cloud computing services in higher education. Computers in Human Behavior, \\n90, 181–187. https://doi.org/10.1016/j.chb.2018.09.005 . \\nAtilola, O., Valentine, S., Kim, H.-H., Turner, D., Mctigue, E., Hammond, T., et al. (2014). \\nMechanix: A natural sketch interface tool for teaching truss analysis and free-body \\ndiagrams. Artificial Intelligence for Engineering Design, Analysis and Manufacturing, 28 \\n(2), 169–192. https://doi.org/10.1017/s0890060414000079 . K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n10Bahçeci, F., & Gürol, M. (2016). The effect of individualized instruction system on the \\nacademic achievement scores of students. Educational Research International , 1–9. \\nhttps://doi.org/10.1155/2016/7392125 , 2016. \\nBates, T., Cobo, C., Mari ~no, O., & Wheeler, S. (2020). Can artificial intelligence transform \\nhigher education? International Journal of Educational Technology in Higher Education, \\n17(42). https://doi.org/10.1186/s41239-020-00218-x . \\nBeck, J., Stern, M., & Haugsjaa, E. (1996). Applications of AI in education. Crossroads, 3 \\n(1), 11–15. \\nBurleson, W., & Lewis, A. (2016). Optimists ’ creed: Brave new cyberlearning, evolving \\nutopias (Circa 2041). International Journal of Artificial Intelligence in Education, 26(2), \\n796–808. https://doi.org/10.1007/s40593-016-0096-x . \\nChen, X., Xie, H., Zou, D., & Hwang, G. J. (2020). Application and theory gaps during the \\nrise of artificial intelligence in education. Computers and Education: Artificial \\nIntelligence, 1, 100002 . \\nCheung, B., Hui, L., Zhang, J., & Yiu, S. (2003). SmartTutor: An intelligent tutoring \\nsystem in web-based adult education. Journal of Systems and Software, 68(1), 11–25. \\nhttps://doi.org/10.1016/s0164-1212(02)00133-4 . \\nChin, D. B., Dohmen, I. M., Cheng, B. H., Oppezzo, M. A., Chase, C. C., & Schwartz, D. L. \\n(2010). Preparing students for future learning with Teachable Agents. Educational \\nTechnology Research & Development, 58(6), 649–669. https://doi.org/10.1007/ \\ns11423-010-9154-5 . \\nChin, D. B., Dohmen, I. M., & Schwartz, D. L. (2013). Young children can learn scientific \\nreasoning with teachable agents. IEEE Transactions on Learning Technologies, 6(3), \\n248–257. https://doi.org/10.1109/tlt.2013.24 . \\nChui, K. T., Fung, D. C. L., Lytras, M. D., & Lam, T. M. (2020). Predicting at-risk \\nuniversity students in a virtual learning environment via a machine learning \\nalgorithm. Computers in Human Behavior, 107, 105584. https://doi.org/10.1016/j. \\nchb.2018.06.032 . \\nClancey, W. J., Bennett, J. S., & Cohen, P. R. (1979). Applications-oriented AI research: \\nEducation (No. STAN-CS-79-749). Stanford university, department of computer science . \\nCung, B., Xu, D., Eichhorn, S., & Warschauer, M. (2019). Getting academically \\nunderprepared students ready through college developmental education: Does the \\ncourse delivery format matter? American Journal of Distance Education, 33(3), \\n178–194. \\nCutumisu, M., Chin, D. B., & Schwartz, D. L. (2019). A digital game-based assessment of \\nmiddle-school and college students ’ choices to seek critical feedback and to revise. \\nBritish Journal of Educational Technology, 50(6), 2977 –3003. https://doi.org/ \\n10.1111/bjet.12796 . \\nDias, S. B., Hadjileontiadou, S. J., Hadjileontiadis, L. J., & Diniz, J. A. (2015). Fuzzy \\ncognitive mapping of LMS users ’ Quality of interaction within higher education \\nblended-learning environment. Expert Systems with Applications, 42(21), 7399 –7423. \\nhttps://doi.org/10.1016/j.eswa.2015.05.048 . \\nEdwards, B. I., & Cheok, A. D. (2018). Why not robot teachers: Artificial intelligence for \\naddressing teacher shortage. Applied Artificial Intelligence, 32(4), 345–360. \\nEtzioni, A., & Etzioni, O. (2017). Incorporating ethics into artificial intelligence. The \\nJournal of Ethics, 21(4), 403–418. https://doi.org/10.1007/s10892-017-9252-2 . \\nFinn, J. (1960). Automation and education: III. Technology and the instructional process. \\nAudio Visual Communication Review, 8(1), 5–26. \\nFlogie, A., & Abersek, B. (2015). Transdisciplinary approach of science, technology, \\nengineering and mathematics education. Journal of Baltic Science Education, 14(6), \\n779–790. \\nFryer, L. K., Ainley, M., Thompson, A., Gibson, A., & Sherlock, Z. (2017). Stimulating and \\nsustaining interest in a language course: An experimental comparison of Chatbot and \\nHuman task partners. Computers in Human Behavior, 75, 461–468. https://doi.org/ \\n10.1016/j.chb.2017.05.045 . \\nGao, F., Luo, T., & Zhang, K. (2012). Tweeting for learning: A critical analysis of current \\nresearch on microblogging in education published in 2008-2011. British Journal of \\nEducational Technology, 43(5), 783–801. \\nGarito, M. A. (1991). Artificial intelligence in education: Evolution of the teaching- \\nlearning relationship. British Journal of Educational Technology, 22(1), 41–47. \\nhttps://doi.org/10.1111/j.1467-8535.1991.tb00050.x . \\nGonzalez, A. J., Hollister, J. R., Demara, R. F., Leigh, J., Lanman, B., Lee, S.-Y., et al. \\n(2017). AI in informal science education: Bringing Turing back to life to perform the \\nTuring test. International Journal of Artificial Intelligence in Education, 27(2), 353–384. \\nhttps://doi.org/10.1007/s40593-017-0144-1 . \\nGriol, D., Molina, J. M., & Callejas, Z. (2014). An approach to develop intelligent learning \\nenvironments by means of immersive virtual worlds. Journal of Ambient Intelligence \\nand Smart Environments, 6(2), 237–255. \\nGulz, A., Londos, L., & Haake, M. (2020). Preschoolers ’ understanding of a teachable \\nagent-based game in early mathematics as reflected in their gaze behaviors –an \\nexperimental study. International Journal of Artificial Intelligence in Education , 1–36. \\nHagendorff, T. (2019). From privacy to anti-discrimination in times of machine learning. \\nEthics and Information Technology, 1–13. https://doi-org.proxy.lib.wayne.edu/10.1 \\n007/s10676-019-09510-5 . \\nHagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. Minds and \\nMachines , 99–120. https://doi.org/10.1007/s11023-020-09517-8 . \\nHinojo-Lucena, F. J., Aznar-Díaz, I., C˘aceres-Reche, M. P., & Romero-Rodríguez, J. M. \\n(2019). Artificial intelligence in higher education: A bibliometric study on its impact \\nin the scientific literature. Education Sciences, 9(1), 51. \\nHodges, J., & Mohan, S. (2019). Machine learning in gifted education: A demonstration \\nusing neural networks. Gifted Child Quarterly, 63(4), 243–252. \\nHung, J., & Zhang, K. (2012). Examining mobile learning trends 2003-2008: A \\ncategorical meta-trend analysis using text mining techniques. Journal of Computing in \\nHigher Education, 24(1), 1–17. \\nHwang, G., Sung, H., Chang, S., & Huang, X. (2020). A fuzzy expert system-based \\nadaptive learning approach to improving students ’ learning performances by considering affective and cognitive factors. Computers and Education: Artificial \\nIntelligence, 1(1), 100003. https://doi.org/10.1016/j.caeai.2020.100003 . \\nIjaz, K., Bogdanovych, A., & Trescak, T. (2017). Virtual worlds vs books and videos in \\nhistory education. Interactive Learning Environments, 25(7), 904–929. https://doi. \\norg/10.1080/10494820.2016.1225099 . \\nKabudi, T., Pappas, I., & Olsen, D. H. (2021). AI-enabled adaptive learning systems: A \\nsystematic mapping of the literature. In Computers and education: Artificial intelligence \\n(p. 100017) . \\nKaplan, A., & Haenlein, M. (2019). Siri, siri, in my hand: Who ’s the fairest in the land? \\nOn the interpretations, illustrations, and implications of artificial intelligence. \\nBusiness Horizons, 62, 15–25. https://doi.org/10.1016/j.bushor.2018.08.004 . \\nKelly, A. E., Sleeman, D., & Gilhooly, K. J. (1993). Artificial intelligence in education: \\nUsing state space search and heuristics in mathematics instruction. International \\nJournal of Man-Machine Studies, 38(4), 725–746. https://doi.org/10.1006/ \\nimms.1993.1034 . \\nKeshav, N. U., Salisbury, J. P., Vahabzadeh, A., & Sahin, N. T. (2017). Social \\ncommunication coaching smartglasses: Well tolerated in a diverse sample of children \\nand adults with autism. JMIR MHealth and UHealth, 5(9). https://doi.org/10.2196/ \\nmhealth.8534 . \\nK\\x7fose, U. (2017). An augmented-reality-based intelligent mobile application for open \\ncomputer education. Mobile Technologies and Augmented Reality in Open Education \\nAdvances in Educational Technologies and Instructional Design , 154–174. https://doi. \\norg/10.4018/978-1-5225-2110-5.ch008 . \\nK\\x7fose, U., & Arslan, A. (2016). Intelligent e-learning system for improving students ’ \\nacademic achievements in computer programming courses. International Journal of \\nEngineering Education, 32, 185–198. \\nKurzweil, R. (1985). What is artificial intelligence anyway? As the techniques of \\ncomputing grow more sophisticated, machines are beginning to appear intelligent - \\nbut can they actually think? American Scientist, 73(3), 258–264. \\nLee, D. (2019, March 26). Google announces AI ethics panel. Retrieved from. https \\n://www.bbc.com/news/technology-47714921 . \\nLee, H. S., Pallant, A., Pryputniewicz, S., Lord, T., Mulholland, M., & Liu, O. L. (2019). \\nAutomated text scoring and real-time adjustable feedback: Supporting revision of \\nscientific arguments involving uncertainty. Science Education, 103(3), 590–622. \\nhttps://doi.org/10.1002/sce.21504 . \\nLegg, S., & Hutter, M. (2007). A collection of definitions of intelligence. Frontiers in \\nArtificial Intelligence and Applications, 157, 17–24. \\nLeony, D., Mu~noz-Merino, P. J., Pardo, A., & Kloos, C. D. (2013). Provision of awareness \\nof learners ’ emotions through visualizations in a computer interaction-based \\nenvironment. Expert Systems with Applications, 40(13), 5093 –5100. https://doi.org/ \\n10.1016/j.eswa.2013.03.030 . \\nLiu, M., Rus, V., & Liu, L. (2017). Automatic Chinese factual question generation. IEEE \\nTransactions on Learning Technologies, 10(2), 194–204. https://doi.org/10.1109/ \\ntlt.2016.2565477 . \\nLoup-Escande, E., Frenoy, R., Poplimont, G., Thouvenin, I., Gapenne, O., & \\nMegalakaki, O. (2017). Contributions of mixed reality in a calligraphy learning task: \\nEffects of supplementary visual feedback and expertise on cognitive load, user \\nexperience and gestural performance. Computers in Human Behavior, 75, 42–49. \\nhttps://doi.org/10.1016/j.chb.2017.05.006 . \\nMas-Sanso, R., & Manresa-Yee, C. (2016). Gamifying an artificial intelligence course in \\nengineering education. International Journal of Engineering Education, 32, 513–520. \\nMatsuda, N., Weng, W., & Wall, N. (2020). The effect of metacognitive scaffolding for \\nlearning by teaching a teachable agent. International Journal of Artificial Intelligence in \\nEducation , 1–37. \\nMcCarthy, K. S., Likens, A. D., Johnson, A. M., Guerrero, T. A., & McNamara, D. S. \\n(2018). Metacognitive overload!: Positive and negative effects of metacognitive \\nprompts in an intelligent tutoring system.  International Journal of Artificial \\nIntelligence in Education, 28(3), 420–438. \\nMcKenney, S., & Reeves, T. C. (2018). Conducting educational design research . NYC: \\nRoutledge .  \\nMclaren, B. M., Deleeuw, K. E., & Mayer, R. E. (2011). Polite web-based intelligent \\ntutors: Can they improve learning in classrooms? Computers & Education, 56(3), \\n574–584. https://doi.org/10.1016/j.compedu.2010.09.019 . \\nMirzaeian, V. R., Kohzadi, H., & Azizmohammadi, F. (2016). Learning Persian grammar \\nwith the aid of an intelligent feedback generator. Engineering Applications of Artificial \\nIntelligence, 49, 167–175. https://doi.org/10.1016/j.engappai.2015.09.012 . \\nMogil, S. J., Simmonds, K., & Simmonds, J. M. (2009). Pain research from 1975 to 2007: \\nA categorical and bibliometric meta-tend analysis of every research paper published \\nin the journal, pain. Pain, 142, 48–58. \\nMontalvo, S., Palomo, J., & de la Orden, C. (2018). Building an educational platform \\nusing nlp: A case study in teaching finance. Journal of Universal Computer Science, 24 \\n(10), 1403 –1423 . \\nMoridis, C. N., & Economides, A. A. (2009). Prediction of student ’s mood during an \\nonline test using formula-based and neural network-based method. Computers & \\nEducation, 53(3), 644–652. https://doi.org/10.1016/j.compedu.2009.04.002 . \\nMunawar, S., Toor, S. K., Aslam, M., & Hamid, M. (2018). Move to smart learning \\nenvironment: Exploratory research of challenges in computer laboratory and design \\nintelligent virtual laboratory for elearning technology. Eurasia Journal of \\nMathematics, Science and Technology Education, 14(5), 1645 –1662. https://doi.org/ \\n10.29333/ejmste/85036 . \\nOkubo, Y. (1997). Bibliometric indicators and analysis of research systems: Methods and \\nexamples, STI working papers 1997/1 . Paris: OECD Science .  \\nPeker, M., Guruler, H., Sen, B., & Istanbullu, A. (2017). A new fuzzy logic based career \\nguidance system: WEB-CGS. Tehnicki Vjesnik - Technical Gazette, 24(6). https://doi. \\norg/10.17559/tv-20151105201325 . K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\nComputers and Education: Artificial Intelligence 2 (2021) 100025\\n11Rapanta, C., & Walton, D. (2016). The use of argument maps as an assessment tool in \\nhigher education. International Journal of Educational Research, 79, 211–221. https:// \\ndoi.org/10.1016/j.ijer.2016.03.002 . \\nReynolds, T., Reeves, T., Bonk, C., & Zhang, K. (2020). MOOCs and open education: \\nFuture opportunities. In K. Zhang, C. J. Bonk, T. Reeves, & T. Reynolds (Eds.), \\nMOOCs and open education in the Global South: Challenges, successes, and opportunities \\n(pp. 342–350). NY: Routledge, 2020 . \\nRomero, C., & Ventura, S. (2013). In Data mining in education. Wiley interdisciplinary \\nreviews: Data mining and knowledge discovery (Vol. 3, pp. 12–27), 1. \\nRoschelle, J., Lester, J., & Fusco, J. (Eds.). (2020). AI and the future of learning: Expert \\npanel report [Report]. Digital Promise . https://circls.org/reports/ai-report . \\nSamarakou, M., Fylladitakis, E. D., Früh, W. G., Hatziapostolou, A., & Gelegenis, J. J. \\n(2015). An advanced elearning environment developed for engineering learners. \\nInternational Journal of Emerging Technologies in Learning (IJET), 10(3), 22–33. \\nhttps://doi.org/10.3991/ijet.v10i3.4484 . \\nSamarakou, M., Tsaganou, G., & Papadakis, A. (2018). An e-learning system for \\nextracting text comprehension and learning style characteristics. Educational \\nTechnology & Society, 21(1), 126–136. \\nSantos, F. R. D., & Notargiacomo, P. (2018). Intelligent educational assistant based on \\nmultiagent system and context-aware computing. International Journal of Advanced \\nComputer Science and Applications, 9(4), 236–243. https://doi.org/10.14569/ \\nijacsa.2018.090437 . \\nShih, B.-Y., Chang, C.-J., Chen, Y.-H., Chen, C.-Y., & Liang, Y.-D. (2012). Lego NXT \\ninformation on test dimensionality using Kolb ’s innovative learning cycle. Natural \\nHazards, 64(2), 1527 –1548. https://doi.org/10.1007/s11069-012-0318-y . \\nSimmons, A. B., & Chappell, S. G. (1988). Artificial intelligence-definition and practice. \\nIEEE Journal of Oceanic Engineering, 13(2), 14–42. https://doi.org/10.1109/48.551 . \\nTang, K. Y., Chang, C. Y., & Hwang, G. J. (2021). Trends in artificial intelligence- \\nsupported e-learning: A systematic review and co-citation network analysis \\n(1998 –2019). Interactive learning environments , 1–19. \\nT\\x7farning, B., Silvervarg, A., Gulz, A., & Haake, M. (2019). Instructing a teachable agent \\nwith low or high self-efficacy –does similarity attract? International Journal of \\nArtificial Intelligence in Education, 29(1), 89–121. \\nThelwall, M. (2008). Bibliometrics to webometrics. Journal of Information Science, 34(4), \\n605–621. \\nWalkington, C., & Bernacki, M. L. (2019). Personalizing algebra to students ’ individual \\ninterests in an intelligent tutoring system: Moderators of impact. International Journal \\nof Artificial Intelligence in Education, 29(1), 58–88. \\nWei, Y., Yang, Q., Chen, J., & Hu, J. (2018). The exploration of a machine learning \\napproach for the assessment of learning styles changes. Mechatronic Systems and \\nControl (Formerly Control and Intelligent Systems), 46(3), 121–126. https://doi.org/ \\n10.2316/journal.201.2018.3.201-2979 . Xiao, Y., & Hu, J. (2019). Assessment of optimal pedagogical factors for canadian esl \\nlearners ’ reading literacy through artificial intelligence algorithms. International \\nJournal of English Linguistics, 9(4), 1–14. https://doi.org/10.5539/ijel.v9n4p1 . \\nXie, T., Zheng, Q., Zhang, W., & Qu, H. (2017). Modeling and predicting the active video- \\nviewing time in a large-scale e-learning system. IEEE Access, 5, 11490 –11504. \\nhttps://doi.org/10.1109/access.2017.2717858 . \\nXu, D., & Wang, H. (2006). Intelligent agent supported personalization for virtual \\nlearning environments. Decision Support Systems, 42(2), 825–843. https://doi.org/ \\n10.1016/j.dss.2005.05.033 . \\nYoon, D.-M., & Kim, K.-J. (2015). Challenges and opportunities in game artificial \\nintelligence education using angry birds. IEEE Access, 3, 793–804. https://doi.org/ \\n10.1109/access.2015.2442680 . \\nZawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review \\nof research on artificial intelligence applications in higher education – where are the \\neducators? International Journal of Educational Technology in Higher Education, 16(1). \\nhttps://doi.org/10.1186/s41239-019-0171-0 . \\nZdenek, S. (2003). Artificial intelligence as a discursive practice: The case of embodied \\nsoftware agent systems. AI & Society, 17(3–4), 340–363. https://doi.org/10.1007/ \\ns00146-003-0284-8 . \\nZhang, K., & Aslan, A. B. (2020). Preparing industry-ready engineers with virtual reality: \\nRecent research and future directions. International Journal of Smart Technology and \\nLearning, 2(2–3), 136–150. https://doi.org/10.1504/IJSMARTTL.2020.112130 . \\nZhang, K., Bonk, C., Reeves, T., & Reynolds, T. (2020). MOOCs and open education in the \\nGlobal South: Successes and challenges. In K. Zhang, C. J. Bonk, T. Reeves, & \\nT. Reynolds (Eds.), MOOCs and open education in the Global South: Challenges, \\nsuccesses, and opportunities (pp. 1–14). NY: Routledge, 2020 . \\nZheng, J., Zhang, Q., Xu, S., Peng, H., & Wu, Q. (2018). Cognition-based context-aware \\ncloud computing for intelligent robotic systems in mobile education. IEEE Access, 6, \\n49103 –49111. https://doi.org/10.1109/ACCESS.2018.286788 . \\nZhu, M., Liu, O. L., & Lee, H.-S. (2020). The effect of automated feedback on revision \\nbehavior and learning gains in formative assessment of scientific argument writing. \\nComputers & Education, 143, 103668. https://doi.org/10.1016/j. \\ncompedu.2019.103668 . \\nKe Zhang is Professor in Learning Design and Technology Program at Wayne State Uni-\\nversity in Detroit, Michigan, USA. Inquiries are welcome by email: bb2145@wayne.edu \\nAyse Begum Aslan is a Project Management and Grant Support Consultant at Enga-\\nge@EMU (Eastern Michigan University) in Ypsilanti, Michigan, USA. Dr. Aslan may be \\nreached by email: aaydinol@emich.edu K. Zhang and A.B. Aslan                                                                                                                                                                                                                      \\n'}, {'document_name': 'Complexity - 2021 - Zhai - A Review of Artificial Intelligence  AI  in Education from 2010 to 2020.pdf', 'file_path': '../data\\\\Folder1\\\\Complexity - 2021 - Zhai - A Review of Artificial Intelligence  AI  in Education from 2010 to 2020.pdf', 'content': \"Review Article\\nA Review of Artificial Intelligence (AI) in Education from\\n2010 to 2020\\nXuesong Zhai\\n ,1Xiaoyan Chu\\n ,1Ching Sing Chai\\n ,2Morris Siu Yung Jong\\n ,2\\nAndreja Istenic\\n ,3,4,5Michael Spector\\n ,6Jia-Bao Liu\\n ,7Jing Yuan,8and Yan Li\\n1\\n1Zhejiang University, Hangzhou 310058, China\\n2Chinese University of Hong Kong, Hong Kong 999077, Hong Kong\\n3University of Primorska, Faculty of Education, Koper 6000, Slovenia\\n4University of Ljubljana, Faculty of Civil and Geodetic Engineering, Ljubljana 1000, Slovenia\\n5Federal University of Kazan, Institute of Psychology and Education, Kazan 420008, Russia\\n6University of North Texas, Denton 76207, USA\\n7Anhui Jianzhu University, Hefei 230601, China\\n8Anhui Xinhua University, Hefei 230088, China\\nCorrespondence should be addressed to Yan Li; yanli@zju.edu.cn\\nReceived 27 August 2020; Revised 18 January 2021; Accepted 2 April 2021; Published 20 April 2021\\nAcademic\\nEditor: Ning Cai\\nCopyright ©2021XuesongZhaietal.*isisanopenaccessarticledistributedundertheCreativeCommonsAttributionLicense,\\nwhich permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\\n*is study provided a content analysis of studies aiming to disclose how artiﬁcial intelligence (AI) has been applied to the education\\nsectorandexplorethepotentialresearchtrendsandchallengesofAIineducation.Atotalof100papersincluding63empiricalpapers(74\\nstudies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index\\ndatabase from 2010 to 2020. *e content analysis showed that the research questions could be classiﬁed into development layer\\n(classiﬁcation, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and\\nintegration layer (aﬀection computing, role-playing, immersive learning, and gamiﬁcation). Moreover, four research trends, including\\nInternetof*ings,swarmintelligence,deeplearning,andneuroscience,aswellasanassessmentofAIineducation,weresuggestedfor\\nfurtherinvestigation.However,wealsoproposedthechallengesineducationmaybecausedbyAIwithregardtoinappropriateuseofAI\\ntechniques, changingrolesofteachersandstudents,as wellas socialandethicalissues.*eresultsprovideinsightsintoanoverviewof\\nthe AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising\\nchannel for educators and AI engineers to carry out further collaborative research.\\n1.Introduction\\n*e emergence of big data, cloud computing, artiﬁcial\\nneural networks, and machine learning has enabled en-gineers to create a machine that can simulate humanintelligence. Building on these technologies, this study\\nrefers to machines that are able to perceive, recognize,\\nlearn, react, and solve problems as artiﬁcial intelligence(AI) [1, 2]. Inevitably, such smart technologies will rev-olutionizetheworkplacesofthefuture[3].*us,whileAIcaninteractandhelphumansperformathigherlevels,itisemerging as the next disruptive innovation [4]. AI iscurrentlyviewedbymanyasadriverthatisintegraltothefourthindustrialrevolution,anditmaytriggerthefourthrevolutionineducation.LearningaboutAIhasalsobeguntobepartofschoolcurriculum[5,6].However,justastheemergenceoftelevisionandcomputerswasoncetoutedtobe game changers of education, they have been shown toin fact enhance access to information without substan-\\ntially changing the core educational practices. Nonethe-\\nless, educators are obliged to review current AIcapabilities and identify possible pathways to optimizelearning. Given the increasing attention, it is timely toreview recent AI research in education to provide edu-cators with an updated understanding of the ﬁeld as apreparation to possible changes.Hindawi\\nComplexity\\nVolume 2021, Article ID 8812542, 18 pages\\nhttps://doi.org/10.1155/2021/8812542\\nAI has been increasingly propagated as having strategic\\nvalue for education [7]. Loeckx [8] suggested that AI could\\nbeaneﬀectivelearningtoolthatlessenstheburdensofbothteachers and students and oﬀers eﬀective learning experi-ences for students. Coupled with current education reformssuch as the digitalization of educational resources, gamiﬁ-\\ncation, and personalized learning experiences, there are\\nmany opportunities for the development of AI applicationsin education. For example, the modelling potential of AItechniques has been exploited systematically to developreactive and adaptive tutorials for the construction of in-dividualizedlearningenvironmentsascompensationfortheshortage of teachers through the use of intelligent tutoringsystem (ITS) [10]. ITSs provide personalized learning ex-perience in four main ways: monitoring student’s input,delivering appropriate tasks, providing eﬀective feedback,and applying interfaces for human-computer communica-\\ntion [7]. Whenmore ITSsare created for moresubjects and\\ntopics, it is likely to change the role of teachers, and hence,schooling may need to be reconceptualized. *ere existmany concerns and worries among teachers on if AIchallenges their jobs. At the same time, such questions aswhat is being learned and how AI is being used are beingdiscussed currently by researchers as well as by educationalpractitioners. Some researchers wondered whether ad-vancements in AI would challenge or even replace teacherssincemanyotherjobsarebeingreplacedbyautomation[11].*ere is an emerging recognition that teachers’ professionalrolesneedtobeadjustedasAIadvancesandthiswilltrigger\\nnew organizational forms [12]. Emerging challenges also\\nincluded students’ attitudes towards these changes [13]. Tosome extent, students as digital citizens are able to leverageAItoimprovelearningoutcomes.Nonetheless,theymayfailto use suitable AI techniques appropriately for a speciﬁclearning context, which would result in negative attitudestowards learning [14].\\nTo summarize, this research involves a review of the\\nstudies of AI in education. Previous studies have includedthree essential perspectives of AI in knowledge processing:(a)knowledgerepresentation,(b)knowledgeobtaining,and\\n(c) knowledge derivation [3]; this review will focus on AI\\ntechniques and tools that have been integrated into edu-cation recently after the proliferation of AI. *e “ﬁrstgeneration”ofAIcouldsupporthumanintellectualworkbyapplying rule-based expert knowledge, and the “secondgeneration” may ﬁnd the optimal solution by statistical/search model, while the “third generation” will dramaticallyimproverecognitionperformancebasedonthebrainmodel.*is review focuses on articles published in the period from2010to2020fromtheWebofScience,asthatrepresentstheperiodwhenthesecondandthirdgenerationofAIbeganto\\nmake headways into education. *e research questions that\\nguided this review are as follows:\\n(1) What is the overall state of AI in education? Which\\nresearch topics and research designs related to AI ineducation are evident from 2010 to 2020?\\n(2) What are the trends in published studies in terms of\\nAI in education?(3) What are the challenges generated from the current\\nresearch of AI in education?\\n2.Method\\n*isstudyisasystematicliteraturereview.*eobjectivesofthe review were to analyze and interpret ﬁndings based onpredeﬁnedresearchquestions(seeabove)andcriteriawhichserve to point out future directions [15]. *e predeﬁnedresearch foci as shown in Table 1 are research purpose,\\nlearning subject, educational level, research approach, and\\neﬀects. *e review was conducted in three stages: planning,performing, and reporting the systematic review.\\n2.1.PlanningtheReview. AspreviousreviewsaboutAIwere\\nconducted in the physical sciences [16, 17], the study aimed\\nto conduct a review in the ﬁeld of the social sciences.\\n*e Web of Science database and the Social Science\\nCitation Index (SSCI) journals were selected for the searchfor desired articles published from 2010 to 2020. Articlespublished in the SSCI database are generally considered ashigh-quality publication among education researchers. *ekeyword employed was “artiﬁcial intelligence,” and thesubject area was reﬁned to “education and educational re-search”. *is process yielded 142 articles including 121 re-search articles, 10reviewpapers, oneinterviewpaper,and 5book reviews. *e selected articles include both analyticstudies(primarilyqualitativeresearch)andempiricalstudies(primarily quantitative research).\\n2.2. Performing the Review. Following Wu et al. [18], this\\nstudywasconductedintwosteps:identiﬁcationandcoding.\\nIn the ﬁrst step, an article was selected to the potential poolwhen it qualiﬁed for either of two criteria: (a) the researchinvolved a speciﬁc AI technique as an intervention inassisting learning or teaching and (b) it provided empiricalevidenceorin-depthanalysis.Asalreadynoted,onlyarticles\\nindexed in SSCI were considered. It should be noted that\\nstudies that focused on the development processes of AIwithout educational implications or only adopted AI as alearning subject without the employment of AI were ex-cluded from this review. Second, as for the analytic studies,only studies that discussed the eﬀect of AI techniques oneducation were included. Each full text of all the identiﬁedpapers was read and screened individually by three-panelmemberswithdoctoraldegreesorprofessorshipsintheﬁeldof learning technology. Studies that did not ﬁt clearly withthe criteria were brought up for panel discussion. *e\\nscreening process yielded 100 articles out of the original set\\nof 121.\\nIn the second step, all the authors discussed thematic\\nanalysisprinciplesandestablishedacodingschemeintermsofhowAIwasusedineducation.Twomaincategorieswereinvestigated: research questions and technology adoption.Firstly, with regard to research questions, previous researchhasfoundthreebasicmodelsofAIinknowledgeprocessing:knowledge representation, knowledge obtaining, andknowledge derivation [3]. Building on that foundation, the2 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nTable1: *e articles coded by research question, technology adoption, learning subject, educational level, research approach, and eﬀects.\\nID AuthorsResearch\\nquestionTechnology adoption Learning Subject Educational level Approach Eﬀects\\n1 Chin et al. [38] FEE Teachable agent Science education58 6thgrade students\\n(study1);teachersand134\\n5thgrade students (study\\n2)EXP OUT∗\\n2 Ngai et al. [55] AFFWearable biofeedback\\ncircuitCircuitry 7 to 9 grade students QE, SUR OUT∗\\n3 Wegerifetal.[42] REAIntelligent matching-\\npattern algorithmsOnline dialogue100 undergraduates and\\n12 postgraduate studentsDA OTH+\\n4*omas and\\nYoung [57]GAM Adaptive modelling Educational game 16 college graduates EXP, SUR PER∗\\n5 Yang et al. [27] ADPHigher-order item\\nresponse algorithmElementary mathematics 158 six graders in Taiwan EXP PER+\\n6 Moon et al. [58] GAMExperience point data\\nmodellingDigital game 40 plays EXP PER+\\n7McLaren et al.\\n[54]AFFIntelligent tutoring\\nsystemChemistry 132 high school students QE OUT∗\\n8 Jones [43]Investigating decentralized theory of artiﬁcial intelligence\\nExploring creative thinking\\n9 Vattam et al. [24] REA Visualization Science education 157middleschoolstudent QE OTH+\\n10 Jonassen [45] Introducing an ask system: interactive learning system\\n11Magnisalis et al.\\n[21]Review of adaptive and intelligent systems for collaborative learning support: adaptive and intelligent systems\\n12Albin-Clark et al.\\n[56]ROL\\nGAMGraphic simulation Construction4 early childhood lectures\\nand many studentsEXP, SUR PER+\\n13Wong and Looi\\n[59]Exploring swarm intelligence\\n14 Seni [60] Investigating the relationship between neurosciences and organizational cognition\\n15 Lin et al. [51] AFF Facial recognition Digital art course 20 adultsEXP,\\nSUR, INTPER∗\\n16 Heslep [61] Introspection to the misunderstandings of AI in education motivated by AI enthusiasts\\n17Nguyen and\\nYang [28]MAT Extraction algorithm Language learningAbout 500 Vietnamese\\nnews on many kinds of\\nmobile phone from 2009\\nto 2010DA 0\\n18 Tierney [22] RECNatural language\\nprocessLanguage learningFive interviews were\\nconducted generating\\nover seven hours of\\nrecordingsINT 0\\n19Lawler and\\nRushby [4]Interview with Rover Lawler to give comments on the eﬀect of computer technique on AI in education\\n20T¨ufekçi and K ¨ose\\n[34]FEEConstraint-based\\nmodellingProgramming 120 university students EXP, SUR OUT+\\n21 Zipitria et al. [19] ADPAutomatic discourse\\nmeasureLanguage learning17 summaries written in\\nBasque languageEXP PER+\\n22 Chin et al. [39] REA Teachable agentKit-based science\\ncurriculum153 fourth grade students QE OTH∗\\n23Mukherjee et al.\\n[30]FEEText-to-diagram\\nconversionReading12 pupils; 4 teachers; 2\\ntechnical professionals; 2\\nnontechnical personsQE OTH+\\n24 Jain et al. [41] FEE Visualization HistoryTwo undergraduate\\nclasses in computer\\nscienceQE PER+\\n25Higgins and\\nHeilman [62]RECAutomated scoring\\nsystemLanguage learningGame team (not\\nmentioned the\\neducational level)0\\n26 Melo et al. [9]REC\\nAFFComputational\\norganizationMultidisciplines148 students involved\\nwere either in high school\\nor in early college yearsEXP PER∗\\n27Flogie and\\nAberˇsek [13]AFFTransdisciplinary\\npedagogyNatural science100studentsin7th,8th,9th\\ngradesSUR OTH+Complexity 3\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nTable1: Continued.\\nID AuthorsResearch\\nquestionTechnology adoption Learning Subject Educational level Approach Eﬀects\\n28Rapanta and\\nWalton [40]REA Argument map Emirati and Spanish classes 205 university students EXP OTH+\\n29Nabiyev et al.\\n[29]CLAVisualization\\nIntelligent tutoring\\nsystemMathematical476 motion problems\\nfrom 9thgrade\\nmathematics textbooks of\\nTurkish Ministry of\\nEducationDA 0\\n30 Loeckx [8] Analytic essay of opportunities for AI used in educational data mining, adaptive learning, and creativity\\n31Hor´akov´a et al.\\n[3]CLAComparison of\\nartiﬁcial networks,\\nclassiﬁcation,\\nregression trees, and\\ndecision treesArtiﬁcial neural networks 120 text fragments QE, DA 0\\n32 Ijaz et al. [14] IMM Virtual reality History60 undergraduate\\nuniversity studentsQE PER+\\n33 Liu et al. [31] RECIntelligent tutoring\\nsystemLanguage learning30 sports articles\\nincluding 100 sentencesDA 0\\n34Malik and\\nAhmad [32]DEE E-assessment system Engineering 243 student of 8th graders EXP 0\\n35 Malik et al. [23] DEEQuery trend\\nassessment systemLanguage learning16 questions from\\nMicrosoft Students’ QA\\nCorpusDA 0\\n36 Peng [63]CLA\\nRECK-means algorithm,\\nPageRank algorithmOnline learning More than 700 scholars EXP 0\\n37MacIntyre et al.\\n[64]MAT Text minding software Language learning10 accomplished adult\\nmusicians and dancersINT 0\\n38 Aoun [65] Book review in terms of importance and limitation of AI in education\\n39Williamson et al.\\n[33]Discussing the importance of neuroscience in education\\n40Munawar et al.\\n[35]FEEIntelligent virtual\\nlaboratoryE-laboratory environment 161 university students SUR OTH∗\\n41Samarakou et al.\\n[47]ADPLearning system on\\ndiagnosis, assistance,\\nand evaluationTelecommunication\\nnetworks28 students studying\\ninformaticsEXP OTH+\\n42 Fenwick [12] Pondering the transformation of teacher’ professional roles\\n43 Kessler [44] Analytic essay of AI in the language teaching\\n44 Petit et al. [36] GAMOnline educational\\nprogramming platformProgramming400 students and 12\\nteachersEXP OUT+\\n45 Kelly et al. [37] DEEQuestion authenticity\\nmeasuring systemEnglish and language arts8-9 grade A large archive\\ndatabase of text\\ntranscripts of 451\\nobservations from 112\\nclassrooms and 132 high-\\nquality audio recording\\nfrom 27 classroomDA 0\\n46 Ge et al. [20]CLA\\nMATAutonomous learning\\nsystemSportsStudents of 2016 from a\\ncollege are selected for PE\\ntesting.Samplesofthe150\\nquestions are collectedDA 0\\n47 Sun [66] FEE Learning system Language learning176 valid enterprise\\nquestionnaires and 178\\nstudentquestionnairesare\\nobtainedQE, SUR OTH∗\\n48Auerbach et al.\\n[67]IMMRobotic hardware and\\nsoftware platformArtiﬁcial Evolution 42 postgraduate students EXP OUT∗\\n49Boulet and\\nDurning [68]Exploring online assessments system applied for the measurement in medical education4 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nTable1: Continued.\\nID AuthorsResearch\\nquestionTechnology adoption Learning Subject Educational level Approach Eﬀects\\n50Cukurova et al.\\n[69]REAArtiﬁcial intelligence\\nand multimodal dataDebating skills127 questionnaires and 47\\naudio recordings from\\ncandidates who have\\napplied to become a tutorSUR, DA OTH+\\n51 Du Boulay [70] ADPIntelligent tutoring\\nsystems (ITSs)STEAM, conceptual\\nunderstanding, and\\ndialogue-based learning(Not mentioned the\\neducational level)EXP OTH∗\\n52 Hughes [71] Review on papers about early self- and coregulation from artiﬁcial intelligence perspective included\\n53Kay and\\nKummerfeld [72]FEE Learning systemLifelong and life-wide\\npersonal user models(Not mentioned the\\neducational level)0\\n54Kitto and Knight\\n[73]Investigating three tensions in ethics when applying artiﬁcial intelligence and data analysis (AIDA) in education\\n55Luckin and\\nCukurova [74]REALearning sciences-\\ndriven AIProblem-solving, learning\\ndata, and debatingDatainonecasefromhigh\\nschoolEXP,INT OUT∗\\n56SellarandGulson\\n[75]DEE AI and data science Education policy4 semistructured\\ninterviews with ﬁve senior\\npolicymakers, technical\\nstaﬀ, and data scientistsINT 0\\n57 Sharmaetal.[76] ADPOnline adaptive self-\\nassessment procedure\\nwith multimodal dataWeb technologies*irty-two undergraduate\\nstudentsEXP 0\\n58Wang and Wang\\n[77]Developing an artiﬁcial intelligence anxiety (AIA) scale\\nExploring the relationships between AIA and motivated learning behaviour\\n59 Webb et al. [78] DiscussinghowtimeandtemporalityareusedandinﬂectedwiththeintroductionofAIineducationpolicycontexts\\n60 Williams [79] Analyzing implications of artiﬁcial intelligence, data analytics, and blockchain technology for the academy\\n61 Williamson [80] FEELearning analytics, AI,\\nand other software for\\ndata collectionHigher education Higher education SUR OUT+\\n62 Wintersetal.[81] Investigating the existing digital structural violence and the approaches to tackling it\\n63 Rowe [82]Exploring the eﬀect on education reform brought by intangible economy which is shaped by globalized datasets\\nsuch as OECD PISA and artiﬁcial intelligence\\n64 Ally [83] Identifying the shaping forces for future education and competencies required by future digital teachers\\n65Song and Wang\\n[84]Analyzing analysis of worldwide educational artiﬁcial intelligence research development in recent twenty years\\n66 Ulum [85] FEE Versant English test English language learning30 students from a state\\nuniversity in TurkeyDA,INT PER+\\n67Costa-Mendes\\net al. [86]REAMultilinear regression\\nmodelHigh school gradesEducational data\\ncollection from preschool,\\nprimary, and high schoolEXP OUT+\\n68 Zhai et al. [87]Investigating the factors impacting machine-human score agreements in machine learning-based science\\nassessments\\n69Loftus and\\nMadden [88]FEE Bayesian networks Internet of *ingsFirst year students from\\nBachelor of Science in\\nComputing programEXP OUT+\\n70Breines and\\nGallagher [89]Introducing the application cases of teacherbot in the University of Edinburgh\\n71 Campo et al. [90] REAMiddle,aMoodleplug-\\nin using a Bayesian\\nnetwork modelComputer science 45 university students EXP OUT∗\\n72Papadopoulos\\net al. [91]Critically reviewing the research on the use of socially assistive robots (SARs) in the pretertiary classroom and its\\nbeneﬁts and disadvantages\\n73 Berendtetal.[92] Examining beneﬁts and risks of artiﬁcial intelligence (AI) in education in relation to fundamental human rights\\n74Standen et al.\\n[93]ADP *e MaTHiSiS systemTeachers selected learning\\nmaterial from a library to\\ncreate their own learning\\nactivities and learning\\ngraphs67 participants aged\\nbetween 6 and 18 yearsEXP OTH∗Complexity 5\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nTable1: Continued.\\nID AuthorsResearch\\nquestionTechnology adoption Learning Subject Educational level Approach Eﬀects\\n75 Liu et al. [94] FEE BP neural network Undergraduate education870 observations have\\nbeen collected from 5\\nconsecutive academic\\nyears in one universityEXP OUT+\\n76 Knox [6]Analyzingthepoliticaleconomyofartiﬁcialintelligence(AI)andeducationinChina,withgovernmentpolicyand\\nprivate sector enterprise introduced\\n77 Cope et al. [95] FEECGScholar (Common\\nGround Scholar)Disciplinary knowledgeStudents studying at the\\nmasters and doctoral\\nlevelsEXP OUT∗\\n78Westera et al.\\n[96]Reviewing the artiﬁcial intelligence (AI) for serious games, presenting reusable game AI components and their\\nrelevance for learning and teaching, AI approach, and application cases\\n79Bonneton-Bott ´e\\net al. [97]FEE*e Kaligo, a digital\\nnotebook applicationHandwriting Kindergarten EXP OUT∗\\n80Smutny and\\nSchreiberova[98]ROL Chatbots Disciplinary knowledge(Not mentioned the\\neducational level)DA 0\\n81 Lucy et al. [99] DEENatural language\\nprocessingHistory(Not mentioned the\\neducational level)EXP OTH∗\\n82Yakubu et al.\\n[100]DEEArtiﬁcial neural\\nnetwork (ANN)Learning management\\nsystems (LMS)1116 students in four\\nNigerian universitiesSUR PER∗\\n83Bonami et al.\\n[101]Analyzing the education through 21st-century skills and the impact of AI development in the age of platforms,\\ntaking research, application, and evaluation into consideration\\n84Ko´c-Januchta\\net al. [102]DEEInquire Biology\\n(artiﬁcial intelligence-\\nenriched textbook)Biology24 students from\\nStockholm UniversityEXP,SUR OUT∗\\n85Tran and\\nMeacheam [118]Introducing four innovative projects that aim to extend learning management systems and improve the level of\\nautomation\\n86 Nye et al. [103] DEE MentorPal STEM 31 high school students SUR PER∗\\n87 Webb et al. [104] Investigating the implications of recent developments in machine learning for human learners and learning\\n88 Tsai et al. [105] DEE Deep neural networks Disciplinary knowledge3552 students from a\\nuniversity in TaiwanSUR 0\\n89Alyahyan and\\nDustegor [106]Constructing guidelines to apply data mining techniques to predict student success\\n90Renz and Hilbig\\n[107]Analyzingthedriversandbarriersthatcurrentlyaﬀectdata-basedteachingandlearningpathsfromtheperspective\\nof EdTech companies\\n91Gulson and\\nWitzenberger\\n[108]Investigatinghowautomatededucationgovernanceassemblageincludesnewformsofexpertiseandauthorityand\\nconstitutes EduTech as an important policy space\\n92Kerimbayev et al.\\n[109]Review the research aimed at studying robot-man interaction, taking Russia and Kazakhstan as an example of the\\ninternational cooperation in the sphere of robotics\\n93 Fu et al. [110] FEEAI-enabled learning\\ntoolsLanguage learning 15 language learners INT,SUR PER+\\n94 Salas-Pilco [111]Examining the use of artiﬁcial intelligence (AI) and robotics in learning designs from the perspective of learning\\nsciences\\n95 Yıldız [112] FEE SCM-AIConceptualization\\nperformances53 ﬁve-year-old and 49\\nseven-year-old Turkish\\nmonolingual children\\nfrom a primary schoolEXP OUT∗\\n96Tolsgaard et al.\\n[113]Critically reviewing the published application and potential role of data science and machine learning in Health\\nProfessions Education\\n97 Hsu [114] DEE AI Chatbot English language learning 30 university students EXP OTH∗98 Wu et al. [115] CLAMachine learning\\nclassiﬁcation modelAhybridadvancedstatistics\\ncourse24 university students EXP 0\\n99 Wang et al. [116] ADP Squirrel AI learning Math 200 eighth grade students EXP OUT∗\\n100Rybinski and\\nKopciuszewska\\n[117]AFFNatural language\\nprocessing (NLP)\\nmodelsHigher education640,349 reviews of 132\\nuniversitiesEXP 0\\nCLA: classiﬁcation; MAT: matching; REC: recommendation; DEE: deep learning; FEE: feedback; REA: reasoning; ADP: adaptive learning; AFF: aﬀection\\ncomputing; ROL: role-playing; IMM: immersive learning; GAM: gamiﬁcation; EXP: experiment; QE: quasiexperiment; DA: discourse analysis; INT: in-terview;SUR:survey;OUT:outcome;PER:perception;OTH:othersincludingaﬀection,criticalthinking,andcreativity. ∗:statisticallysigniﬁcantchange.+:\\nrecognizable change without conducting signiﬁcance tests. 0: focus on algorithms test without examination of learning performance.6 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nresearch questions of the sample papers were classiﬁed into\\nthree dimensions: (a) development, focusing on theknowledge presentation model; (b) extraction, centering onhow to obtain knowledge from data mining; and (c) ap-plication, emphasizing the human-computer interactionthrough information derivation. Secondly, with regard to\\ntechnology adoption, the focus was on the types of tech-\\nnology that the study adopted, which were further catego-rized into software (e.g., algorithms and programs) andhardware(e.g.,sensorsanddevicessuchasvirtualreality).Itshould be noted that astudy with technology without an AIpurpose in education was not included. A detailed de-scriptionisshowninTable1anditincludeslearningsubject,educational level, research approach, and eﬀects. Moreover,the researchers conducted further frequency comparisonsontheassociationsbetweentheresearchpurposesandsomefactors such as AI technology adoption as well as time\\nperiods to predict the trends and challenges of AI in\\neducation.\\n3.Findings and Discussion\\nAccording to the above coding criteria and content anal-ysis, the three dimensions of research questions are shownin Table 2 and the 72 studies from 63 empirical studies (5papershavetwostudiesand2papershavethreestudies)arefurthersubclassiﬁedinto11categories.*ereare23studiesin the dimension of development. *e AI technique wasutilized as a development tool for the construction of asmart learning environment, which can be subclassiﬁed asfocusing on the development of algorithms including\\nclassiﬁcation, matching, recommendation, and deep\\nlearning for teaching and learning purposes. Additionally,35 reviewed studies were found in the dimension of ex-traction, which referred to the application of developed AItechniques,normallybasedonalgorithms,tooﬀerstudentsfeedback, reasoning, and adaptive learning. 14 empiricalstudies were found in the dimension of application whichconsisted of aﬀection computing, role-playing, immersivelearning, and gamiﬁcation. In the integration dimension,AI techniques included those involving human factors asvitalvariablestoidentifyandanalyzelearners’personalized\\nfeatures.Insuchstudies,human-computerinteractionwas\\ngenerated to improve such characteristics as creativity,responsibility, and critical thinking that can impactlearners’ performances and perceptions. *e followingsectionsdescribewhateducationalissuesweredealtwithinthe age of AI and how AI technique was employed in eachresearch question.\\n3.1. Dimension of Development. As shown in Table 2, 16\\nempirical studies were found focusing on the development\\nof education systems such as intelligent tutoring system(ITS) and electronic assessment. *e development proce-dure was usually conducted with an induction-deductionapproach, in which prior experiments and data were ana-lyzed to predict the variables followed by the algorithmtesting to obtain the ﬁnal modelling equation [19].Generally, the development of an educational system is\\nconstituted of three components: the presentations, logicalmodelling, and data dimension [20]. All the 23 studiescentered on logical modelling, while no study was found onthe presentation methods or data mining. *e possibleexplanation may due to that the modelling techniques were\\nthefoundationofAItechniqueandfundamentallypenetrate\\nthroughout the procedure of system development. In thisdimension, the research was generally conducted in thedomainofcomputerscienceorinformationscience,andthedomainknowledgeasthesourcematerialwasimportedintoalgorithmframe(showninFigure1(a))withfewpedagogicaldesigns reported. For example, Horakova et al. [3] aimed toexplore the classiﬁcation ability of a text mining machineusing three classiﬁcation techniques. *e results show thatartiﬁcial neural networks (ANNs) were signiﬁcantly moreeﬀective than regression trees and decision trees to separate\\neducational texts or text fragments.\\nAdditionally, in terms of the matching/group formation\\nmodelling, prior research employing stereotype theory has\\nassessed that the Bayesian networks, association rules,clustering, fuzzy C-means, and the fuzzy and genetic al-gorithmswerewell-acceptedalgorithmsforthemodellingofindividual properties of the student. *ese techniquesprovide potential indications for the investigation offorming homogeneous and heterogeneous groups in aneducational context [21].\\nMoreover, the trends of the growing amount of data\\nchallenge educators to analyze qualitative data eﬃciently.\\nNatural language processing (NLP) provided a means to\\ndiagnose the problem and make a recommendation bysimplifyingandacceleratingthediscoveryofwhatlieswithinthe data [22]. However, the assessment of a complex edu-cational system requires more profound information re-trieval. *e integration of multiple approaches, such asbenchmark in NLP/Semantic Web ﬁeld, was suggested tomodel smarter computer-aided systems in which agentscould be trained automatically [23].\\nTo optimize the modelling in the learning context, the\\nhierarchical structures were considered as potential solu-\\ntions to model the educational system. *is is because ed-\\nucationisgenerallyacomplexsystem withtheexhibitionofsubsystems and components, in which the invisible causalprocesses among subsystem/component behaviours wouldcausally aﬀect each other [24]. It was suggested that sys-tematic modelling should analyze three dimensions in theeducationcontext:learner’svariation,learningdomains,andlearning activities [25, 26]. For example, some researchersconstructed the higher-order item response theory frame-work involving the overall ability at the ﬁrst dimension andmultiple domain abilities at the second dimension, which\\nhas been well adopted in the automatic problem-solving\\nprocess [27].\\nBased on the above and Nguyen and Yang’s suggestion\\n[28], the aims of developing an AI-integrated system ineducationcouldbegrouped intofourtypes:classiﬁcation(5studies), matching (3 studies), recommendation (5 studies),anddeeplearning(10studies).(1)Classiﬁcationreferstothereconstruction of knowledge bases, in which the materialsComplexity 7\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nTable2: *e number of studies concerning AI in education from 2010 to 2020.\\n6\\n3 351 2871320\\n33100113916\\n9\\n6 45 1 39 102236\\n04812162024283236\\n2011 2012 2013 2014 2015 2016 2017 2018 2019 2020Qantitative research\\nQanlitative researchTotal\\nQuantitative research topics\\nDevelopment (N �23)Classiﬁcation 1 2 1 1 5\\nMatching 1 1 1 3\\nRecommendation 1 2 2 5\\nDeep learning 2 1 1 6 10\\nExtraction (N �24)Feedback 1 1 2 2 3 7 16\\nReasoning 1 1 1 1 4 2 10\\nAdaptive learning 1 1 1 4 2 9\\nApplication (N �12)Aﬀection computing 1 1 1 1 1 1 6\\nRole-playing 1 1 2\\nImmersive learning 1 1 2\\nGamiﬁcation 1 2 1 4\\nQuantitative research 4 6 3 3 5 1 2 8 7 13 20 72\\nQualitative research 0 3 3 1 0 0 1 1 3 9 16 37\\nTotal 4 9 6 4 5 1 3 9 10 22 36 109\\nAlgorithms\\nDomainClassiﬁcation\\nmatching\\nRecommendation\\ndeep learningSystem\\ndevelopment\\n(a)\\nAdaptive learningReasoning\\nFeedbackAI\\ntechnique\\nDomain\\nknowledgePedagogical\\ndesign (b)\\nAffection ComputingRole-playing\\nGamification\\nImmersive learningAI\\ntechnique\\nDomain\\nknowledgePedagogical\\ndesign\\nHuman\\nfactor\\n(c)\\nFigure1: *e hierarchy of artiﬁcial intelligence in educational implementation. (a) *e dimension of system development, (b) the di-\\nmension of extraction, and (c) the dimension of application.8 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\ncould be categorized according to varied characteristics.\\nClassiﬁcation demarcates knowledge content, which con-tributes to the accuracy of text analysis [3]. For example,some researchers developed an ITS with the characteristicsof categorizing motion problems, by which learners couldeasily access diﬀerent types of motion problems in Math-\\nematics [29]. (2) Matching refers to a conversion mecha-\\nnism, in which varied sets of classiﬁcation are connected tospeciﬁc learning purpose. For example, a text-to-diagramsystem was developed for blind students to link geometrywords to an underlying diagram on the Braille printout,which has been certiﬁed as an eﬀective teaching/learningtool at a Blind school [30]. (3) *e recommendation isregarded as an intelligent authoring tool. With the supportofthenaturallanguageprocess,itcouldautomaticallycreatenew themes, theories, and pedagogical contents as a re-sponse to learners’ feedback, to help teachers save time and\\neﬀort [31]. It constructed a human-computer interaction\\nand widely used to generate real-time and intelligentfeedback according to learners’ input, which has beenregarded as a reliable feature in modern assessment system[32]. (4) Deep learning, or machine learning, is a compre-hensive approach of big data processing and learning be-haviour analysis. Based on the proliferation of big data ineducation, such as learning or teaching behaviour, thesystem could self-adjust to meet users’ dynamic require-ments by upgrading its algorithms [33].\\nTo date, some studies have reported the lack of signif-\\nicant impact on improving teaching. *e challenge was\\nlargelyattributedtotheweakpedagogicaldesignandlackof\\nappropriate assessment criteria [8]. Future research shouldtherefore be grounded in learning theories so that moreacceptable, accessible, and eﬃcacious AI can be an integralpart of learners’ lives.\\n3.2. Dimension of Extraction. Educators have begun to ex-\\nploresuitableapplicationsofAItechniquesintheirteaching.\\n*erearecurrentlysomeAIapplicationsthathaveachieved\\nthe integration of technique, domain knowledge, and ped-\\nagogical design. *e three types of pedagogical applicationsof AI identiﬁed in this review were feedback (16 studies),reasoning (10 studies), and adaptive learning (9 studies).While these applications could be interlinked, they werecategorized as such based on the classiﬁcation explicated bythe authors of the reviewed articles.\\n3.2.1. Feedback. One of the challenges impairing person-\\nalized learning is the inappropriate sequencing of contents.\\n*erestructuringofpresentationsequencesisseekingaway\\nto redeﬁne the organization of knowledge according to thestudent’sreaction.Inthissituation,feedbackisanimportantapproach to meet learners’ proximal learning patterns [9].Using an artiﬁcial neural network, the system providesimmediate feedback according to students’ input to helpthem gradually get access to the abstract concepts andperform practical exercises. Besides, researchers perceived apositive trend towards the system, which may attribute totwo perspectives.(1) Based on Ohlsson’s theory, students can learn from\\nthe feedback generated as the result of an error [34]. In aphysical teaching environment, the teacher could interactwithstudentsimmediatelyasdiﬃcultiesarise.Itis,however,diﬃcult for such just-in-time interaction in an onlinecontext. *e situation requires intelligent algorithms to\\nprovide feedback automatically. For example, with the help\\nof pedagogical agent-based cognitive architecture, the in-telligentvirtuallaboratorywasdevelopedtogiveappropriatefeedback to students who encounter diﬃculties in the lab-oratory [35]. Besides, a learning website, Jutge.org, wasdeveloped with the features of a rich and well-organizedproblem repository. *e website provides instant feedbackandhelpsstudentstoprogressivelysolveproblemsandlearnfrom their mistakes [36]. (2) Immediate feedback promotesactive training in interactive learning environments thatwould beneﬁt learner’s comprehension diagnosis [19]. *e\\nprevious study combined speech recognition, natural lan-\\nguage processing, and machine learning to measure thequality of classroomtalk, inwhich newformsof interactionwere created to provoke thoughts and further shape theeﬀective interaction of the learning environment [37].Another AI system used path traversal algorithms to es-tablish causal chains, by which students were provided withelaborated feedback and hints rather than the correct an-swers. *e learning-by-teaching context was constructed bylearners’ self-organization of interactions and their inter-pretation of feedback [38].\\nAlthough a large number of beneﬁts were reported with\\nrespect to automated feedback of domain knowledge, noresearch in this review had established the connection topedagogical theories. Most of the authors in the develop-ment dimensions were from the computer science domain,whichleadstotheirfocusonthepresentationofsourcedata(domain knowledge) technically without much pedagogicalconsideration.\\n3.2.2. AI-Supported Reasoning. *e recursive feedback may\\nhave the potential to foster learners’ abilities to reason in\\nspeciﬁc ways because the human-computer interaction isabletoengenderamongthestudentsasenseofresponsibilitytowardimprovingtheconstructionofknowledgerepository[39]. *e reconstruction of the knowledge repository wasseen as a process of using modelling to realize pedagogicaldesign as shown in Figure 1(b). However, some researchersfound that novices such as students and preservice teachersshowed minimal understanding of the invisible causal be-\\nhavioursinthesystemcomparedtoexpertsandexperienced\\nteachers[24].Anotherresearchshowedasimilarconclusion:students were able to learn the relevant facts and pairwiserelations, while they may still fail to reason with them verywell [39]. One possible explanation could be that reasoningislargelyinvisibleanditisdiﬃculttoinducetheprocessesofreasoning through the observation of the behaviours. AItechniques such as the visualization technique could beapplied to foster learners’ reasoning.\\nTo help learners improve their reasoning, the graph\\nstructure [29] and learners’ engagement [24] techniquesComplexity 9\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nhave been studied. For the graph structure, intelligent sys-\\ntemscouldbedevelopedtomakethinkingvisible.Inasense,the simulation approach of the AI technique was employedto mimic thoughts tracking the reasoning visually in realtime. For example, the argument-mapping tools weredesignedtoassistlearnerswithvisualizationofthepremises\\nand conclusions of arguments. *e ﬁndings showed that a\\nsequence of connected arguments was chained together forlearnerstomakeanultimateconclusion[40].Drawingfromthe sociocultural theories of learning in designing AI tosupportstudents’reasoning,Vattametal.[24]reportedthatengagedlearnerscouldbetterunderstandthemultiplelevelsof organization in complex systems. *erefore, students’engagement is an essential aspect to be considered for thedesign of a learning system that aims to support reasoning.\\n*e hierarchical reasoning generated by the intelligent\\nsystemhadbeneﬁcialeﬀectsonstudents’learning.Firstly,it\\nmay help learners to optimize the elucidation of the rela-\\ntionships between the subcomponents of a particular topic.In return, the intelligent reasoning system can be used as aform of evaluation to assess if the student has capturedenough concepts for the given topic [41]. Secondly, thesystem could provide an argumentative interaction whichplacedgreatsigniﬁcanceintheconstructionofcollaborativelearning atmosphere. It is because, as a result of peers’reasoning, learners tend to externalize their arguments andimprove their premises. Jain et al. [41] combined visualizedmapping tool with collaboration scripts. *e design suc-cessfully helped learners to analyze and evaluate opposing\\npositions on contentious topics. Generally, researchers\\nregarded the reasoning visualization tools as valuablescaﬀolds to develop learners’ critical thinking and writing[40].\\nHowever, using AI techniques, including visualization\\nandhierarchicalreasoningmodelling,maybeinadequatetosupportreasoning.*efourstudiesreviewedfocusedontheutilization of modelling to support general reasoning, whilethe reasoning model should be largely domain-speciﬁc[24, 39, 40, 42]. Moreover, there is an unresolved challengein coding learners’ behaviours as far as AI-supported rea-\\nsoning is concerned. *e reasoning process may be more\\neﬀective when learners’ personalized performance is con-sidered. Although the visualized reasoning tools couldperform well in a small-scale group setting, it is diﬃcult toobtain adequate reasoning analysis of the data from a largepopulationbecausethereasoningsystemfailstoadjustitselfautomatically. *erefore, the requirements of dealing withincreasingly large and diverse data demand self-adaptivealternatives [9].\\n3.2.3. Adaptive Learning. Based on the new decentralized\\ntheoriesofAIandsocialcognition,theapparentcomplexity\\nof learners’ behaviour was largely a reﬂection of the com-plexity of the learning environments. *is prompted edu-cators to provide adaptive scaﬀolds for diversiﬁed learningenvironments with various types of learners. Diﬀerent fromthefeedbacksystemthatoﬀersstockresponses,theadaptiveeducational system is a formative and corrective automatedsystem that can adjust itself (target of intervention) to suitindividual learners’ characteristics, needs, and preferences(pedagogical objective) [43]. Although only three empiricalstudieswereidentiﬁedinthisreview,someresearcherswerevery positive to the future promotion of adaptive system inteaching and learning. Technologies such as intelligent\\nspeech recognition and automated writing evaluation [44]\\nhave beentested with promisingﬁndings. Inaddition,therewas substantial evidence showing that adaptive intelligenceenhances learning by automatically enabling learners tolocate and access proximal educational resources with re-spect to navigation and presentation support [45].\\nPrevious research has emphasized that the design di-\\nmension was a worth exploring alternative in the appli-cation of adaptive system [46]. To design successfuladaptive systems in education, curriculum designers andsystem designers have to leverage on to include the\\nmodelling of the problem-solving process in the speciﬁc\\ndomain knowledge andthe use ofbig data[21, 44]. Firstly,the mechanism of the adaptive system connects learners’priordomainknowledgeandtheevaluationoftheircurrentdomain performance to scaﬀold their problem-solving[47]. In particular, the pedagogical design is essential inadaptive intelligent context. It involves the selection ofadaptive algorithms and considerations about the com-patibility of the learning style and the intelligence sup-portive methods. In this sense, the assumption that AIwould threaten the teachers’ position may be unfoundedbecause of teachers’ vital role as curriculum designers.\\nSecondly, the adaptive system is empowered by big data.\\nSince the main feature of the adaptive learning system ispersonalization,accumulationofbigdatasuchastherangeof diverse individual characteristics and learning style andpreferencesisnecessaryforintelligentpersonalizationtoberealized. However, research on personalization in thecontext of the adaptive system is limited to the users’characteristics related to domain knowledge. *e deeperinternal characters, such as human mental status andcreativity, were barely noticed and studied [21]. *ishowever has vital research potential with the development\\nofadvancedAItechniquessuchasbiofeedbacktechniques.\\n3.3. Dimension of Application\\n3.3.1. Technology Adoption in the Application Dimension.\\n*e dimension of application highlights the importance ofincluding human aﬀection in the application of AI in ed-\\nucation. *e latest research has indicated that aﬀection had\\nincreasinglybeenreportedtoexertasigniﬁcantinﬂuenceondecision-making, perception, and learning [48]. Previousstudies on the measurement of learning performance onlyfocusedontwodimensions:learningoutcomes(e.g.,scoringand achievement) and perceptions (e.g., satisfaction andacceptance), whereas other aspects were less noticed. Basedon the maturity of biofeedback technique, such as eye-tracking and EEG, aﬀection computing was increasinglyadopted to investigate students' internal motivations onlearning, such as creativity and responsibility [49, 50].10 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nAccording to the content analysis of the selected papers\\nshown in Table 1, there are ﬁve typical AI techniques that\\nsupportedaﬀectioncomputingandanalysisintheeducationsector. *ey are complex algorithms, visualization, XR(virtual/augmented/mixed reality), wearable technique, andneuroscience.Inmanysituations,theysupportedeachother\\nto construct a smart learning environment and system. (1)\\nComplex algorithms were designed with consideration ofhuman factors rather than the simple combination offunctionalblocks.Fromtheperspectiveofhuman-computerinteraction, the learners should be treated as a knowledgecreator rather than the receiver, which helps to generatepositive aﬀection status. From the perspective of presenta-tion modes, the traditional declarative statements in acomputer system should be replaced by more diversiﬁedverbal presentations such as dialogue, coaching, and gen-erality. (2) Visualization was seen as an optimal method\\nchosen for the solution of complex conception. One of the\\nbeneﬁts of visualization is making complex knowledge en-tertaining, such as game-based learning, in which learners’motivation will be greatly generated. (3) XR includingvirtual/augmented/mixedrealityprovidesahighlysimulatedlearning context, which may be challenging to realize inphysical classrooms. For example, to help learners under-stand complex landforms in geography, XR indulges stu-dents into a lively and creative status. (4) *e wearabletechnique,suchasGoogleglasses,helpstointegratelearningactivity into somatosensory moves. Although it was still inan exploratory period, it has great potential to advance\\ndomain knowledge in a practical context in daily life. (5)\\nModernneuroscienceexploitshowthebrainworksandthisexpands the research of learning to include the learners’physiological state. Research in this area would enrich un-derstanding about individual variations and could provideadditional avenues to match instruction with the mostoptimal guidance.\\n3.3.2.:eCategoriesoftheApplicationDimension. Withthe\\nsupports of the above ﬁve AI techniques, four types of\\nlearning models were generated with the application ofaﬀection analysis, which was biofeedback (6 studies), role-playing (2 studies), immersive learning (2 studies), andgamiﬁcation (4 studies).\\nAﬀection computing refers to the analysis of human\\nemotions and feelings captured by physical sensors andaﬀective algorithms, which has gained much attention inrecent years. Aﬀection computing enhanced human-com-\\nputer interaction. Based on the facial identiﬁcation, some\\nresearchers improved the intelligent tutoring system bywhich students’ emotional status was detected to give themtimely emotional feedback [51]. Two essential aspects areneededtooptimizetheaﬀectioncomputingtechnique:ﬁrst,teachers have to make timely appropriate instructionaladjustments according to learners’ aﬀective status; second,comprehensive operation of multimode aﬀection sources asa single source is unlikely to provide accurate analysis ofaﬀection. For example, the eye-tracking technique couldcapture learners’ eye ﬁxation to track the attended area, butthe reasons for the foci may be attributed to diﬀerent af-fections such as interest, anxiety, or even distraction. Anadditional source of data such as EEG could help to make amore accurate assessment [52].\\nRole-play is a learning method that inspires students to\\nponder on problems with aﬀections assuming varied roles.\\nSomealgorithmsweredesignedwiththeintegrationofrole-\\nplay into the pedagogical design, where students are taughtby an intelligent agent rather than being taught by thelearning system [39]. Enlisting role-play can enhancelearners’ investment in their interactions with computers.More than that, learners’ sense of responsibility was exertedtowards the intelligent agent, which was consistent with theresearchfromChaseetal.,demonstratingthatstudentsmaywork harder on behalf of their agents than they would forthemselves [53]. Additionally, to motivate students to act asa companion to an intelligent agent, the politeness pre-\\nsentation mode was employed in the intelligent tutoring\\nsystems, which was observed to beneﬁt the needy students[54].*efutureresearchofrole-playmayfocusongrantingaccess to students so that they could customize their rolesand target agents.\\nImmersivelearningisanapproachthatenablesstudents\\nto customize scenes of characters engaging in full-viewlearningsettings.*eenhancementofXR,3Dgraphics,andwearable devices could promote the learning performanceand these are strongly related to immersive aﬀection, whichgenerated students’ academic performance and positiveperceptions, such as excitement, enthusiasm, and creativity.\\nFor example, learners could obtain a high degree of ex-\\ncitementintheimmersivelearningenvironment.Immersiveenvironment can also be coupled with immersive collabo-ration with gestures, emotions, and nonverbal communi-cation [14]. Using immersive learning may also reducestudents’ sense of being intimidated by complex topics andtechnical concepts when they expose to simulated techno-logical and computing issues [55]. Most importantly, manyimmersive learning tools encourage learners’ enthusiasm tocreate and change the environments, which could fostercreativity[56].However,fewstudieswerefoundtoconsider\\ndomainknowledgeasavariable.*epossiblereasonmaybe\\nthat many immersive learning tools were in the explorativestage. Further investigations in speciﬁc domains are eagerlyneeded.\\nGamiﬁcation has emerged as an important theoretical\\nnotion in the education sector. *e most successful ed-ucational games tightly integrate the pedagogical design,domain knowledge, and aﬀection elements with game-play. AI has assisted the integration of the game andknowledge domain, and the further potential is makingthe game adapt to the learners’ behaviours and aﬀections\\ndynamically [57]. One of the examples appropriately\\nintegratingdomainknowledgewithaﬀectionisMinecraftEdu. *is is a historical simulation game where studentscanlearnabouthistoricalﬁguresandeventsorgetinsightinto the spread of epidemics. Learners could get access tohistorical events with authenticemotions in the real-timeinteraction, and the collateral emotion would help thembetter understand the speciﬁc content knowledge [8].Complexity 11\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nAnother example employed a game reward system as\\nmotivational mechanisms to promote voluntary andproactive learning. *e results showed that the rewardsystemhadadesirableﬁtwiththepedagogicaldesign,andthe future educational algorithms might better get asso-ciated with the ﬁeld of artiﬁcial intelligence to motivate\\nemergent learning [58].\\n3.4. :e Results from Qualitative Research. According to\\nselected qualitative research (as shown in Table 3), the\\nexplorationofAIineducationexperiencedaprocessfromtheoretical research to a speciﬁc practice ﬁeld, and at lastback to review. Simultaneously, qualitative research also\\nprovided support for the development of quantitative\\nresearch throughout the whole process. Some theoreticalstudies were at the forefront. For example, in 2011 and2012, qualitative research on decentralized theory [43]and swarm intelligence [59] appeared, and then the realartiﬁcial intelligence research began. AI algorithms werenot very mature at the beginning while advanced intel-ligentalgorithmsareusuallybasedonbigdatatechnology,and they could constantly learn and improve in themassive data. *e big data must be decentralized andgroup-oriented. *erefore, we believe that the early the-\\noretical research has played a signiﬁcant supporting role.\\nIn 2019, researchers attached more emphasis on thesummary of previous studies and prospects for futuredevelopment,andmoreconsiderationwillbegiventothestatusquo, future, andpossibleproblems ofAI invarioussectors of education.\\n4.The Research Trends of AI in Education\\n4.1. Technology Adoption of Internet of :ings. *e existing\\nresearch mainly focused on the virtual online system, andthe Internet of *ings (IoT) is less noticed. Learners’ bio-feedback also needs to be explored in future educational\\nresearch.Accordingtothereviewedpapers,amajorityofAI\\ntechnology in education focused on online informationtechnology or system (107 out of 109), such as intelligenttutoring system, intelligent virtual laboratory, and assess-ment system. Only one study [55] employed a wearablecircuit to examine learners’ biofeedback. *is may be at-tributed to the fact that the intelligent online system is wellestablished, easier to build on, and cost-eﬀective. However,to cater to diverse learning contents and varied learningskills,theIoTholdsmuchpromise.Itmayenhancestudents’spatial and mechanical understanding of physical con-\\nstructionprocessesinscienceeducation.*eIoTtechnology\\ncansimulatebrainfunctionsinphysicalcontexttosenseandunderstandhuman’scognitivebehaviours,whichapparentlyoptimizes human cognition and performance in two qual-itativestudies[33,60].Althoughno empiricalstudiesintheselectedpaperswerefoundtotesttheeﬀectofIoTtechniqueon education, the IoT with aﬀordable costs and wearablecomputing devices could be a potential area of future de-velopment of AI in education. *is is consistent with theHorizon report in 2019.4.2.SwarmIntelligenceinEducation. Swarmintelligencehas\\nbecome avital development direction ofAI, where therolesof teachers and students will be disruptively changed.According to the selected papers, the decentralized theorywasﬁrstlyinvestigatedineducationin2011[43],followedby\\nthe introduction of swarm intelligence in education in 2012\\n[59]. However, no empirical study has explored howteachersandstudentsmeetthechallengesbroughtbyswarmintelligence.Itispredictedthatthefollowingtwotopicsmaybecome the research trends according to the features ofswarm intelligence. Firstly, swarm intelligence does not relyon centralized control of individual behaviours. In thissituation, learners change from knowledge absorbers tocreators.*eyactivelyconstructedknowledgebyinterfacingwith the system in a variety of contexts. Teachers’Table3: Qualitative research topics.\\n2020\\n(1) AI research development in recent twenty years\\n(2) Machine learning-based science assessments\\n(3) Application cases of teacherbot\\n(4) Socially assistive robots (SARs)\\n(5) AIED in relation to fundamental human rights\\n(6) Political economy of AI and education\\n(7) AI for serious games\\n(8) Impact of AI development in the age of platforms\\n(9) Innovative projects extending LMS\\n(10) Machine learning\\n(11) Data mining techniques\\n(12) Data-based teaching and learning paths\\n(13) Automated education governance assemblage\\n(14) Robot-human interaction\\n(15) AI and robotics in learning designs\\n(16) Data science and machine learning\\n2019\\n(1) Assessment system\\n(2) Early self- and coregulation from AI perspective\\n(3) Ethical tension about applying AIDA in education\\n(4) Artiﬁcial Intelligence Anxiety (AIA) Scale\\n(5) AI in education policy contexts\\n(6) AI, data analytics, and blockchain technology\\n(7) Digital structural violence\\n(8) Intangible economy\\n(9) Future education and digital teachers\\n2018\\n(1) Neuroscience in education\\n(2) Teacher’ professional roles\\n2017\\n(1) Human literacy\\n2016\\n(1) Educational data mining, adaptive learning, and creativity\\n2013\\n(1) Eﬀect of AI in education\\n2012\\n(1) Swarm intelligence\\n(2) Neurosciences in Edu\\n(3) Misunderstandings of AI in Edu\\n2011\\n(1) Decentralized theory\\n(2) Interactive learning12 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n“authorities” may be challenged by a group of experienced\\npractitioners such as engineers and farmers, and a collab-orative curriculum design would be constructed by swarmintelligence system [45]. Moreover, swarm intelligence maychange teachers’ duties from knowledge transmission toknowledgeorganization.Previousresearchhassuggestedthe\\nexploration of crowdfunding or crowdsourcing by teachers\\non education, and how teachers perform their organizingability in the future [5]. However, as Figure 2 presents, theinvestigation from teachers’ perspective is still inadequate,which needs further study. Secondly, swarm intelligencefacilitated adaptivity in dynamic or unstable environments.Swarm agents usually exchange information by leavingmarks and observing the activities of their peers. For ex-ample,thebestsolutioninthecurrentmomentmaybecomeunavailableinthenextmoment.*erefore,itissuggestedtoinvest further how AI performs dynamic recommendation\\nfor students on diﬀerent learning progress [59].\\n4.3.DeepLearningandNeurocomputation. Deeplearningor\\nmachine learning will reshape the interactions between\\nhuman beings and machines in the future. *e trends ofhuman-computerinteractionwillnolongerbebasedontheperspective of machine operation by a human. Instead, themachine can improve predictions by learning from big data\\nwithoutbeingspeciﬁcallyprogrammed.Twostudiesondeep\\nlearning were ﬁrst mentioned in the selected papers in 2017[23,32].In2018,oneempiricalstudy[37]waspublishedandit focused the deep learning technology on the modelling ofscoring-based data. However, the data based on human’sphysical features were less noticed. Based on the basis ofneuroscientiﬁcunderstandingofthebrain,PearsonandIBMhaveproposedtoinvestigateneurocomputationbrain-basededucationaltechnologies[33].However,onlytwoqualitativestudies [33, 60] suggested the integration of neuroscienceand AI in the education sector. Future research trends in\\nintegrating brain function with deep learning techniques to\\noptimizehuman-computerinteractioncouldbeexpected.Itwill inﬂuence the application and integration of AI in ed-ucation, such as adaptive learning and role-play. *is viewhasbeenreportedintheHorizonreportin2018.Speciﬁcally,thereportforecaststhatadaptivelearningtechniqueswillbefurther generalized in two to three years.\\n4.4. Evaluation of AI in Education. All empirical studies\\nreviewed presented the positive eﬀects of AI techniques on\\neducation (see Table 1). However, the interview and thereview paper have, respectively, surfaced the challenges ormisunderstandingofAIineducation[4,21].*ereisaneedto articulate a holistic evaluation criterion to measure theeﬀectiveness of AI in education. To ensure the validity andreliability of the evaluation, a multidimensional modelshould be adopted, which includes technique, pedagogicaldesign, domain knowledge, and human factors. Woolf’s[119] Roadmap for Education Technology predicted that in\\nthe era of AI Educational Data Mining, the lifelong as-\\nsessment of students’ knowledge, their progress, and theenvironments where they learn, as well as the success andfailureinteachingstrategies,canbechronologicallytracked.\\nBesides,currentresearchisdisproportionatelyfocusedon\\nspeciﬁc educational contexts and a handful of variables. Asshown in Figure 2, most research sampled students as par-ticipants, while teachers and professor practitioners were less\\nnoticed; additionally, most researchers considered science,\\nhumanity,andsocialscienceassubjects,butlessattentionwaspaid to sports, arts, and special education. For example, onlyonestudywasfoundtodeveloptext-to-diagramconversionasa novel teaching aid for blind learners [30].\\n5.The Challenges AI Confronted in Education\\nAI is a promising ﬁeld that faces many technology bottle-necks.*echallengeswouldbemorecomplexandintricate,\\nespecially when they are connected to an application in\\neducation. *e challenges this review identiﬁes could beclassiﬁed into three categories: technique, teachers andstudents, and social ethics.\\nAlthough AI techniques displayed and predicted smart\\ncomputation in the education domain, they generally fail tobring “added-value” to large-scale students because of theconcern of costs, and the mainstream is still occupied by“basic value” [38]. Speciﬁcally, some researchers found thatmany AI techniques were designed for a general situationthat could not address the needs of a particular domain,\\nspeciﬁc learning activities, or teaching goals. *is would\\nprevent the actualization of personalized learning experi-ences [8, 120].\\nAnother great challenge reported in the Horizon report\\nin 2018 is the reconceptualization of the role of educators.Teachers’ attitudes towards AI have a signiﬁcant inﬂuenceon the eﬀectiveness of using AI in education. Teachers mayswingfromtotalresistancetooverreliance.*eformercouldarisefrominadequate,inappropriate,irrelevant,oroutdatedprofessionaldevelopment.*elattermaybeduetoteachers’unrealisticexpectations.*eseteachersmayfocustoomuch\\non the emerging AI technologies rather than learning itself\\n[44]. Additionally, from the perspective of students, AItechnique may provide smart and eﬃcient tools that causestudentstoavoiddoingtheknowledgeprocessingworkthatteachers expect them to do. For example, the AI translatorsmay oﬀer ready-made illustrations, pronunciation, ﬁxedphrases, and even a serial of examples. Students are thusunwilling to engage in the inquiry processes that facilitatedeep learning.\\n*e ethical issues brought by AI are also challenging for\\nboth researchers and educational practitioners. It was clear\\nthatAIhasmadegreatstridesoverthepastfewyears,mostly\\nbecause of cheaper processing and the availability of data;however,individualstudentdatamaybeexposed,shared,orused inappropriately. It is a constantly mindful challengethat educators and AI engineers will face when consideringhow we access, evaluate, and share the big data and theresults of data analysis [44, 65]. Another ethical debate wasconspicuously found in gamiﬁcation that emphasis shouldbe put on learning and tend to “suck the fun out” of games,or on gameplay “suck out the learning” [57].Complexity 13\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n6.Conclusions\\nGiven the rapid growth of AI, there is an urgent need to\\nunderstandhoweducatorscanbestutilizeAItechniquesforthe academic success of students. *is paper reviewed AI ineducation research from 2010 to 2020. It is found that the\\nresearch to date could be classiﬁed into three dimensions:\\nthe dimension of development including classiﬁcation,matching, recommendation, and deep learning; the di-mensionofanextractioninvolvingfeedback,reasoning,andadaptive learning; and the dimension of application in-cluding aﬀection computing, role-playing, immersivelearning,andgamiﬁcation.Moreover,basedontheresearchquestionsandtherelatedAItechniques,fourresearchtrendswere identiﬁed. *ey are the Internet of *ings, swarmintelligence, deep learning, and neuroscience, as well as anassessmentoftheeﬀectofAIineducation.*echallengesof\\nAI in education were also conspicuously seen in terms of\\ntechnique perspective, teachers’ and students’ roles, andsocial ethical issues. *ese ﬁndings could be valuable ref-erences for educational researchers, students, and AI de-velopers who plan to contribute to the relevant studies.Furthermore,itseemsclearthateducatorsneedtoworkwithAI engineers to address the gaps between technique andpedagogy.\\n7.Limitations and Future Study\\nAlthoughthisreviewdoesproposesomevaluabletrendsandpotential research directions for AI in education, there existseveral limitations. Firstly, thepapers reviewed in this study\\nwereﬁlteredfromSocialScienceCitationIndex,whileother\\ndatabases on natural science (e.g., SCOPUS and EI) andsources (e.g., reports, news, conference papers, and patents)couldbeinvolvedtooﬀeramorecomprehensiveoverviewinthis ﬁeld. For instance, articles from the International\\nJournal of Artiﬁcial Intelligence in Education that has pub-\\nlished30volumeswerenotconsidered.*isreviewthereforeis limited only to SSCI articles. Additionally, the initialsearch could be extended using more keywords such asadaptive learning and tutor system, which may lead to thelatest technical reports of AI in education that were notincluded in this paper. Secondly, since the current reviewwasnotattemptedtobeinclusivebuttoprovideasystematicoverview of AI in education, the analysis in this review mayprovide a framework for future research integration. Forexample, a more formal meta-analysis could be conductedon selected empirical studiesthatreported eﬀect sizesto seewhat impact on learning AI might be having. Besides, the\\nfuture analysis could go back further in time to see if there\\nwere changes about the time that AI 2.0 started to makeheadways into education.\\nData Availability\\n*econtentanalysisdatausedtosupporttheﬁndingsofthisstudy are included within the article.\\nConflicts of Interest\\n*eauthorsdeclarethattheyhavenoconﬂictsofinterestto\\nreport regarding the present study.\\nAcknowledgments\\n*is research work was supported by the 2020 Humanities\\nand Social Science Projects of the Ministry of Education(Grant ID: 20YJC880118), National Science Funding ofChina (Grant ID: 61977057), 2019 National Social ScienceFunding of China (19ZDA364), and the project of Infor-matization Capability in University Governance System,Chinese Association of Higher Education, 2020 (Grant no.2020ZDWT18).\\nReferences\\n[1] K. Kumar and G. S. M. *akur, “Advanced applications of\\nneural networks and artiﬁcial intelligence: A review,” In-\\nternational journal of information technology and computer\\nscience, vol. 4, no. 6, pp. 57–68, 2012.\\n[2] J. M. Spector and D. J. Muraida, Automating Instructional\\nDesign: Concepts and Issues, Educational Technology Pub-\\nlications, Englewood Cliﬀs, NJ, USA, 1993.\\n0510152025\\nAdults OthersEducational levelPreschool\\nstudentsPrimary\\nschool\\nstudentsMiddle\\nschool\\nstudentsCollege\\nstudents(a)\\n0481216202428\\nScience Arts\\nand sportsSpecial\\neducationMultidisciplinesSubjectsHumanities\\nand\\nsocial sciences (b)\\nFigure2: *e number of reviewed studies by educational level and subjects.14 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n[3] T.Horakova,M.Houska,andL.Domeova,“Classiﬁcationof\\nthe educational texts styles with the methods of artiﬁcial\\nintelligence,” Journal of Baltic Science Education, vol. 16,\\nno. 3, pp. 324–336, 2017.\\n[4] R. W. Lawler and N. Rushby, “An interview with Robert\\nLawler,”British Journal of Educational Technology, vol. 44,\\nno. 1, pp. 20–30, 2013.\\n[5] Dai, C. S. Chai, P. Y. Lin et al., “Promoting students’ well-\\nbeing by developing their readiness for the artiﬁcial intel-ligence age,” Sustainability, vol. 12, no. 16, pp. 1–15, 2020.\\n[6] J. Knox, “Artiﬁcial intelligence and education in China,”\\nLearning, Media and Technology, vol. 45, no. 3, pp. 1–14,2020.\\n[7] A.SeldonandO.Abidoye, :eFourthEducationRevolution,\\npp. 1–14, University of Buckingham Press, London, UK,2018.\\n[8] J. Loeckx, “Blurring boundaries in education: context and\\nimpact of MOOCs,” :e International Review of Research in\\nOpen and Distributed Learning, vol. 17, no. 3, pp. 92–121,2016.\\n[9] F. R. Melo, E. L. Fl ˆores, S. D. Carvalho, R. A. G. Teixeira,\\nL. F. B. Loja, and R. de Sousa Gomide, “Computationalorganization of didactic contents for personalized virtuallearning environments,” Computers & Education, vol. 79,\\npp. 126–137, 2014.\\n[10] B. Boulay, “Artiﬁcial intelligence as an eﬀective classroom\\nassistant,” IEEE Intelligent Systems, vol. 31, no. 6, pp. 76–81,\\n2016.\\n[11] M. Lacity and L. P. Willcocks, Robotic Process Automation\\nand Risk Mitigation: :e Deﬁnitive Guide, SB Publishing,Ashford, UK, 2017.\\n[12] T. Fenwick, “Pondering purposes, propelling forwards,”\\nStudies in Continuing Education, vol. 40, no. 3, pp. 367–380,2018.\\n[13] A. Flogie and B. Aberˇ sek, “Transdisciplinary approach of\\nscience, technology, engineering and mathematics educa-tion,”Journal of Baltic Science Education, vol. 14, no. 6,\\npp. 779–790, 2015.\\n[14] K. Ijaz, A. Bogdanovych, and T. Trescak, “Virtual worlds vs\\nbooksand videos inhistory education,” Interactive Learning\\nEnvironments, vol. 25, no. 7, pp. 904–929, 2017.\\n[15] B. Kitchenham, P. Pretorius, D. Budgen et al., “Systematic\\nliterature reviews in software engineering–a tertiary study,”Information and software technology, vol. 52, no. 8,pp. 792–805, 2010.\\n[16] R. Trescak, B. Yang, E. Zio, and X. Chen, “Artiﬁcial intel-\\nligence for fault diagnosis of rotating machinery: a review,”Mechanical Systems and Signal Processing, vol. 108, pp. 33–\\n47, 2018.\\n[17] Z. Wang and R. S. Srinivasan, “A review of artiﬁcial intel-\\nligencebasedbuildingenergyuseprediction:contrastingthe\\ncapabilities of single and ensemble prediction models,”Renewable and Sustainable Energy Reviews, vol. 75,pp. 796–808, 2017.\\n[18] Y.-T. Wu, H.-T. Hou, F.-K. Hwang et al., “A review of in-\\ntervention studies on technology-assisted instruction from2005–2010,” Journal of Educational Technology & Society,\\nvol. 16, no. 3, pp. 191–203, 2013.\\n[19] I.Zipitria,A.Arruarte,andJ.Elorriaga,“Discoursemeasures\\nfor Basque summary grading,” Interactive Learning Envi-\\nronments, vol. 21, no. 6, pp. 528–547, 2013.\\n[20] X. Ge, Y. Yin, and S. Feng, “Application research of com-\\nputer artiﬁcial intelligence in college student sportsautonomous learning,” Kuram Ve Uygulamada Egitim\\nBilimleri, vol. 18, no. 5, pp. 2143–2154, 2018.\\n[21] I. Magnisalis, S. Demetriadis, and A. Karakostas, “Adaptive\\nand intelligent systems for collaborative learning support: a\\nreview of the ﬁeld,” IEEE Transactions on Learning Tech-\\nnologies, vol. 4, no. 1, pp. 5–20, 2011.\\n[22] P. Tierney, “A qualitative analysis framework using natural\\nlanguage processing and graph theory,” :e International\\nReviewofResearchinOpenandDistributedLearning,vol.13,no. 5, pp. 173–189, 2012.\\n[23] K. R. Malik, R. R. Mir, M. Farhan, T. Raﬁq, and M. Aslam,\\n“Studentquerytrendassessmentwithsemanticalannotationand artiﬁcial intelligent multi-agents,” Eurasia Journal of\\nMathematics, Science and Technology Education, vol. 13,\\nno. 7, pp. 3893–3917, 2017.\\n[24] S. Vattam, A. K. Goel, S. Rugaber et al., “Understanding\\ncomplex natural systems by articulating structure-behavior-function models,” Educational Technology & Society, vol.14,\\nno. 1, pp. 66–81, 2011.\\n[25] A. Casamayor, A. Amandi, and M. Campo, “Intelligent\\nassistance for teachers in collaborative E-learning environ-\\nments,” Computers & Education, vol. 53, no. 4,\\npp. 1147–1154, 2009.\\n[26] A. Gogoulou, E. Gouli, and M. Grigoriadou, “Adapting and\\npersonalizing the communication in a synchronous com-munication tool,” Journal of Computer Assisted Learning,\\nvol. 24, no. 3, pp. 203–216, 2008.\\n[27] C.-W. Yang, B.-C. Kuo, and C.-H. Liao, “A HO-IRT based\\ndiagnostic assessment system with constructed response\\nitems,”Turkish Online Journal of Educational Technology-\\nTOJET, vol. 10, no. 4, pp. 46–51, 2011.\\n[28] B.-A. Nguyen and D.-L. Yang, “A semi-automatic approach\\nto construct Vietnamese ontology from online text,” :e\\nInternational Review of Research in Open and Distributed\\nLearning, vol. 13, no. 5, pp. 148–172, 2012.\\n[29] V. V. Nabiyev, ¨U. Çakiro˘ glu, H. Karal, A. K. Er¨ umit, and\\nA. Çebi, “Application of graph theory in an intelligenttutoring system for solving mathematical word problems,”\\nEurasia Journal of Mathematics, Science & Technology Ed-\\nucation, vol. 12, no. 4, pp. 687–701, 2016.\\n[30] A. Mukherjee, U. Garain, and A. Biswas, “Experimenting\\nwithautomatictext-to-diagramconversion:anovelteachingaid for the blind people,” Journal of Educational Technology\\n& Society, vol. 17, no. 3, pp. 40–53, 2014.\\n[31] M. Liu, V. Rus, and L. Liu, “Automatic Chinese factual\\nquestion generation,” IEEE Transactions on Learning Tech-\\nnologies, vol. 10, no. 2, pp. 194–204, 2017.\\n[32] K.R.MalikandT.Ahmad,“E-assessmentdatacompatibility\\nresolution methodology with bidirectional data transfor-mation,” EURASIA Journal of Mathematics, Science &\\nTechnology Education, vol. 13, no. 7, pp. 3969–3991, 2017.\\n[33] B. Williamson, J. Pykett, and S. Nemorin, “Biosocial spaces\\nand neurocomputational governance: brain-based and\\nbrain-targetedtechnologiesineducation,” Discourse:Studies\\nin the Cultural Politics of Education, vol. 39, no. 2,\\npp. 258–275, 2018.\\n[34] A. T¨ ufekçi and U. K¨ ose, “Development of an artiﬁcial in-\\ntelligence based software system on teaching computerprogramming and evaluation of the system,” Hacettepe\\n¨Universitesi E˘ gitim Fak¨ ultesi Dergisi, vol. 28, no. 2,pp. 469–481, 2013.\\n[35] S.Munawar,S.K.Toor,M.Aslam,andM.Hamid,“Moveto\\nsmart learning environment: exploratory research of chal-lenges in computer laboratory and design intelligent virtualComplexity 15\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nlaboratory for eLearning technology,” Eurasia Journal of\\nMathematics, Science and Technology Education, vol. 14,\\nno. 5, pp. 1645–1662, 2018.\\n[36] J.Petit,S.Roura,J.Carmonaetal.,“Jutge.org:characteristics\\nand experiences,” IEEE Transactions on Learning Technol-\\nogies, vol. 11, no. 3, pp. 321–333, 2018.\\n[37] S. Kelly, A. M. Olney, P. Donnelly, M. Nystrand, and\\nS. K. D’Mello, “Automatically measuring question authen-ticity in real-world classrooms,” Educational Researcher,\\nvol. 47, no. 7, pp. 451–464, 2018.\\n[38] D. B. Chin, I. M. Dohmen, B. H. Cheng, M. A. Oppezzo,\\nC. C. Chase, and D. L. Schwartz, “Preparing students forfuture learning with teachable agents,” Educational Tech-\\nnologyResearchandDevelopment,vol.58,no.6,pp.649–669,\\n2010.\\n[39] D. B. Chin, I. M. Dohmen, and D. L. Schwartz, “Young\\nchildren can learn scientiﬁc reasoning with teachableagents,”IEEE Transactions on Learning Technologies, vol. 6,\\nno. 3, pp. 248–257, 2013.\\n[40] C.RapantaandD.Walton,“*euseofargumentmapsasan\\nassessment tool in higher education,” International Journal\\nof Educational Research, vol. 79, pp. 211–221, 2016.\\n[41] G. P. Jain, V. P. Gurupur, J. L. Schroeder, and\\nE. D. Faulkenberry, “Artiﬁcial intelligence-based studentlearning evaluation: a concept map-based approach foranalyzing a student’s understanding of a topic,” IEEE\\nTransactions on Learning Technologies, vol. 7, no. 3,pp. 267–279, 2014.\\n[42] R. Wegerif, B. M. McLaren, M. Chamrada et al., “Exploring\\ncreative thinking in graphically mediated synchronous di-alogues,” Computers&Education,vol.54,no.3,pp.613–621,\\n2010.\\n[43] A.Jones,“Philosophicalandsocio-cognitivefoundationsfor\\nteaching in higher education through collaborative ap-proaches to student learning,” Educational Philosophy and\\n:eory, vol. 43, no. 9, pp. 997–1011, 2011.\\n[44] G.Kessler,“Technologyandthefutureoflanguageteaching,”\\nForeign Language Annals, vol. 51, no. 1, pp. 205–218, 2018.\\n[45] D. H. Jonassen, “Ask systems: interrogative access to mul-\\ntiplewaysofthinking,” EducationalTechnologyResearchand\\nDevelopment, vol. 59, no. 1, pp. 159–175, 2011.\\n[46] E. Walker, N. Rummel, and K. R. Koedinger, “Beyond ex-\\nplicit feedback: new directions in adaptive collaborativelearning support,” in Proceedings of the 9th International\\nConference on Computer Supported Collaborative Learning,vol. 1, Maratea, Italy, June 2009.\\n[47] M. Samarakou, G. Tsaganou, and A. Papadakis, “An\\nE-learning system for extracting text comprehension andlearning style characteristics,” Journal of Educational Tech-\\nnology & Society, vol. 21, no. 1, pp. 126–136, 2018.\\n[48] M.B.Ammar,M.Neji,A.M.Alimi,andG.Gouard `eres,“*e\\naﬀective tutoring system,” Expert Systems with Applications,\\nvol. 37, no. 4, pp. 3013–3023, 2010.\\n[49] I. Arroyo, D. G. Cooper, W. Burleson, B. P. Woolf,\\nK.Muldner,and R. Christopherson, “Emotion sensors gotoschool,” Artiﬁcial Intelligence in Education, vol. 200,\\npp. 17–24, 2009.\\n[50] K. Floyd, J. A. Hess, L. A. Miczo, K. K. Halone,\\nA. C. Mikkelson, and K. J. Tusing, “Human aﬀection ex-\\nchange: VIII. Further evidence of the beneﬁts of expressed\\naﬀection,” Communication Quarterly, vol. 53, no. 3,\\npp. 285–303, 2005.\\n[51] H.-C. K. Lin, C.-H. Wang, C.-J. Chao, and M.-K. Chien,\\n“Employingtextualandfacialemotionrecognitiontodesignan aﬀective tutoring system,” Turkish Online Journal of\\nEducational Technology-TOJET, vol. 11, no. 4, pp. 418–426,\\n2012.\\n[52] X.Zhai,Q.Fang,Y.Dong et al.,“*eeﬀectsofbiofeedback-\\nbased stimulated recall on self-regulated online learning: agender and cognitive taxonomy perspective,” Journal of\\nComputerAssistedLearning,vol.34,no.6,pp.775–786,2018.\\n[53] C.C.Chase,D.B.Chin,M.A.Oppezzo,andD.L.Schwartz,\\n“Teachableagentsandtheprot ´eg´eeﬀect:increasingtheeﬀort\\ntowards learning,” Journal of Science Education and Tech-\\nnology, vol. 18, no. 4, pp. 334–352, 2009.\\n[54] B.M.McLaren,K.E.DeLeeuw,andR.E.Mayer,“Politeweb-\\nbased intelligent tutors: can they improve learning inclassrooms?” Computers & Education, vol. 56, no. 3,\\npp. 574–584, 2011.\\n[55] G. Ngai, S. C. F. Chan, J. C. Y. Chan, and W. W. Y. Lau,\\n“Deploying a wearable computing platform for computingeducation,” IEEE Transactions on Learning Technologies,\\nvol. 3, no. 1, pp. 45–55, 2010.\\n[56] A.Albin-Clark,T.L.J.Howard,andB.Anderson,“Real-time\\ncomputer graphics simulation of blockplay in early child-hood,”Computers&Education,vol.57,no.4,pp.2496–2504,\\n2011.\\n[57] J. M. *omas and R. M. Young, “Annie: automated gen-\\neration of adaptive learner guidance for fun serious games,”IEEE Transactions on Learning Technologies, vol. 3, no. 4,pp. 329–343, 2010.\\n[58] M.-K. Moon, S.-G. Jahng, and T.-Y. Kim, “A computer-\\nassisted learning model based on the digital game expo-nential reward system,” Turkish Online Journal of Educa-\\ntional Technology-TOJET, vol. 10, no. 1, pp. 1–14, 2011.\\n[59] L.-H. Wong and C.-K. Looi, “Swarm intelligence: new\\ntechniques for adaptive systems to provide learning sup-port,”Interactive Learning Environments, vol. 20, no. 1,\\npp. 19–40, 2012.\\n[60] D. A. Seni, “Do the modern neurosciences call for a new\\nmodel of organizational cognition?” Science & Education,\\nvol. 21, no. 10, pp. 1485–1506, 2012.\\n[61] R. D. Heslep, “Education for computers,” Studies in Phi-\\nlosophy and Education, vol. 31, no. 4, pp. 357–364, 2012.\\n[62] D. Higgins and M. Heilman, “Managing what we can\\nmeasure:quantifyingthesusceptibilityofautomatedscoringsystems to gaming behavior,” Educational Measurement:\\nIssues and Practice, vol. 33, no. 3, pp. 36–46, 2014.\\n[63] W. Peng, “Research on online learning behavior analysis\\nmodel in big data environment,” Eurasia Journal of Math-\\nematics, Science and Technology Education, vol. 13, no. 8,pp. 5675–5684, 2017.\\n[64] P. D. MacIntyre, S. C. Baker, and H. Sparling, “Heritage\\npassions, heritage convictions, and the rooted L2 self: musicand Gaelic language learning in Cape Breton, Nova Scotia,”:e Modern Language Journal, vol. 101, no. 3, pp. 501–516,2017.\\n[65] J. E. Aoun, Robot-proof: Higher Education in the Age of\\nArtiﬁcial Intelligence, MIT Press, Cambridge, MA, USA,2017.\\n[66] Y. Sun, “Construction and eﬀect evaluation of Russian\\nwisdom classroom teaching model underthe background of“thebeltandroad”” KuramVeUygulamadaEgitimBilimleri,\\nvol. 18, no. 6, pp. 3477–3485, 2018.\\n[67] J. E. Auerbach, A. Concordel, P. M. Kornatowski, and\\nD. Floreano, “Inquiry-based learning with Robogen: anopen-source software and hardware platform for robotics16 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\nand artiﬁcial intelligence,” IEEE Transactions on Learning\\nTechnologies, vol. 12, no. 3, pp. 356–369, 2018.\\n[68] J. R. Boulet and S. J. Durning, “What we measure . . .and\\nwhat we should measure in medical education . . .and what\\nwe should measure in medical education,” Medical Educa-\\ntion, vol. 53, no. 1, pp. 86–94, 2019.\\n[69] M.Cukurova,C.Kent,andR.Luckin,“Artiﬁcialintelligence\\nand multimodal data in the service of human decision-\\nmaking: a case study in debate tutoring,” British Journal of\\nEducational Technology, vol. 50, no. 6, pp. 3032–3046, 2019.\\n[70] B. Du Boulay, “Escape from the Skinner Box: the case for\\ncontemporary intelligent learning environments,” British\\nJournal of Educational Technology, vol. 50, no. 6, pp. 2902–2919, 2019.\\n[71] C.Hughes,“Howdoparentsguidechildrentowards‘playing\\ntolearn’?Reﬂectionsonfourstudiesinaspecialissueonself-and co-regulation in early childhood,” Metacognition and\\nLearning, vol. 14, no. 3, pp. 315–326, 2019.\\n[72] J. Kay and B. Kummerfeld, “From data to personal user\\nmodels for life-long, life-wide learners,” British Journal of\\nEducational Technology, vol. 50, no. 6, pp. 2871–2884, 2019.\\n[73] K.KittoandS.Knight,“Practicalethicsforbuildinglearning\\nanalytics,” BritishJournalofEducationalTechnology,vol.50,\\nno. 6, pp. 2855–2870, 2019.\\n[74] R. Luckin and M. Cukurova, “Designing educational tech-\\nnologies in the age of AI: a learning sciences-driven ap-proach,” British Journal of Educational Technology, vol. 50,\\nno. 6, pp. 2824–2838, 2019.\\n[75] S. Sellar and K. N. Gulson, “Becoming information centric:\\nthe emergence of new cognitive infrastructures in educationpolicy,”Journal of Education Policy, pp. 1–18, 2019.\\n[76] K. Sharma, Z. Papamitsiou, and M. Giannakos, “Building\\npipelines for educational data using AI and multimodalanalytics: a “grey-box” approach,” British Journal of Edu-\\ncational Technology, vol. 50, no. 6, pp. 3004–3031, 2019.\\n[77] Y.-Y.WangandY.-S.Wang,“Developmentandvalidationof\\nanartiﬁcialintelligenceanxietyscale:aninitialapplicationinpredicting motivated learning behavior,” Interactive Learn-\\ning Environments, pp. 1–16, 2019.\\n[78] M. E. Webb, A. Fluck, J. Magenheim et al., “Machine\\nlearning for human learners: opportunities, issues, tensionsand threats,” Educational Technology Research and Devel-\\nopment, pp. 1–22, 2020.\\n[79] P. Williams, “Does competency-based education with\\nblockchainsignal a newmissionfor universities?” Journal of\\nHigher Education Policy and Management, vol. 41, no. 1,pp. 104–117, 2019.\\n[80] B. Williamson, “Policy networks, performance metrics and\\nplatformmarkets:chartingtheexpandingdatainfrastructureof higher education,” British Journal of Educational Tech-\\nnology, vol. 50, no. 6, pp. 2794–2809, 2019.\\n[81] N. Winters, R. Eynon, A. Geniets, J. Robson, and K. Kahn,\\n“Can we avoid digital structural violence in future learningsystems?” Learning, Media and Technology, vol. 45, no. 1,\\npp. 17–30, 2020.\\n[82] E. Rowe, “Capitalism without capital: the intangible econ-\\nomyof educationreform,” Discourse: Studiesin theCultural\\nPolitics of Education, vol. 40, no. 2, pp. 271–279, 2019.\\n[83] M. Ally, “Competency proﬁle of the digital and online\\nteacher in future education,” International Review of Re-\\nsearchinOpenandDistributedLearning,vol.20,no.2,2019.\\n[84] P.SongandX.Wang,“Abibliometricanalysisofworldwide\\neducational artiﬁcial intelligence research development inrecent twenty years,” Asia Paciﬁc Education Review, vol. 21,\\nno. 3, pp. 473–486, 2020.\\n[85]¨O. G. Ulum, “A critical deconstruction of computer-basedtest application in Turkish State University,” 2020.\\n[86] R.Costa-Mendes,T.Oliveira,M.Castelli,andF.Cruz-Jesus,\\n“A machine learning approximation of the 2015 Portuguesehigh school student grades: a hybrid approach,” Education\\nand Information Technologies, vol. 26, no. 2, pp.1527–1547,2020.\\n[87] X.Zhai,L.Shi,andR.H.Nehm,“Ameta-analysisofmachine\\nlearning-based science assessments: factors impacting ma-chine-human score agreements,” Journal of Science Educa-\\ntion and Technology, pp. 1–19, 2020.\\n[88] M. Loftus and M. G. Madden, “A pedagogy of data and\\nartiﬁcial intelligence for student subjectiﬁcation,” Teaching\\nin Higher Education, vol. 25, no. 4, pp. 456–475, 2020.\\n[89] M. R. Breines and M. Gallagher, “A return to Teacherbot:\\nrethinkingthedevelopmentofeducationaltechnologyattheUniversity of Edinburgh,” Teaching in Higher Education,\\npp. 1–15, 2020.\\n[90] M. Campo, A. Amandi, and J. C. Biset, “A software archi-\\ntecture perspective about Moodle ﬂexibility for supportingempirical research of teaching theories,” Education and\\nInformation Technologies, vol. 26, no. 1, pp. 817–842, 2020.\\n[91] I. Papadopoulos, R. Lazzarino, S. Miah, T. Weaver,\\nB. *omas, and C. Koulouglioti, “A systematic review of theliterature regarding socially assistive robots in pre-tertiaryeducation,” Computers and Education, vol. 155, 2020.\\n[92] B. Berendt, A. Littlejohn, and M. Blakemore, “AI in edu-\\ncation: learner choice and fundamental rights,” Learning,\\nMedia and Technology, vol. 45, no. 3, pp. 312–324, 2020.\\n[93] P.J.Standen,D.J.Brown,M.Taherietal.,“Anevaluationof\\nan adaptive learning system based on multimodal aﬀect\\nrecognitionforlearnerswithintellectualdisabilities,” British\\nJournal of Educational Technology, vol. 51, no. 5, pp. 1748–\\n1765, 2020.\\n[94] C. Liu, Y. Feng, and Y. Wang, “An innovative evaluation\\nmethodfor undergraduate education: an approach basedonBP neural network and stress testing,” Studies in Higher\\nEducation, pp. 1–17, 2020.\\n[95] B. Cope, M. Kalantzis, and D. Searsmith, “Artiﬁcial intelli-\\ngence for education: knowledge and its assessment in AI-enabled learning ecologies,” Educational Philosophy and\\n:eory, pp. 1–17, 2020.\\n[96] W. Westera, R. Prada, S. Mascarenhas et al., “Artiﬁcial in-\\ntelligence moving serious gaming: presenting reusable gameAI components,” Education and Information Technologies,\\nvol. 25, no. 1, pp. 351–380, 2020.\\n[97] N. Bonneton-Bott ´e, S. Fleury, N. Girard et al., “Can tablet\\napps support the learning of handwriting? An investigationoflearningoutcomesinkindergartenclassroom,” Computers\\n& Education, vol. 151, p. 103831, 2020.\\n[98] P. Smutny and P. Schreiberova, “Chatbots for learning: a\\nreviewofeducationalchatbotsfortheFacebookMessenger,”Computers & Education, vol. 151, Article ID 103862, 2020.\\n[99] L. Lucy,D. Demszky,P.Bromley, andD. Jurafsky, “Content\\nanalysis of textbooks via natural language processing:\\nﬁndings on gender, race, and ethnicity in Texas US history\\ntextbooks,” AERA Open, vol. 6, no. 3, Article ID\\n2332858420940312, 2020.\\n[100] M.N.Yakubu,S.I.Dasuki,A.M.Abubakar,andM.M.Kah,\\n“DeterminantsoflearningmanagementsystemsadoptioninNigeria: a hybrid SEM and artiﬁcial neural networkComplexity 17\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\napproach,” Education and Information Technologies, vol. 25,\\nno. 5, pp. 3515–3539, 2020.\\n[101] B.Bonami,L.Piazentini,andA.Dala-Possa,“Education,big\\ndata and artiﬁcial intelligence: mixed methods in digital\\nplatforms,” Comunicar, vol. 28, no. 65, pp. 43–52, 2020.\\n[102] M. M. Ko ´c-Januchta, K. J. Sch ¨onborn, L. A. Tibell,\\nV.K.Chaudhri,andH.C.Heller,“Engagingwithbiologyby\\nasking questions: investigating students’ interaction and\\nlearning with an artiﬁcial intelligence-enriched textbook,”Journal of Educational Computing Research, vol. 58, no. 6,pp. 1190–1224, Article ID 0735633120921581, 2020.\\n[103] B. D. Nye, D. M. Davis, S. Z. Rizvi et al., “Feasibility and\\nusability of MentorPal, a framework for rapid developmentof virtual mentors,” Journal of Research on Technology in\\nEducation, vol. 53, no. 1, pp. 21–43, 2021.\\n[104] P. T. Webb, S. Sellar, and K. N. Gulson, “Anticipating ed-\\nucation: governing habits, memories and policy-futures,”\\nLearning,MediaandTechnology,vol.45,no. 3,pp.284–297,\\n2020.\\n[105] S. C. Tsai, C. H. Chen, Y. T. Shiao, J. S. Ciou, and T. N. Wu,\\n“Precision education with statistical learning and deeplearning: a case study in Taiwan,” International Journal of\\nEducational Technology in Higher Education, vol. 17, pp. 1–\\n13, 2020.\\n[106] E. Alyahyan and D. D¨ us ¸teg ¨or, “Predicting academic success\\nin higher education: literature review and best practices,”International Journal of Educational Technology in Higher\\nEducation, vol. 17, no. 1, p. 3, 2020.\\n[107] A.RenzandR.Hilbig,“Prerequisitesforartiﬁcialintelligence\\nin further education: identiﬁcation of drivers, barriers, andbusiness models of educational technology companies,”International Journal of Educational Technology in Higher\\nEducation, vol. 17, pp. 1–21, 2020.\\n[108] K. N. Gulson and K. Witzenberger, “Repackaging authority:\\nartiﬁcial intelligence, automated governance and educationtrade shows,” Journal of Education Policy, pp. 1–16, 2020.\\n[109] N. Kerimbayev, N. Beisov, A. Kovtun, N. Nurym, and\\nA. Akramova, “Robotics in the international educationalspace: integration and the experience,” Education and In-\\nformation Technologies, vol. 25, no. 6, pp. 5835–5851, 2020.\\n[110] S. Fu, H. Gu, and B. Yang, “*e aﬀordances of AI-enabled\\nautomatic scoring applications on learners’ continuous\\nlearning intention: an empirical study in China,” British\\nJournal of Educational Technology, vol. 51, no. 5, pp. 1674–\\n1692, 2020.\\n[111] S.Z.Salas-Pilco,“*eimpactofAIandroboticsonphysical,\\nsocial-emotional and intellectual learning outcomes: an in-tegrated analytical framework,” British Journal of Educa-\\ntional Technology, vol. 51, no. 5, pp. 1808–1825, 2020.\\n[112] T.Yıldız,“*emosteﬀectiveelementinconceptualizationis\\nsocialinteraction,notsourceormodality:anewmodelofthe\\nconceptualdevelopment in children,” Learning, Culture and\\nSocial Interaction, vol. 24, Article ID 100377, 2020.\\n[113] M. G. Tolsgaard, C. K. Boscardin, Y. S. Park, M. M. Cuddy,\\nand S. S. Sebok-Syer, “*e role of data science and machinelearning in health professions education: practical applica-\\ntions, theoretical contributions, and epistemic beliefs,” Ad-\\nvances in Health Sciences Education, vol. 25, no. 5,\\npp. 1057–1086, 2020.\\n[114] L. Hsu, “To CALL or not to CALL: empirical evidence from\\nneuroscience,” Computer Assisted Language Learning,\\npp. 1–24, 2020.\\n[115] J.-Y. Wu, Y.-C. Hsiao, and M.-W. Nian, “Using supervised\\nmachine learning on large-scale online forums to classifycourse-related Facebook messages in predicting learning\\nachievement within the personal learning environment,”\\nInteractive Learning Environments, vol. 28, no.1, pp. 65–80,\\n2020.\\n[116] S. Wang, C. Christensen, W. Cui et al., “When adaptive\\nlearning is eﬀective learning: comparison of an adaptive\\nlearning system to teacher-led instruction,” Interactive\\nLearning Environments, pp. 1–11, 2020.\\n[117] K. Rybinski and E. Kopciuszewska, “Will artiﬁcial intelli-\\ngencerevolutionisethestudentevaluationofteaching?Abigdata study of 1.6 million student reviews,” Assessment &\\nEvaluation in Higher Education, pp. 1–13, 2020.\\n[118] T. P. Tran and D. Meacheam, “Enhancing learners’ expe-\\nrience through extending learning systems,” IEEE Transac-\\ntions on Learning Technologies, vol. 13, no. 3, pp. 540–551,2020.\\n[119] B. P. Woolf, A Roadmap for Education Technology (hal-\\n00588291), University of Massachusetts Amherst, Amherst,\\nMA, USA, 2010.\\n[120] T. Lewin, After Setbacks, Online Courses Are Rethought, *e\\nNew York Times, New York City, NY, USA, 2013.18 Complexity\\n 8503, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1155/2021/8812542 by Sri Lanka National Access, Wiley Online Library on [22/11/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\"}, {'document_name': 'Machine-Learning-Algorithms-A-Review.pdf', 'file_path': '../data\\\\Folder1\\\\Machine-Learning-Algorithms-A-Review.pdf', 'content': 'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/344717762\\nMachine Learning Algorithms -A Review\\nTechnic al R eport \\xa0\\xa0 in\\xa0\\xa0International Journal of Scienc e and R esearch (IJSR)  · Januar y 2019\\nDOI: 10.21275/ ART20203995\\nCITATIONS\\n1,179READS\\n387,705\\n1 author:\\nBatt a Mahesh\\nIndependent R esearcher\\n5 PUBLICA TIONS \\xa0\\xa0\\xa01,183  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Batt a Mahesh  on 17 Oct ober 2020.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\nMachine Learning Algorithms \\n-\\n \\nA Review\\n \\n \\nBatta Mahesh\\n \\n \\nAbstract:\\n \\nMachine learning\\n \\n(\\nML\\n) is the\\n \\nscientific study\\n \\nof\\n \\nalgorithms\\n \\nand\\n \\nstatistical models\\n \\nthat\\n \\ncomputer systems\\n \\nuse to perform a \\nspecific task without being explicitly programmed. \\nLearning algorithms in many applications that’s we make use of daily. Every time a \\nweb search engine li\\nke Google is used to search the internet, one of the reasons that work so well is because a learning algorithm that \\nhas learned how to rank web pages. These algorithms are used for various purposes like data mining, image processing, predict\\nive \\nanalytics, \\netc. to name a few. The main advantage of using machine learning is that, once an algorithm learns what to do with data, it \\ncan do its work automatically. In this paper, a brief review and future prospect of the vast applications of machine learning\\n \\nalgori\\nthms\\n \\nhas been made.\\n \\n \\n \\nKeywords: \\nAlgorithm, Machine Learning, Pseudo Code, Supervised learning, Unsupervised learning, Reinforcement learning\\n \\n \\n1.\\n \\nIntroduction\\n \\n \\nSince \\ntheir evolution, humans have been using many types \\nof tools to accomplish various tasks in a simpler way. The \\ncreativity of the human brain led to the invention of different \\nmachines. These machines made the human life easy by \\nenabling \\npeople\\n \\nto meet various life needs, including \\ntravelling, industries, and computing. And Machine learning \\nis the one among them.\\n \\n \\nAccording to Arthur Samuel Machine learning is defined as \\nthe field of study that gives computers the ability to learn \\nwithout \\nbeing explicitly programmed. Arthur Samuel was \\nfamous for his checkers playing program. \\nMachine learning \\n(ML)\\n \\nis used to teach machines how to handle the data more \\nefficiently. Sometimes after viewing the data, we cannot \\ninterpret the extract information f\\nrom the data. In that case, \\nwe apply machine learning. With the abundance of datasets \\navailable, the demand for machine learning is in rise. Many \\nindustries apply machine learning to extract relevant data. \\nThe purpose of machine learning is to learn from t\\nhe data. \\nMany studies have been done on how to make machines \\nlearn by themselves without being explicitly programmed. \\nMany mathematicians and programmers apply several \\napproaches to find the solution of this problem which are \\nhaving huge data sets. \\n \\nMachine Learning relies on different algorithms to solve \\ndata problems. Data scientists like to point out that there‟s \\nno single one\\n-\\nsize\\n-\\nfits\\n-\\nall type of algorithm that is best to \\nsolve a \\nproblem. The kind of algorithm employed depends \\non the kind of problem you wish to solve, the number of \\nvariables, the kind of model that would suit it best and so on. \\nHere‟s a quick look at some of the commonly used \\nalgorithms in machine learning (ML)\\n \\n \\nSu\\npervised Learning\\n \\nSupervised learning\\n \\nis the\\n \\nmachine learning\\n \\ntask of learning \\na function that maps an input to an output based on example \\ninput\\n-\\noutput pairs.\\n \\nIt infers a function from\\n \\nlabelled\\n \\ntraining \\ndata\\n \\nconsisting of a set of\\n \\ntraining examples. The su\\npervised \\nmachine learning algorithms are those algorithms which \\nneeds external assistance. The input dataset is divided into \\ntrain and test dataset. The train dataset has output variable \\nwhich needs to be predicted or classified. All algorithms \\nlearn some \\nkind of patterns from the training dataset and \\napply them to the test dataset for prediction or classification. \\nThe workflow of supervised machine learning algorithms is \\ngiven in fig below. Most famous supervised machine \\nlearning algorithms have been discu\\nssed here\\n \\n \\nFig\\nure:\\n \\nSupervised learning Workflow\\n \\n \\n \\n \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n381 International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\nDecision Tree\\n \\nDecision tree is a graph to represent choices and their results \\nin form of a tree. The nodes in the graph represent an event \\nor choice and the edges of the graph represent the decision \\nrules\\n \\nor conditions\\n. \\nEach tree consists of nodes and \\nbranches. Each node represents attributes in a group that is \\nto be classified and each branch represents a value that the \\nnode can take\\n.\\n \\n \\n \\nFig\\nure\\n: \\nDecision Tree\\n \\n \\nDecision Tree Pseudo Code:\\n \\ndef \\n \\ndecisionTreeLearning(examples, attributes, \\nparent_examples):\\n \\nif len(examples) == 0:\\n \\nreturn pluralityValue(parent_examples)\\n \\n# return most probable answer as there is no training data \\nleft\\n \\nelif len(attributes) == 0:\\n \\nreturn pluralityValue(examples)\\n \\nelif (all \\nexamples classify the same):\\n \\nreturn their classification\\n \\nA = max(attributes, key(a)=importance(a, examples)\\n \\n# choose the most promissing attribute to condition on\\n \\ntree = new Tree(root=A)\\n \\nfor value in A.values():\\n \\nexs = examples[e.A == value]\\n \\nsubtree = decis\\nionTreeLearning(exs, attributes.remove(A), \\nexamples)\\n \\n# note implementation should probably wrap the trivial case \\nreturns into trees for consistency\\n \\ntree.addSubtreeAsBranch(subtree, label=(A, value)\\n \\nreturn tree\\n \\n \\nNavie Bayes\\n \\nIt is a classification technique \\nbased on\\n \\nBayes\\n \\nTheorem with \\nan assumption of independence among predictors. In simple \\nterms, a\\n \\nNaive Bayes classifier\\n \\nassumes that the presence of \\na particular feature in a class is unrelated to the presence of \\nany other feature. \\nNaïve Bayes mainly targets\\n \\nthe text \\nclassification industry. It is mainly used for clustering and \\nclassification purpose depends on the conditional probability \\nof happening.\\n \\n \\nFig\\nure:\\n \\nNavie Bayes\\n \\n \\nPseudo Code of Navie Bayes\\n \\nInput\\n:\\n \\nTraining dataset T, \\n \\nF= (f1, f2, f3,.., fn) // value of the predictor variable in \\ntesting dataset. \\n \\nOutput\\n: A class of testing dataset. \\n \\nStep\\ns\\n: \\n \\n1)\\n \\nRead the training dataset T; \\n \\n2)\\n \\nCalculate the mean and standard deviation of the \\npredictor variables in each class; \\n \\n3)\\n \\nRepeat Calculate \\nthe probability of fi using the gauss \\ndensity equation in each class; Until the probability of all \\npredictor variables (f1, f2, f3,.., fn) has been calculated. \\n \\n4)\\n \\nCalculate the likelihood for each class; \\n \\n5)\\n \\nGet the greatest likelihood\\n \\n \\nSupport Vector Machine\\n \\nAnother most widely used state\\n-\\nof\\n-\\nthe\\n-\\nart machine learning \\ntechnique is Support Vector Machine (SVM).\\n \\nIn\\n \\nmachine \\nlearning,\\n \\nsupport\\n-\\nvector machines\\n \\nare\\n \\nsupervised \\nlearning\\n \\nmodels with associated learning\\n \\nalgorithms\\n \\nthat \\nanalyze data used for\\n \\nclassification\\n \\nand\\n \\nregression analysis.\\n \\nIn addition to performing\\n \\nlinear classification, SVMs can \\nefficiently perform a non\\n-\\nlinear classification using what is \\ncalled the\\n \\nkernel trick, implicitly mapping their inputs into \\nhigh\\n-\\ndimensional feature spaces.\\n \\nIt basically, dr\\naw margins \\nbetween the classes. The margins are drawn in such a \\nfashion that the distance between the margin and the classes \\nis maximum and hence, minimizing the classification error.\\n \\n \\n \\nFig\\nure\\n: \\nSupport Vector Machine\\n \\n \\nPseudo Code of Support Vector Machine\\n \\ninitialize Yi = YI for i \\n⋹\\n \\nI \\n \\nrepeat \\n \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n382 International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\ncompute svm solution vv , b for data set with imputed labels \\ncompute outputs ii = (vv , xi) + b for all xi in positive bags \\nset yi = sgn(fi) for every i e i, yi = 1 \\n \\nfor (every positive bag bi) end \\n \\nif (liei(l + yi)/2 == 0) \\n \\ncompute i* = arg maxiei ii \\n \\nset yi* = 1 \\n \\nend \\n \\nwhile (imputed labels have changed) \\n \\noutput (vv, b)\\n \\n \\nUnsupervised\\n \\nLearning:\\n \\nThese are called unsupervised learning because unlike \\nsupervised learning above there is no correct answers and \\nthere is no teacher. Algorithms are left to their own devises \\nto discover and present the interesting structure in the data. \\nThe unsupervised le\\narning algorithms learn few features \\nfrom the data. When new data is introduced, it uses the \\npreviously learned features to recognize the class of the data. \\nIt is mainly used for clustering and feature reduction.\\n \\n \\n \\nFig\\nure:\\n \\nUnsupervised Learning\\n \\n \\nPrincipal\\n \\nComponent Analysis\\n \\nPrincipal component analysis is a statistical procedure that \\nuses an orthogonal transformation to convert a set of \\nobservations of possibly correlated variables into a set of \\nvalues of linearly uncorrelated variables called principal \\nco\\nmponents. In this \\nthe dimension of the data is reduced to \\nmake the computations faster and easier.\\n \\nIt\\n \\nis\\n \\nused\\n \\nto explain \\nthe variance\\n-\\ncovariance structure of a set of variables \\nthrough linear combinations. It is often\\n \\nused\\n \\nas a \\ndimensionality\\n-\\nreduction tec\\nhnique.\\n \\n \\nFig\\nure:\\n \\nPrincipal Component Analysis\\n \\n \\nK\\n-\\nMeans Clustering\\n \\nK\\n-\\nmeans is\\n \\none of the\\n \\nsimplest unsupervised learning \\nalgorithms that solve the well known clustering problem.\\n \\nThe\\n \\nprocedure \\nfollows a simple and easy way\\n \\nto classify a \\ngiven data set through a\\n \\ncertain number of\\n \\nclusters. The \\nmain idea is to\\n \\ndefine k centers, one for each cluster. These \\ncenters should\\n \\nbe placed in a cunning\\n \\nway\\n \\nbecause of \\ndifferent\\n \\nlocation\\n \\ncauses different resu\\nlt. So, the better \\nchoice\\n \\nis\\n \\nto place them\\n \\nis much as possible far away from \\neach other.\\n \\n \\n \\nFig\\nure\\n:\\n \\nK\\n-\\nMeans Clustering\\n \\nTh\\ne\\n \\nnext\\n \\nstep is to\\n \\ntake each point belonging\\n \\nto a given data \\nset and associate it to the nearest center.\\n \\nWhen no point\\n \\nis \\npending, the first step is completed and an early group age \\nis\\n \\ndone.\\n \\nAt this point we need to re\\n-\\ncalculate k new centroids \\nas bary\\n \\ncente\\nr of the\\n \\nclusters resulting from the previous \\nstep.\\n \\n \\nFigure: \\nPseudo Code of \\nK\\n-\\nMeans Clustering\\n \\n \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n383 International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\nSemi Supervise Learning:\\n \\nSemi\\n-\\nsupervised machine learning\\n \\nis a combination \\nof\\n \\nsupervised\\n \\nand unsupervised\\n \\nmachine learning\\n \\nmethods.\\n \\nIt can be fruit\\n-\\nfull in those areas of machine learning and \\ndata mining where the unlabeled data is already present and \\ngetting the labeled data is a tedious process\\n. With more \\ncommon\\n \\nsupervised machine learning\\n \\nmethods, you train \\na\\n \\nmachine learning\\n \\nalgor\\nithm on a “labeled” dataset in \\nwhich each record includes the outcome information. The \\nsome of Semi Supervise learning algorithms are discussed \\nbelow\\n \\n \\nTransductive SVM\\n \\nTransductive support vector machines (TSVM) has been \\nwidely used as a means of treating \\npartially labeled data in \\nsemisupervised learning. Around it, there has been mystery \\nbecause of lack of understanding its foundation in \\ngeneralizatio\\nn. It is used to label the unlabeled data in such a \\nway that the margin is maximum between the labeled and \\nunlabeled data. Finding an exact solution by TSVM is a NP\\n-\\nhard problem.\\n \\n \\nGenerative Models\\n \\nA Generative model is the one\\n \\nthat can generate data\\n. It \\nmodels both the features and the class (i.e. the complete \\ndata). If we model\\n \\nP(x,y): I can use this \\nprobability \\ndistribution to generate data points \\n-\\n \\nand hence all \\nalgorithms modeling\\n \\nP(x,y)\\n \\nare generative.\\n \\nOne labeled \\nexample per component is enough to confirm the mixture \\ndistribution.\\n \\n \\nSelf\\n-\\nTraining\\n \\nIn self\\n-\\ntraining, a classifier is trained with a por\\ntion of \\nlabeled data. The classifier is then fed with unlabeled data. \\nThe unlabeled points and the predicted labels are added \\ntogether in the training set. This procedure is then repeated \\nfurther. Since the classifier is learning itself, hence the name \\nsel\\nf\\n-\\ntraining.\\n \\n \\nReinforcement Learning\\n \\nReinforcement learning is an area of machine learning \\nconcerned with how software agents ought to take actions in \\nan environment in order to maximize some notion of \\ncumulative reward. Reinforcement learning is one of thr\\nee \\nbasic machine learning paradigms, alongside supervised \\nlearning and unsupervised learning\\n.\\n \\n \\n \\nFig\\nure\\n: \\nReinforcement Learning\\n \\n \\nMultitask Learning\\n \\nMulti\\n-\\nTask learning is a sub\\n-\\nfield of Machine Learning that \\naims to solve multiple different tasks at the \\nsame time, by \\ntaking advantage of the similarities between different tasks. \\nThis can improve the learning efficiency and also act as a \\nregularize.\\n \\nFormally, if there are\\n \\nn\\n \\ntasks (conventional deep \\nlearning approaches aim to solve just 1 task using 1 \\npartic\\nular model), where these\\n \\nn\\n \\ntasks or a subset of them \\nare related to each other but not exactly identical, Multi\\n-\\nTask Learning\\n \\n(MTL)\\n \\nwill help in improving the learning of \\na particular model by using the knowledge contained in all \\nthe n tasks.\\n \\n \\nEnsemble \\nLearning\\n \\nEnsemble\\n \\nlearning\\n \\nis the process by which multiple models, \\nsuch as classifiers or experts, are strategically generated and \\ncombined to solve a particular\\n \\ncomputational\\n \\nintelligence\\n \\nproblem. Ensemble learning is primarily used to \\nimprove the perfor\\nmance of a model, or reduce the \\nlikelihood of an unfortunate selection of a poor one. Other \\napplications of ensemble learning include assigning a \\nconfidence to the decision made by the model, selecting \\noptimal features, data fusion, incremental learning, n\\non\\n-\\nstationary learning and error\\n-\\ncorrecting.\\n \\n \\nBoosting:\\n \\nThe term „Boosting‟ refers to a family of algorithms \\nwhich\\n \\nconverts weak learner to strong learners.\\n \\nBoosting is a \\ntechnique in ensemble learning which is used to decrease \\nbias and variance.\\n \\nBoosting is based on the question posed \\nby\\n \\nKearns\\n \\nand\\n \\nValiant \\n“\\nCan a set of weak learners create \\na single strong learner?\"\\n \\nA weak learner is defined to be \\na\\n \\nclassifier, a strong learner is a classifier that is arbitrarily \\nwell\\n-\\ncorrelated with the true cla\\nssification.\\n \\n \\n \\nFig\\nure\\n: \\nBoosting Pseudo code\\n \\n \\nBagging\\n \\nBagging or bootstrap aggregating is applied where the \\naccuracy and stability of a machine learning algorithm needs \\nto be increased. It is applicable in classification and \\nregression. Bagging also \\ndecreases variance and helps in \\nhandling overfitting.\\n \\n \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n384 International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\n \\nFig\\nure\\n:\\n \\nPseudo code of Bagging\\n \\n \\nNeu\\nral Networks\\n \\nA neural network is a series of algorithms that endeavors to \\nrecognize underlying relationships in a set of data through a \\nprocess that mimics the way \\nthe human brain operates. In \\nthis sense, neural networks refer to systems of neurons, \\neither organic or artificial in nature. Neural networks can \\nadapt to changing input; so the network generates the best \\npossible result without needing to redesign the out\\nput \\ncriteria. The concept of neural networks, which has its roots \\nin\\n \\nartificial intelligence, is swiftly gaining popularity in the \\ndevelopment of\\n \\ntrading systems.\\n \\n \\n \\nFigure: \\nNeu\\nral Networks\\n \\n \\nAn artificial neural network behaves the same way. It works \\non \\nthree layers. The input layer takes input. The hidden layer \\nprocesses the input. Finally, the output layer sends the \\ncalculated output.\\n \\n \\nSupervised Neural Network\\n \\nIn the supervised neural network, the output of the input is \\nalready known. The predicted out\\nput of the neural network \\nis compared with the actual output. Based on the error, the \\nparameters are changed, and then fed into t\\nhe neural network \\nagain\\n. Supervised neural network is used in feed forward \\nneural network\\n.\\n \\n \\nFig\\nure\\n: \\nSupervised Neural Network\\n \\n \\n \\nUnsupervised Neural Network\\n \\nThe neural network has no prior clue about the output the \\ninput. The main job of the network is to categorize the data \\naccording to some similarities. The neural network checks \\nthe correlation between various inputs and groups\\n \\nthem.\\n \\n \\n \\nFig\\nure\\n: \\nUnsupervised Neural Network\\n \\n \\nReinforced Neural Network\\n \\nReinforcement learning refers to goal\\n-\\noriented algorithms, \\nwhich learn how to attain a complex objective (goal) or \\nmaximize along a particular dimension over many steps; for \\nexample, \\nmaximize the points won in a game over many \\nmoves. They can start from a blank slate, and under the right \\nconditions they achieve superhuman performance. Like a \\nchild incentivized by spankings and candy, these algorithms \\nare penalized when they make the wr\\nong decisions and \\nrewarded when they make the right ones \\n–\\n \\nthis is \\nreinforcement.\\n \\n \\nFig\\nure\\n: \\nReinforced Neural Network\\n \\n \\nInstance\\n-\\nBased Learning\\n \\nInstance\\n-\\nbased learning refers to a family of techniques \\nfor\\n \\nclassification and\\n \\nregression, which produce a class \\nlabel/predication based on the similarity of the query to its \\nnearest neighbor(s) in the training set. In explicit contrast to \\nother methods s\\nuch as\\n \\ndecision trees\\n \\nand\\n \\nneural networks, \\ninstance\\n-\\nbased learning algorithms do not create an \\nabstraction from specific instances. Rather, they simply store \\nall the data, and at query time derive an answer from an \\nexamination of the queries\\n \\nnearest \\nneighb\\nour \\n(s).\\n \\n \\nK\\n-\\nNearest Neighbor\\n \\nThe\\n \\nk\\n-\\nnearest neighbors\\n \\n(\\nKNN\\n) algorithm is a simple, \\nsupervised machine learning algorithm that can be used to \\nsolve both classification and regression problems. It\\'s easy to \\nimplement and understand, but has a major drawback of \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n385 International Journal of Science and Research (IJSR)\\n \\nISSN: 2319\\n-\\n7064\\n \\nResearchGate Impact Factor (2018): 0.28 \\n| SJIF (2018): 7.426\\n \\nVolume 9 Issue 1, January 2020\\n \\nwww.ijsr.net\\n \\nLicensed Under Creative Commons Attribution CC BY\\n \\nbecoming significantly slows as the size of that data i\\nn use \\ngrows.\\n \\n \\n \\nFig\\nure\\n: \\nPseudo code of KNN\\n \\n \\n2.\\n \\nConclusion\\n \\n \\nMachine Learning can be a Supervised or Unsupervised. If \\nyou have lesser amount of data and clearly labelled data for \\ntraining, opt for Supervised Learning. Unsupervised \\nLearning would generally give \\nbetter performance and \\nresults for large data sets. If you have a huge data set easily \\navailable, go for deep learning techniques. You also have \\nlearned Reinforcement Learning and Deep Reinforcement \\nLearning. You now know what Neural Networks are, their \\nap\\nplications and limitations.\\n \\nThis paper surveys various \\nmachine learning algorithms. Today each and every person \\nis using machine learning knowingly or unknowingly. From \\ngetting a recommended product in online shopping to \\nupdating photos in social networkin\\ng sites. This paper gives \\nan introduction to most of the popular machine learning \\nalgorithms.\\n \\n \\nReferences\\n \\n \\n[1]\\n \\nW. Richert, L. P. Coelho, “Building Machine Learning \\nSystems with Python”, Packt Publishing Ltd., ISBN \\n978\\n-\\n1\\n-\\n78216\\n-\\n140\\n-\\n0\\n \\n[2]\\n \\nJ. M. Keller, M. R. Gray, J.\\n \\nA. Givens Jr., “A Fuzzy K\\n-\\nNearest Neighbor Algorithm”, IEEE Transactions on \\nSystems, Man and Cybernetics, Vol. SMC\\n-\\n15, No. 4, \\nAugust 1985\\n \\n[3]\\n \\nhttps://www.geeksforgeeks.org/machine\\n-\\nlearning/\\n \\n[4]\\n \\n] S. Marsland, Machine learning: an algorithmic \\nperspective. CRC pres\\ns, 2015.\\n \\n[5]\\n \\nM. Bkassiny, Y. Li, and S. K. Jayaweera, “A survey on \\nmachine\\n \\nlearning techniques in cognitive radios,” IEEE \\nCommunications Surveys & Tutorials, vol. 15, no. 3, \\npp. 1136\\n–\\n1159, Oct. 2012.\\n \\n[6]\\n \\nhttps://en.wikipedia.org/wiki/Instance\\n-\\nbased_learning\\n \\n[7]\\n \\nR. S. \\nSutton, “Introduction: The Challenge of \\nReinforcement Learning”, Machine Learning, 8, Page \\n225\\n-\\n227, Kluwer Academic Publishers, Boston, 1992\\n \\n[8]\\n \\nP. Harrington, “Machine Learning in action”, Manning \\nPublications Co., Shelter Island, New York, 2012\\n \\n \\n \\n \\nPaper ID: ART20203995\\nDOI: 10.21275/ART20203995\\n386 \\nView publication stats'}, {'document_name': 'A_Survey_on_Big_Data_Analytics_Challenge.pdf', 'file_path': '../data\\\\Folder2\\\\A_Survey_on_Big_Data_Analytics_Challenge.pdf', 'content': 'A Survey on Big Data Analytics: Challenges, Open\\nResearch Issues and Tools\\nD.  P. Acharjya\\nSchool  of Computing  Science  and  Engineering  \\nVIT  University\\nVellore,  India  632014Kauser  Ahmed  P\\nSchool  of Computing  Science  and  Engineering  \\nVIT  University\\nVellore,  India  632014\\nAbstract —A huge repository of terabytes of data is generated\\neach day from modern information systems and digital technolo-\\ngies such as Internet of Things and cloud computing. Analysis\\nof these massive data requires a lot of efforts at multiple levels\\nto extract knowledge for decision making. Therefore, big data\\nanalysis is a current area of research and development. The basic\\nobjective of this paper is to explore the potential impact of big\\ndata challenges, open research issues, and various tools associated\\nwith it. As a result, this article provides a platform to explore\\nbig data at numerous stages. Additionally, it opens a new horizon\\nfor researchers to develop the solution, based on the challenges\\nand open research issues.\\nKeywords —Big data analytics; Hadoop; Massive data; Struc-\\ntured data; Unstructured Data\\nI. I NTRODUCTION\\nIn digital world, data are generated from various sources\\nand the fast transition from digital technologies has led to\\ngrowth of big data. It provides evolutionary breakthroughs in\\nmany ﬁelds with collection of large datasets. In general, it\\nrefers to the collection of large and complex datasets which\\nare difﬁcult to process using traditional database management\\ntools or data processing applications. These are available\\nin structured, semi-structured, and unstructured format in\\npetabytes and beyond. Formally, it is deﬁned from 3Vs to 4Vs.\\n3Vs refers to volume, velocity, and variety. V olume refers to\\nthe huge amount of data that are being generated everyday\\nwhereas velocity is the rate of growth and how fast the data\\nare gathered for being analysis. Variety provides information\\nabout the types of data such as structured, unstructured, semi-\\nstructured etc. The fourth V refers to veracity that includes\\navailability and accountability. The prime objective of big data\\nanalysis is to process data of high volume, velocity, variety, and\\nveracity using various traditional and computational intelligent\\ntechniques [1]. Some of these extraction methods for obtaining\\nhelpful information was discussed by Gandomi and Haider\\n[2]. The following Figure 1 refers to the deﬁnition of big\\ndata. However exact deﬁnition for big data is not deﬁned and\\nthere is a believe that it is problem speciﬁc. This will help us\\nin obtaining enhanced decision making, insight discovery and\\noptimization while being innovative and cost-effective.\\nIt is expected that the growth of big data is estimated to\\nreach 25 billion by 2015 [3]. From the perspective of the\\ninformation and communication technology, big data is a ro-\\nbust impetus to the next generation of information technologyindustries [4], which are broadly built on the third platform,\\nmainly referring to big data, cloud computing, internet of\\nthings, and social business. Generally, Data warehouses have\\nbeen used to manage the large dataset. In this case extracting\\nthe precise knowledge from the available big data is a foremost\\nissue. Most of the presented approaches in data mining are not\\nusually able to handle the large datasets successfully. The key\\nproblem in the analysis of big data is the lack of coordination\\nbetween database systems as well as with analysis tools such as\\ndata mining and statistical analysis. These challenges generally\\narise when we wish to perform knowledge discovery and repre-\\nsentation for its practical applications. A fundamental problem\\nis how to quantitatively describe the essential characteristics\\nof big data. There is a need for epistemological implications\\nin describing data revolution [5]. Additionally, the study on\\ncomplexity theory of big data will help understand essential\\ncharacteristics and formation of complex patterns in big data,\\nsimplify its representation, gets better knowledge abstraction,\\nand guide the design of computing models and algorithms\\non big data [4]. Much research was carried out by various\\nresearchers on big data and its trends [6], [7], [8].\\nHowever, it is to be noted that all data available in the\\nform of big data are not useful for analysis or decision making\\nprocess. Industry and academia are interested in disseminating\\nthe ﬁndings of big data. This paper focuses on challenges in\\nbig data and its available techniques. Additionally, we state\\nopen research issues in big data. So, to elaborate this, the\\npaper is divided into following sections. Sections 2 deals\\nwith challenges that arise during ﬁne tuning of big data.\\nSection 3 furnishes the open research issues that will help\\nus to process big data and extract useful knowledge from it.\\nSection 4 provides an insight to big data tools and techniques.\\nConclusion remarks are provided in section 5 to summarize\\noutcomes.\\nII. C HALLENGES IN BIGDATA ANALYTICS\\nRecent years big data has been accumulated in several\\ndomains like health care, public administration, retail, bio-\\nchemistry, and other interdisciplinary scientiﬁc researches.\\nWeb-based applications encounter big data frequently, such\\nas social computing, internet text and documents, and inter-\\nnet search indexing. Social computing includes social net-\\nwork analysis, online communities, recommender systems,\\nreputation systems, and prediction markets where as internet\\nsearch indexing includes ISI, IEEE Xplorer, Scopus, Thomson(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n511 | P a g e\\nwww.ijacsa.thesai.org Fig. 1: Characteristics of Big Data\\nReuters etc. Considering this advantages of big data it provides\\na new opportunities in the knowledge processing tasks for\\nthe upcoming researchers. However oppotunities always follow\\nsome challenges.\\nTo handle the challenges we need to know various compu-\\ntational complexities, information security, and computational\\nmethod, to analyze big data. For example, many statistical\\nmethods that perform well for small data size do not scale\\nto voluminous data. Similarly, many computational techniques\\nthat perform well for small data face signiﬁcant challenges in\\nanalyzing big data. Various challenges that the health sector\\nface was being researched by much researchers [9], [10]. Here\\nthe challenges of big data analytics are classiﬁed into four\\nbroad categories namely data storage and analysis; knowledge\\ndiscovery and computational complexities; scalability and vi-\\nsualization of data; and information security. We discuss these\\nissues brieﬂy in the following subsections.\\nA. Data Storage and Analysis\\nIn recent years the size of data has grown exponentially\\nby various means such as mobile devices, aerial sensory\\ntechnologies, remote sensing, radio frequency identiﬁcation\\nreaders etc. These data are stored on spending much cost\\nwhereas they ignored or deleted ﬁnally becuase there is no\\nenough space to store them. Therefore, the ﬁrst challenge for\\nbig data analysis is storage mediums and higher input/output\\nspeed. In such cases, the data accessibility must be on the\\ntop priority for the knowledge discovery and representation.\\nThe prime reason is being that, it must be accessed easily and\\npromptly for further analysis. In past decades, analyst use hard\\ndisk drives to store data but, it slower random input/output\\nperformance than sequential input/output. To overcome this\\nlimitation, the concept of solid state drive (SSD) and phrase\\nchange memory (PCM) was introduced. However the avialable\\nstorage technologies cannot possess the required performance\\nfor processing big data.\\nAnother challenge with Big Data analysis is attributed\\nto diversity of data. with the ever growing of datasets, data\\nmining tasks has signiﬁcantly increased. Additionally data\\nreduction, data selection, feature selection is an essential task\\nespecially when dealing with large datasets. This presents anunprecedented challenge for researchers. It is becuase, existing\\nalgorithms may not always respond in an adequate time when\\ndealing with these high dimensional data. Automation of this\\nprocess and developing new machine learning algorithms to\\nensure consistency is a major challenge in recent years. In\\naddition to all these Clustering of large datasets that help\\nin analyzing the big data is of prime concern [11]. Recent\\ntechnologies such as hadoop and mapReduce make it possible\\nto collect large amount of semi structured and unstructured\\ndata in a reasonable amount of time. The key engineering\\nchallenge is how to effectively analyze these data for obtaining\\nbetter knowledge. A standard process to this end is to transform\\nthe semi structured or unstructured data into structured data,\\nand then apply data mining algorithms to extract knowledge. A\\nframework to analyze data was discussed by Das and Kumar\\n[12]. Similarly detail explanation of data analysis for public\\ntweets was also discussed by Das et al in their paper [13].\\nThe major challenge in this case is to pay more attention for\\ndesigning storage sytems and to elevate efﬁcient data analysis\\ntool that provide guarantees on the output when the data\\ncomes from different sources. Furthermore, design of machine\\nlearning algorithms to analyze data is essential for improving\\nefﬁciency and scalability.\\nB. Knowledge Discovery and Computational Complexities\\nKnowledge discovery and representation is a prime issue\\nin big data. It includes a number of sub ﬁelds such as\\nauthentication, archiving, management, preservation, informa-\\ntion retrieval, and representation. There are several tools for\\nknowledge discovery and representation such as fuzzy set\\n[14], rough set [15], soft set [16], near set [17], formal\\nconcept analysis [18], principal component analysis [19] etc to\\nname a few. Additionally many hybridized techniques are also\\ndeveloped to process real life problems. All these techniques\\nare problem dependent. Further some of these techniques may\\nnot be suitable for large datasets in a sequential computer. At\\nthe same time some of the techniques has good characteristics\\nof scalability over parallel computer. Since the size of big\\ndata keeps increasing exponentially, the available tools may\\nnot be efﬁcient to process these data for obtaining meaningful\\ninformation. The most popular approach in case of larage\\ndataset management is data warehouses and data marts. Data\\nwarehouse is mainly responsible to store data that are sourced\\nfrom operational systems whereas data mart is based on a data\\nwarehouse and facilitates analysis.\\nAnalysis of large dataset requires more computational\\ncomplexities. The major issue is to handle inconsistencies\\nand uncertainty present in the datasets. In general, systematic\\nmodeling of the computational complexity is used. It may be\\ndifﬁcult to establish a comprehensive mathematical system that\\nis broadly applicable to Big Data. But a domain speciﬁc data\\nanalytics can be done easily by understanding the particular\\ncomplexities. A series of such development could simulate big\\ndata analytics for different areas. Much research and survey\\nhas been carried out in this direction using machine learning\\ntechniques with the least memory requirements. The basic\\nobjective in these research is to minimize computational cost\\nprocessing and complexities [20], [21], [22].\\nHowever, current big data analysis tools have poor per-\\nformance in handling computational complexities, uncertainty,(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n512 | P a g e\\nwww.ijacsa.thesai.org and inconsistencies. It leads to a great challenge to develop\\ntechniques and technologies that can deal computational com-\\nplexity, uncertainty,and inconsistencies in a effective manner.\\nC. Scalability and Visualization of Data\\nThe most important challenge for big data analysis tech-\\nniques is its scalability and security. In the last decades\\nresearchers have paid attentions to accelerate data analysis and\\nits speed up processors followed by Moore’s Law. For the\\nformer, it is necessary to develop sampling, on-line, and mul-\\ntiresolution analysis techniques. Incremental techniques have\\ngood scalability property in the aspect of big data analysis. As\\nthe data size is scaling much faster than CPU speeds, there is a\\nnatural dramatic shift in processor technology being embedded\\nwith increasing number of cores [23]. This shift in processors\\nleads to the development of parallel computing. Real time\\napplications like navigation, social networks, ﬁnance, internet\\nsearch, timeliness etc. requires parallel computing.\\nThe objective of visualizing data is to present them more\\nadequately using some techniques of graph theory. Graphical\\nvisualization provides the link between data with proper inter-\\npretation. However, online marketplace like ﬂipkart, amazon,\\ne-bay have millions of users and billions of goods to sold each\\nmonth. This generates a lot of data. To this end, some company\\nuses a tool Tableau for big data visualization. It has capability\\nto transform large and complex data into intuitive pictures. This\\nhelp employees of a company to visualize search relevance,\\nmonitor latest customer feeback, and their sentiment analysis.\\nHowever, current big data visualization tools mostly have poor\\nperformances in functionalities, scalability, and response in\\ntime.\\nWe can observe that big data have produced many chal-\\nlenges for the developments of the hardware and software\\nwhich leads to parallel computing, cloud computing, dis-\\ntributed computing, visualization process, scalability. To over-\\ncome this issue, we need to correlate more mathematical\\nmodels to computer science.\\nD. Information Security\\nIn big data analysis massive amount of data are correlated,\\nanalyzed, and mined for meaningful patterns. All organizations\\nhave different policies to safe guard their sensitive information.\\nPreserving sensitive information is a major issue in big data\\nanalysis. There is a huge security risk associated with big data\\n[24]. Therefore, information security is becoming a big data\\nanalytics problem. Security of big data can be enhanced by\\nusing the techniques of authentication, authorization, and en-\\ncryption. Various security measures that big data applications\\nface are scale of network, variety of different devices, real time\\nsecurity monitoring, and lack of intrusion system [25], [26].\\nThe security challenge caused by big data has attracted the\\nattention of information security. Therefore, attention has to\\nbe given to develop a multi level security policy model and\\nprevention system.\\nAlthough much research has been carried out to secure\\nbig data [25] but it requires lot of improvement. The major\\nchallenge is to develop a multi-level security, privacy preserved\\ndata model for big data.III. O PEN RESEARCH ISSUES IN BIGDATA ANALYTICS\\nBig data analytics and data science are becoming the\\nresearch focal point in industries and academia. Data science\\naims at researching big data and knowledge extraction from\\ndata. Applications of big data and data science include infor-\\nmation science, uncertainty modeling, uncertain data analysis,\\nmachine learning, statistical learning, pattern recognition, data\\nwarehousing, and signal processing. Effective integration of\\ntechnologies and analysis will result in predicting the future\\ndrift of events. Main focus of this section is to discuss open\\nresearch issues in big data analytics. The research issues\\npertaining to big data analysis are classiﬁed into three broad\\ncategories namely internet of things (IoT), cloud computing,\\nbio inspired computing, and quantum computing. However it\\nis not limited to these issues. More research issues related to\\nhealth care big data can be found in Husing Kuo et al. paper\\n[9].\\nA. IoT for Big Data Analytics\\nInternet has restructured global interrelations, the art of\\nbusinesses, cultural revolutions and an unbelievable number\\nof personal characteristics. Currently, machines are getting in\\non the act to control innumerable autonomous gadgets via\\ninternet and create Internet of Things (IoT). Thus, appliances\\nare becoming the user of the internet, just like humans with\\nthe web browsers. Internet of Things is attracting the attention\\nof recent researchers for its most promising opportunities\\nand challenges. It has an imperative economic and societal\\nimpact for the future construction of information, network and\\ncommunication technology. The new regulation of future will\\nbe eventually, everything will be connected and intelligently\\ncontrolled. The concept of IoT is becoming more pertinent\\nto the realistic world due to the development of mobile de-\\nvices, embedded and ubiquitous communication technologies,\\ncloud computing, and data analytics. Moreover, IoT presents\\nchallenges in combinations of volume, velocity and variety.\\nIn a broader sense, just like the internet, Internet of Things\\nenables the devices to exist in a myriad of places and facilitates\\napplications ranging from trivial to the crucial. Conversely, it is\\nstill mystifying to understand IoT well, including deﬁnitions,\\ncontent and differences from other similar concepts. Several\\ndiversiﬁed technologies such as computational intelligence,\\nand big-data can be incorporated together to improve the\\ndata management and knowledge discovery of large scale\\nautomation applications. Much research in this direction has\\nbeen carried out by Mishra, Lin and Chang [27].\\nKnowledge acquisition from IoT data is the biggest chal-\\nlenge that big data professional are facing. Therefore, it is\\nessential to develop infrastructure to analyze the IoT data. An\\nIoT device generates continuous streams of data and the re-\\nsearchers can develop tools to extract meaningful information\\nfrom these data using machine learning techniques. Under-\\nstanding these streams of data generated from IoT devices and\\nanalysing them to get meaningful information is a challenging\\nissue and it leads to big data analytics. Machine learning\\nalgorithms and computational intelligence techniques is the\\nonly solution to handle big data from IoT prospective. Key\\ntechnologies that are associated with IoT are also discussed in\\nmany research papers [28]. Figure 2 depicts an overview of\\nIoT big data and knowledge discovery process.(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n513 | P a g e\\nwww.ijacsa.thesai.org Fig. 2: IoT Big Data Knowledge Discovery\\nKnowledge exploration system have originated from theo-\\nries of human information processing such as frames, rules,\\ntagging, and semantic networks. In general, it consists of\\nfour segments such as knowledge acquisition, knowledge\\nbase, knowledge dissemination, and knowledge application.\\nIn knowledge acquisition phase, knowledge is discovered\\nby using various traditional and computational intelligence\\ntechniques. The discovered knowledge is stored in knowledge\\nbases and expert systems are generally designed based on the\\ndiscovered knowledge. Knowledge dissemination is important\\nfor obtaining meaningful information from the knowledge\\nbase. Knowledge extraction is a process that searches doc-\\numents, knowledge within documents as well as knowledge\\nbases. The ﬁnal phase is to apply discovered knowledge in\\nvarious applications. It is the ultimate goal of knowledge\\ndiscovery. The knowledge exploration system is necessarily\\niterative with the judgement of knowledge application. There\\nare many issues, discussions, and researches in this area of\\nknowledge exploration. It is beyond scope of this survey\\npaper. For better visualization, knowledge exploration system\\nis depicted in Figure 3.\\nFig. 3: IoT Knowledge Exploration System\\nB. Cloud Computing for Big Data Analytics\\nThe development of virtualization technologies have made\\nsupercomputing more accessible and affordable. Computinginfrastructures that are hidden in virtualization software make\\nsystems to behave like a true computer, but with the ﬂexibility\\nof speciﬁcation details such as number of processors, disk\\nspace, memory, and operating system. The use of these virtual\\ncomputers is known as cloud computing which has been one\\nof the most robust big data technique. Big Data and cloud\\ncomputing technologies are developed with the importance of\\ndeveloping a scalable and on demand availability of resources\\nand data. Cloud computing harmonize massive data by on-\\ndemand access to conﬁgurable computing resources through\\nvirtualization techniques. The beneﬁts of utilizing the Cloud\\ncomputing include offering resources when there is a demand\\nand pay only for the resources which is needed to develop\\nthe product. Simultaneously, it improves availability and cost\\nreduction. Open challenges and research issues of big data\\nand cloud computing are discussed in detail by many re-\\nsearchers which highlights the challenges in data management,\\ndata variety and velocity, data storage, data processing, and\\nresource management [29], [30]. So Cloud computing helps\\nin developing a business model for all varieties of applications\\nwith infrastructure and tools.\\nBig data application using cloud computing should support\\ndata analytic and development. The cloud environment should\\nprovide tools that allow data scientists and business analysts to\\ninteractively and collaboratively explore knowledge acquisition\\ndata for further processing and extracting fruitful results.\\nThis can help to solve large applications that may arise in\\nvarious domains. In addition to this, cloud computing should\\nalso enable scaling of tools from virtual technologies into\\nnew technologies like spark, R, and other types of big data\\nprocessing techniques.\\nBig data forms a framework for discussing cloud comput-\\ning options. Depending on special need, user can go to the\\nmarketplace and buy infrastructure services from cloud service\\nproviders such as Google, Amazon, IBM, software as a service\\n(SaaS) from a whole crew of companies such as NetSuite,\\nCloud9, Jobscience etc. Another advantage of cloud computing\\nis cloud storage which provides a possible way for storing big\\ndata. The obvious one is the time and cost that are needed to\\nupload and download big data in the cloud environment. Else,\\nit becomes difﬁcult to control the distribution of computation\\nand the underlying hardware. But, the major issues are privacy\\nconcerns relating to the hosting of data on public servers,\\nand the storage of data from human studies. All these issues\\nwill take big data and cloud computing to a high level of\\ndevelopment.\\nC. Bio-inspired Computing for Big Data Analytics\\nBio-inspired computing is a technique inspired ny nature\\nto address complex real world problems. Biological systems\\nare self organized without a central control. A bio-inspired\\ncost minimization mechanism search and ﬁnd the optimal\\ndata service solution on considering cost of data management\\nand service maintenance. These techniques are developed by\\nbiological molecules such as DNA and proteins to conduct\\ncomputational calculations involving storing, retrieving, and\\nprocessing of data. A signiﬁcant feature of such computing\\nis that it integrates biologically derived materials to perform\\ncomputational functions and receive intelligent performance.\\nThese systems are more suitable for big data applications.(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n514 | P a g e\\nwww.ijacsa.thesai.org Huge amount of data are generated from variety of resources\\nacross the web since the digitization. Analyzing these data\\nand categorizing into text, image and video etc will require\\nlot of intelligent analytics from data scientists and big data\\nprofessionals. Proliferations of technologies are emerging like\\nbig data, IoT, cloud computing, bio inspired computing etc\\nwhereas equilibrium of data can be done only by selecting right\\nplatform to analyze large and furnish cost effective results.\\nBio-inspired computing techniques serve as a key role in\\nintelligent data analysis and its application to big data. These\\nalgorithms help in performing data mining for large datasets\\ndue to its optimization application. The most advantage is its\\nsimplicity and their rapid concergence to optimal solution [31]\\nwhile solving service provision problems. Some applications to\\nthis end using bio inspired computing was discussed in detail\\nby Cheng et al [32]. From the discussions, we can observe that\\nthe bio-inspired computing models provide smarter interac-\\ntions, inevitable data losses, and help is handling ambiguities.\\nHence, it is believed that in future bio-inspired computing may\\nhelp in handling big data to a large extent.\\nD. Quantum Computing for Big Data Analysis\\nA quantum computer has memory that is exponentially\\nlarger than its physical size and can manipulate an exponential\\nset of inputs simultaneously [33]. This exponential improve-\\nment in computer systems might be possible. If a real quantum\\ncomputer is available now, it could have solved problems\\nthat are exceptionally difﬁcult on recent computers, of course\\ntoday’s big data problems. The main technical difﬁculty in\\nbuilding quantum computer could soon be possible. Quantum\\ncomputing provides a way to merge the quantum mechanics to\\nprocess the information. In traditional computer, information\\nis presented by long strings of bits which encode either a\\nzero or a one. On the other hand a quantum computer uses\\nquantum bits or qubits. The difference between qubit and bit\\nis that, a qubit is a quantum system that encodes the zero and\\nthe one into two distinguishable quantum states. Therefore,\\nit can be capitalized on the phenomena of superposition and\\nentanglement. It is because qubits behave quantumly. For\\nexample, 100 qubits in quantum systems require 2100 complex\\nvalues to be stored in a classic computer system. It means that\\nmany big data problems can be solved much faster by larger\\nscale quantum computers compared with classical computers.\\nHence it is a challenge for this generation to built a quantum\\ncomputer and facilitate quantum computing to solve big data\\nproblems.\\nIV. T OOLS FOR BIG DATA PROCESSING\\nLarge numbers of tools are available to process big data. In\\nthis section, we discuss some current techniques for analyzing\\nbig data with emphasis on three important emerging tools\\nnamely MapReduce, Apache Spark, and Storm. Most of the\\navailable tools concentrate on batch processing, stream pro-\\ncessing,and interactive analysis. Most batch processing tools\\nare based on the Apache Hadoop infrastructure such as Mahout\\nand Dryad. Stream data applications are mostly used for real\\ntime analytic. Some examples of large scale streaming platform\\nare Strom and Splunk. The interactive analysis process allow\\nusers to directly interact in real time for their own analysis.For example Dremel and Apache Drill are the big data plat-\\nforms that support interactive analysis. These tools help us in\\ndeveloping the big data projects. A fabulous list of big data\\ntools and techniques is also discussed by much researchers [6],\\n[34]. The typical work ﬂow of big data project discussed by\\nHuang et al is highlighted in this section [35] and is depicted\\nin Figure 4.\\nFig. 4: Workﬂow of Big Data Project\\nA. Apache Hadoop and MapReduce\\nThe most established software platform for big data anal-\\nysis is Apache Hadoop and Mapreduce. It consists of hadoop\\nkernel, mapreduce, hadoop distributed ﬁle system (HDFS)\\nand apache hive etc. Map reduce is a programming model\\nfor processing large datasets is based on divide and conquer\\nmethod. The divide and conquer method is implemented in two\\nsteps such as Map step and Reduce Step. Hadoop works on\\ntwo kinds of nodes such as master node and worker node. The\\nmaster node divides the input into smaller sub problems and\\nthen distributes them to worker nodes in map step. Thereafter\\nthe master node combines the outputs for all the subproblems\\nin reduce step. Moreover, Hadoop and MapReduce works as\\na powerful software framework for solving big data problems.\\nIt is also helpful in fault-tolerant storage and high throughput\\ndata processing.\\nB. Apache Mahout\\nApache mahout aims to provide scalable and commercial\\nmachine learning techniques for large scale and intelligent data\\nanalysis applications. Core algorithms of mahout including\\nclustering, classiﬁcation, pattern mining, regression, dimen-\\nsionalty reduction, evolutionary algorithms, and batch based\\ncollaborative ﬁltering run on top of Hadoop platform through\\nmap reduce framework. The goal of mahout is to build a\\nvibrant, responsive, diverse community to facilitate discussions\\non the project and potential use cases. The basic objective\\nof Apache mahout is to provide a tool for elleviating big\\nchallenges. The different companies those who have imple-\\nmented scalable machine learning algorithms are Google, IBM,\\nAmazon, Yahoo, Twitter, and facebook [36].\\nC. Apache Spark\\nApache spark is an open source big data processing frame-\\nwork built for speed processing, and sophisticated analytics.(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n515 | P a g e\\nwww.ijacsa.thesai.org It is easy to use and was originally developed in 2009 in UC\\nBerkeleys AMPLab. It was open sourced in 2010 as an Apache\\nproject. Spark lets you quickly write applications in java, scala,\\nor python. In addition to map reduce operations, it supports\\nSQL queries, streaming data, machine learning, and graph data\\nprocessing. Spark runs on top of existing hadoop distributed\\nﬁle system (HDFS) infrastructure to provide enhanced and\\nadditional functionality. Spark consists of components namely\\ndriver program, cluster manager and worker nodes. The driver\\nprogram serves as the starting point of execution of an appli-\\ncation on the spark cluster. The cluster manager allocates the\\nresources and the worker nodes to do the data processing in\\nthe form of tasks. Each application will have a set of processes\\ncalled executors that are responsible for executing the tasks.\\nThe major advantage is that it provides support for deploying\\nspark applications in an existing hadoop clusters. Figure 5\\ndepicts the architecture diagram of Apache Spark. The various\\nfeatures of Apache Spark are listed below:\\nFig. 5: Architecture of Apache Spark\\n• The prime focus of spark includes resilient distributed\\ndatasets (RDD), which store data in-memory and\\nprovide fault tolerance without replication. It supports\\niterative computation, improves speed and resource\\nutilization.\\n• The foremost advantage is that in addition to MapRe-\\nduce, it also supports streaming data, machine learn-\\ning, and graph algorithms.\\n• Another advantage is that, a user can run the applica-\\ntion program in different languages such as Java, R,\\nPython, or Scala. This is possible as it comes with\\nhigher-level libraries for advanced analytics. These\\nstandard libraries increase developer productivity and\\ncan be seamlessly combined to create complex work-\\nﬂows.\\n• Spark helps to run an application in Hadoop cluster,\\nup to 100 times faster in memory, and 10 times faster\\nwhen running on disk. It is possible because of the\\nreduction in number of read or write operations to\\ndisk.\\n• It is written in scala programming language and runs\\non java virtual machine (JVM) environment. Addi-\\ntionally, it upports java, python and R for developing\\napplications using Spark.D. Dryad\\nIt is another popular programming model for implementing\\nparallel and distributed programs for handling large context\\nbases on dataﬂow graph. It consists of a cluster of computing\\nnodes, and an user use the resources of a computer cluster\\nto run their program in a distributed way. Indeed, a dryad\\nuser use thousands of machines, each of them with multiple\\nprocessors or cores. The major advantage is that users do\\nnot need to know anything about concurrent programming. A\\ndryad application runs a computational directed graph that is\\ncomposed of computational vertices and communication chan-\\nnels. Therefore, dryad provides a large number of functionality\\nincluding generating of job graph, scheduling of the machines\\nfor the available processes, transition failure handling in the\\ncluster, collection of performance metrics, visualizing the job,\\ninvokinguser deﬁned policies and dynamically updating the job\\ngraph in response to these policy decisions without knowing\\nthe semantics of the vertices [37].\\nE. Storm\\nStorm is a distributed and fault tolerant real time com-\\nputation system for processing large streaming data. It is\\nspecially designed for real time processing in contrasts with\\nhadoop which is for batch processing. Additionally, it is also\\neasy to set up and operate, scalable, fault-tolerant to provide\\ncompetitive performances. The storm cluster is apparently\\nsimilar to hadoop cluster. On storm cluster users run different\\ntopologies for different storm tasks whereas hadoop platform\\nimplements map reduce jobs for corresponding applications.\\nThere are number of differences between map reduce jobs\\nand topologies. The basic difference is that map reduce job\\neventually ﬁnishes whereas a topology processes messages all\\nthe time, or until user terminate it. A storm cluster consists of\\ntwo kinds of nodes such as master node and worker node. The\\nmaster node and worker node implement two kinds of roles\\nsuch as nimbus and supervisor respectively. The two roles have\\nsimilar functions in accordance with jobtracker and tasktracker\\nof map reduce framework. Nimbus is in charge of distributing\\ncode across the storm cluster, scheduling and assigning tasks\\nto worker nodes, and monitoring the whole system. The\\nsupervisor complies tasks as assigned to them by nimbus.\\nIn addition, it start and terminate the process as necessary\\nbased on the instructions of nimbus. The whole computational\\ntechnology is partitioned and distributed to a number of worker\\nprocesses and each worker process implements a part of the\\ntopology.\\nF . Apache Drill\\nApache drill is another distributed system for interactive\\nanalysis of big data. It has more ﬂexibility to support many\\ntypes of query languages, data formats, and data sources. It is\\nalso specially designed to exploit nested data. Also it has an\\nobjective to scale up on 10,000 servers or more and reaches the\\ncapability to process patabytes of data and trillions of records\\nin seconds. Drill use HDFS for storage and map reduce to\\nperform batch analysis.\\nG. Jaspersoft\\nThe Jaspersoft package is an open source software that\\nproduce reports from database columns. It is a scalable big(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n516 | P a g e\\nwww.ijacsa.thesai.org data analytical platform and has a capability of fast data visu-\\nalization on popular storage platforms, including MangoDB,\\nCassandra, Redis etc. One important property of Jaspersoft\\nis that it can quickly explore big data without extraction,\\ntransformation, and loading (ETL). In addition to this, it also\\nhave an ability to build powerful hypertext markup language\\n(HTML) reports and dashboards interactively and directly from\\nbig data store without ETL requirement. These generated\\nreports can be shared with anyone inside or outside user’s\\norganization.\\nH. Splunk\\nIn recent years a lot of data are generated through machine\\nfrom business industries. Splunk is a real-time and intelligent\\nplatform developed for exploiting machine generated big data.\\nIt combines the up-to-the-moment cloud technologies and big\\ndata. In turn it helps user to search, monitor, and analyze their\\nmachine generated data through web interface. The results are\\nexhibited in an intuitive way such as graphs, reports, and alerts.\\nSplunk is different from other stream processing tools. Its\\npeculiarities include indexing structured, unstructured machine\\ngenerated data, real-time searching, reporting analytical results,\\nand dashboards. The most important objective of Splunk is\\nto provide metrices for many application, diagnose problems\\nfor system and information technology infrastructures, and\\nintelligent support for business operations.\\nV. S UGGESTIONS FOR FUTURE WORK\\nThe amount of data collected from various applications\\nall over the world across a wide variety of ﬁelds today is\\nexpected to double every two years. It has no utility unless\\nthese are analyzed to get useful information. This necessitates\\nthe development of techniques which can be used to facilitate\\nbig data analysis. The development of powerful computers is\\na boon to implement these techniques leading to automated\\nsystems. The transformation of data into knowledge is by\\nno means an easy task for high performance large-scale data\\nprocessing, including exploiting parallelism of current and\\nupcoming computer architectures for data mining. Moreover,\\nthese data may involve uncertainty in many different forms.\\nMany different models like fuzzy sets, rough sets, soft sets,\\nneural networks, their generalizations and hybrid models ob-\\ntained by combining two or more of these models have been\\nfound to be fruitful in representing data. These models are\\nalso very much fruitful for analysis. More often than not, big\\ndata are reduced to include only the important characteristics\\nnecessary from a particular study point of view or depending\\nupon the application area. So, reduction techniques have been\\ndeveloped. Often the data collected have missing values. These\\nvalues need to be generated or the tuples having these missing\\nvalues are eliminated from the data set before analysis. More\\nimportantly, these new challenges may comprise, sometimes\\neven deteriorate, the performance, efﬁciency and scalability\\nof the dedicated data intensive computing systems. The later\\napproach sometimes leads to loss of information and hence\\nnot preferred. This brings up many research issues in the\\nindustry and research community in forms of capturing and\\naccessing data effectively. In addition, fast processing while\\nachieving high performance and high throughput, and storing\\nit efﬁciently for future use is another issue. Further, pro-\\ngramming for big data analysis is an important challengingissue. Expressing data access requirements of applications\\nand designing programming language abstractions to exploit\\nparallelism are an immediate need [38].\\nAdditionally, machine learning concepts and tools are\\ngaining popularity among researchers to facilitate meaningful\\nresults from these concepts. Research in the area of machine\\nlearning for big data has focused on data processing, algo-\\nrithm implementation, and optimization. Many of the machine\\nlearning tools for big data are started recently needs drastic\\nchange to adopt it. We argue that while each of the tools has\\ntheir advantages and limitations, more efﬁcient tools can be\\ndeveloped for dealing with problems inherent to big data. The\\nefﬁcient tools to be developed must have provision to handle\\nnoisy and imbalance data, uncertainty and inconsistency, and\\nmissing values.\\nVI. C ONCLUSION\\nIn recent years data are generated at a dramatic pace.\\nAnalyzing these data is challenging for a general man. To\\nthis end in this paper, we survey the various research issues,\\nchallenges, and tools used to analyze these big data. From\\nthis survey, it is understood that every big data platform has\\nits individual focus. Some of them are designed for batch\\nprocessing whereas some are good at real-time analytic. Each\\nbig data platform also has speciﬁc functionality. Different\\ntechniques used for the analysis include statistical analysis,\\nmachine learning, data mining, intelligent analysis, cloud com-\\nputing, quantum computing, and data stream processing. We\\nbelive that in future researchers will pay more attention to\\nthese techniques to solve problems of big data effectively and\\nefﬁciently.\\nREFERENCES\\n[1] M. K.Kakhani, S. Kakhani and S. R.Biradar, Research issues in big\\ndata analytics , International Journal of Application or Innovation in\\nEngineering & Management, 2(8) (2015), pp.228-232.\\n[2] A. Gandomi and M. Haider, Beyond the hype: Big data concepts, meth-\\nods, and analytics , International Journal of Information Management,\\n35(2) (2015), pp.137-144.\\n[3] C. Lynch, Big data: How do your data grow? , Nature, 455 (2008),\\npp.28-29.\\n[4] X. Jin, B. W.Wah, X. Cheng and Y . Wang, Signiﬁcance and challenges\\nof big data research , Big Data Research, 2(2) (2015), pp.59-64.\\n[5] R. Kitchin, Big Data, new epistemologies and paradigm shifts , Big\\nData Society, 1(1) (2014), pp.1-12.\\n[6] C. L. Philip, Q. Chen and C. Y . Zhang, Data-intensive applications,\\nchallenges, techniques and technologies: A survey on big data , Infor-\\nmation Sciences, 275 (2014), pp.314-347.\\n[7] K. Kambatla, G. Kollias, V . Kumar and A. Gram, Trends in big data\\nanalytics , Journal of Parallel and Distributed Computing, 74(7) (2014),\\npp.2561-2573.\\n[8] S. Del. Rio, V . Lopez, J. M. Bentez and F. Herrera, On the use of\\nmapreduce for imbalanced big data using random forest , Information\\nSciences, 285 (2014), pp.112-137.\\n[9] MH. Kuo, T. Sahama, A. W. Kushniruk, E. M. Borycki and D. K.\\nGrunwell, Health big data analytics: current perspectives, challenges\\nand potential solutions , International Journal of Big Data Intelligence,\\n1 (2014), pp.114-126.\\n[10] R. Nambiar, A. Sethi, R. Bhardwaj and R. Vargheese, A look at\\nchallenges and opportunities of big data analytics in healthcare , IEEE\\nInternational Conference on Big Data, 2013, pp.17-22.\\n[11] Z. Huang, A fast clustering algorithm to cluster very large categorical\\ndata sets in data mining , SIGMOD Workshop on Research Issues on\\nData Mining and Knowledge Discovery, 1997.(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n517 | P a g e\\nwww.ijacsa.thesai.org [12] T. K. Das and P. M. Kumar, Big data analytics: A framework for\\nunstructured data analysis , International Journal of Engineering and\\nTechnology, 5(1) (2013), pp.153-156.\\n[13] T. K. Das, D. P. Acharjya and M. R. Patra, Opinion mining about a\\nproduct by analyzing public tweets in twitter , International Conference\\non Computer Communication and Informatics, 2014.\\n[14] L. A. Zadeh, Fuzzy sets , Information and Control, 8 (1965), pp.338-\\n353.\\n[15] Z. Pawlak, Rough sets , International Journal of Computer Information\\nScience, 11 (1982), pp.341-356.\\n[16] D. Molodtsov, Soft set theory ﬁrst results , Computers and Mathe-\\nmatics with Aplications, 37(4/5) (1999), pp.19-31.\\n[17] J. F.Peters, Near sets. General theory about nearness of objects ,\\nApplied Mathematical Sciences, 1(53) (2007), pp.2609-2629.\\n[18] R. Wille, Formal concept analysis as mathematical theory of concept\\nand concept hierarchies , Lecture Notes in Artiﬁcial Intelligence, 3626\\n(2005), pp.1-33.\\n[19] I. T.Jolliffe, Principal Component Analysis , Springer, New York, 2002.\\n[20] O. Y . Al-Jarrah, P. D. Yoo, S. Muhaidat, G. K. Karagiannidis and\\nK. Taha, Efﬁcient machine learning for big data: A review , Big Data\\nResearch, 2(3) (2015), pp.87-93.\\n[21] Changwon. Y , Luis. Ramirez and Juan. Liuzzi, Big data analysis\\nusing modern statistical and machine learning methods in medicine ,\\nInternational Neurourology Journal, 18 (2014), pp.50-57.\\n[22] P. Singh and B. Suri, Quality assessment of data using statistical and\\nmachine learning methods . L. C.Jain, H. S.Behera, J. K.Mandal and\\nD. P.Mohapatra (eds.), Computational Intelligence in Data Mining, 2\\n(2014), pp. 89-97.\\n[23] A. Jacobs, The pathologies of big data , Communications of the ACM,\\n52(8) (2009), pp.36-44.\\n[24] H. Zhu, Z. Xu and Y . Huang, Research on the security technology of big\\ndata information , International Conference on Information Technology\\nand Management Innovation, 2015, pp.1041-1044.\\n[25] Z. Hongjun, H. Wenning, H. Dengchao and M. Yuxing, Survey of\\nresearch on information security in big data , Congresso da sociedada\\nBrasileira de Computacao, 2014, pp.1-6.\\n[26] I. Merelli, H. Perez-sanchez, S. Gesing and D. D.Agostino, Managing,\\nanalysing, and integrating big data in medical bioinformatics: open\\nproblems and future perspectives , BioMed Research International, 2014,\\n(2014), pp.1-13.\\n[27] N. Mishra, C. Lin and H. Chang, A cognitive adopted framework\\nfor iot big data management and knowledge discovery prospective ,\\nInternational Journal of Distributed Sensor Networks, 2015, (2015), pp.\\n1-13\\n[28] X. Y .Chen and Z. G.Jin, Research on key technology and applications\\nfor internet of things , Physics Procedia, 33, (2012), pp. 561-566.\\n[29] M. D. Assuno, R. N. Calheiros, S. Bianchi, M. a. S. Netto and R. Buyya,\\nBig data computing and clouds: Trends and future directions , Journal\\nof Parallel and Distributed Computing, 79 (2015), pp.3-15.\\n[30] I. A. T. Hashem, I. Yaqoob, N. Badrul Anuar, S. Mokhtar, A. Gani and\\nS. Ullah Khan, The rise of big data on cloud computing: Review and\\nopen research issues , Information Systems, 47 (2014), pp. 98-115.\\n[31] L. Wang and J. Shen, Bioinspired cost-effective access to big data ,\\nInternational Symposium for Next Generation Infrastructure, 2013, pp.1-\\n7.\\n[32] C. Shi, Y . Shi, Q. Qin and R. Bai Swarm intelligence in big data\\nanalytics , H. Yin, K. Tang, Y . Gao, F. Klawonn, M. Lee, T. Weise,\\nB. Li and X. Yao (eds.), Intelligent Data Engineering and Automated\\nLearning, 2013, pp.417-426.\\n[33] M. A. Nielsen and I. L.Chuang, Quantum Computation and Quantum\\nInformation , Cambridge University Press, New York, USA 2000.\\n[34] M. Herland, T. M. Khoshgoftaar and R. Wald, A review of data mining\\nusing big data in health informatics , Journal of Big Data, 1(2) (2014),\\npp. 1-35.\\n[35] T. Huang, L. Lan, X. Fang, P. An, J. Min and F. Wang Promises and\\nchallenges of big data computing in health sciences , Big Data Research,\\n2(1) (2015), pp. 2-11.[36] G. Ingersoll, Introducing apache mahout: Scalable, commercial friendly\\nmachine learning for building intelligent applications , White Paper,\\nIBM Developer Works, (2009), pp. 1-18.\\n[37] H. Li, G. Fox and J. Qiu, Performance model for parallel matrix mul-\\ntiplication with dryad: Dataﬂow graph runtime , Second International\\nConference on Cloud and Green Computing, 2012, pp.675-683.\\n[38] D. P. Acharjya, S. Dehuri and S. Sanyal Computational Intelligence for\\nBig Data Analysis , Springer International Publishing AG, Switzerland,\\nUSA, ISBN 978-3-319-16597-4, 2015.(IJACSA) International Journal of Advanced Computer Science and Applicati ons, \\nVol. 7, No. 2, 2016 \\n518| P a g e\\nwww.ijacsa.thesai.org '}, {'document_name': 'CURMay06.pdf', 'file_path': '../data\\\\Folder2\\\\CURMay06.pdf', 'content': 'Data Mining Curriculum: A Proposal (Version 1.0)\\nIntensive Working Group of ACM SIGKDD Curriculum Committee :\\nSoumen Chakrabarti, Martin Ester, Usama Fayyad, Johannes G ehrke,\\nJiawei Han, Shinichi Morishita, Gregory Piatetsky-Shapir o, Wei Wang\\nApril 30, 2006\\n1 Introduction\\nRecent tremendous technical advances in processing power, storage capacity, and inter-connectivity of com-\\nputer technology is creating unprecedented quantities of d igital data. Data mining , the science of extracting\\nuseful knowledge from such huge data repositories, has emer ged as a young and interdisciplinary ﬁeld in\\ncomputer science. Data mining techniques have been widely a pplied to problems in industry, science, en-\\ngineering and government, and it is widely believed that dat a mining will have profound impact on our\\nsociety. The growing consensus that data mining can bring re al value has led to an explosion in demand\\nfor novel data mining technologies and for students who are t rained in data mining—students who have an\\nunderstanding of data mining techniques, can apply them to r eal-life problems, and are trained for research\\nand development of new data mining methods. Courses in data m ining have started to sprawl all over the\\nworld.\\nBased on this development of the ﬁeld, the ACM SIGKDD Executi ve Committee has set up the ACM\\nSIGKDD Curriculum Committee to design a sample curriculum f or data mining that gives recommendations\\nfor educating the next generation of students in data mining . Based on feedback from researchers, educators,\\nand students, we are convinced that it is an important task to have a carefully designed, conceptually strong,\\ntechnically rich, and balanced curriculum for this discipl ine. A comprehensive and balanced curriculum will\\nensure that the education in data mining sets a solid foundat ion for the healthy growth of the ﬁeld, and it will\\npromote systematic training of students in computer scienc e, information sciences, and other related ﬁelds,\\nand it will provide guidance for the training of the next gene ration of data mining researchers, developers\\nand technology users.\\nThe Curriculum Committee is composed of university profess ors and researchers who have actively con-\\ntributed to data mining research and education, researcher s and practitioners from industry who have rich\\nexperiences in applying data mining technology, and admini strators from government agencies. This report\\nis the ﬁrst draft from the Intensive Working Group of the Comm ittee. We expect that this draft will be\\nextensively revised and reviewed, and we are looking forwar d to suggestions and recommendations from the\\nCommittee and from the general data mining research, develo pment, and application community.\\nThe remainder of this report is structured as follows. First , we outline the principles that guided us in\\nthe selection of material in Section 2. We then give a brief de scription of the prerequisites that we assume\\nstudents of our proposed curriculum to have in Section 3. Sec tion 4 contains the core of this document, our\\ncurriculum proposal.\\n2 Curriculum Design Philosophy\\nData mining is an interdisciplinary ﬁeld at the intersectio n of artiﬁcial intelligence, machine learning, statis-\\ntics, and database systems, and we believe that diﬀerent edu cators will emphasize diﬀerent topics in their\\n1courses. Thus we divided this curriculum proposal into two p arts. The ﬁrst part titled Foundations contains\\nbasic material that we believe should be covered in any intro ductory course on data mining. The second\\npart called Advanced Topics is a comprehensive collection of material that can be sample d to complete an\\nintroductory course or selections of which can form the basi s for an advanced course in data mining.\\nWe believe that the teaching of data mining should concentra te onlong-lasting scientiﬁc principles and\\nconcepts of the ﬁeld. Thus instead of covering the last details of the m ost recent research, we designed the\\nbasic material to lay a solid foundation that opens the door t o explore more advanced material.\\nThe core endeavor in data mining is to extract knowledge from data; this knowledge is captured in a\\nhuman-understandable structure . The discovery of structure in data is a multifaceted proble m that includes\\nthe following components:\\nDatabase and Data Management Issues: Where does the data reside? How is it to be accessed? What\\nforms of sampling are needed? are possible? are appropriate ? What are the implications of the\\ndatabase or data warehouse structure and constraints on dat a movement and data preparation?\\nData Preprocessing: What are the required data transformations before a chosen a lgorithm or class of\\nalgorithms can be applied to the data? What are eﬀective meth ods for reducing the dimensionality of\\nof the data so the algorithms can work eﬃciently? How are miss ing data items to be modelled? What\\ntransformations properly encode a priori knowledge of the p roblem?\\nChoice of Model and Statistical Inference Considerations: What are the appropriate choices to en-\\nsure proper statistical inference? What are valid approxim ations? What are the implications of the\\ninference methods on the expected results? How is the result ing structure to be evaluated? Validated?\\nInterestingness Metrics: What makes the derived structure interesting oruseful ? How do the goals of\\nthe particular data mining activity inﬂuence the choice of a lgorithms or techniques to be used?\\nAlgorithmic Complexity Considerations: What choice of algorithms based on the size and dimension-\\nality of data? What about computational resource constrain ts? Requirements on accuracy of resulting\\nmodels? What are the scalability considerations and how sho uld they be addressed?\\nPost-processing of Discovered Structure: How are the results to be used? What are the requirements\\nfor use at prediction time? What are the transformation requ irements at model application time? How\\nare changes in the data or underlying distributions to be man aged?\\nVisualization and Understandability: What are the constraints on the discovered structure from th e\\nperspective of understandability by humans? What are eﬀect ive visualization techniques for the result-\\ning structure? How can data be eﬀectively visualized in the c ontext of or with the aid of the discovered\\nstructures?\\nMaintenance, Updates, and Model Life Cycle Considerations :When are models to be changed or\\nupdated? How must the models change as the utility metrics in the application domain change? How\\nare the resulting predictions or discovered structure inte grated with application domain metrics and\\nconstraints?\\nThe partial list above demonstrates that data mining involv es many problems and many notions that\\nhave historically been studies in isolation. This necessit ates a healthy coverage of a wide range of areas\\nwithin the proposed curriculum.\\n3 Prerequisites\\nData mining is a broad ﬁeld that combines techniques from diﬀ erent areas in computer science and statistics.\\nOur model curriculum assumes that students have basic backg round knowledge in the following areas:\\n2Database Systems: Data models, query languages, SQL, conceptual database des ign, query processing,\\nand transaction processing.\\nStatistics: Expectation, basic probability, distributions, hypothes is tests, ANOVA, and estimating a distri-\\nbution parameter.\\nLinear Algebra: Vectors and matrices, vector spaces, basis, matrix inversi on, and solving linear equations.\\nAlgorithms and Data Structures: We assume familiarity with basic data structures and genera l matu-\\nrity of students to understand algorithms written in pseudo -code.\\nWe believe that most computer science seniors either have co vered this material in previous courses, can\\npick up missing material in self-study, or that the missing m aterial is introduced by the course instructor as\\nnecessary.\\n4 Course Topics and Models\\nRecall that we partitioned our curriculum into two parts: A c ourse on Foundations and a course on Advanced\\nTopics . A standard 14-week one semester introductory course on dat a mining (oﬀered to either senior\\nundergraduate or ﬁrst-year graduate students) could cover all the units in Foundations and a selected set\\nof units from the Advanced Topics. A selected set of units fro m the Advanced Topics can be covered in a\\nsecond course.\\n4.1 Foundations (Course I)\\n1.Introduction. Basic concepts of data mining, including motivation, deﬁni tion, the relationships of\\ndata mining with database systems, statistics, machine lea rning, diﬀerent kinds of data repositories\\non which data mining can be performed, diﬀerent kind of patte rns and knowledge to be mined, the\\nconcept of interestingness, and the current trends and deve lopments of data mining. The material can\\nprobably be introduced by showing a few case studies.\\n(a)Concepts of data mining : motivation, deﬁnition, the relationships of data mining w ith database\\nsystems, statistics, machine learning, and information re trieval.\\n(b)Knowledge discovery process : An overview of the Knowledge Discovery Process. Emphasis\\non the iterative and interactive nature of the KDD Process.\\n(c)Mining on diﬀerent kinds of data : relational, transactional, object-relational, heterog eneous,\\nspatiotemporal, text, multimedia, Web, stream, mobile, an d so on.\\n(d)Mining for diﬀerent kind of knowledge : classiﬁcation, regression, clustering, frequent pat-\\nterns, discriminant, outliers, and so on.\\n(e)Evaluation of knowledge : interestingness or quality of knowledge, including accur acy, utility\\n(such as support), and relevance (such as correlation).\\n(f)Applications of data mining : market analysis, scientiﬁc and engineering process analy sis,\\nbioinformatics, homeland security, and so on.\\n2.Data Preprocessing. This unit will cover the following topics: (1) why preproces s the data? (2) basic\\ndata cleaning techniques, (3) data integration and transfo rmation, and (4) data reduction methods. In\\nparticular, the following topics will be covered.\\n(a)Descriptive data summarization : This unit covers basic techniques for summarizing and\\ndescribing data. It will cover: (1) computing the measures o f central tendency such as mean,\\nand mode, (2) computing the measures of data dispersion such as quantiles, boxplots, variances,\\nstandard deviation, and outliers, and (3) graphic display o f basic statistical descriptions, such as\\nhistogram, scatter plot, boxplot, quantile-quantile plot , and local regression curves.\\n3(b)Data cleaning methods : Basic techniques for handling missing values, noisy data, and incon-\\nsistent data, including typical binning, clustering, and r egression methods for data cleaning.\\n(c)Data integration and transformation methods : This includes data smoothing, data aggre-\\ngation, data generalization, normalization, attribute (o r feature) construction.\\n(d)Basic data reduction methods : It introduces binning (histograms), sampling, and data cu be\\naggregation.\\n(e)Discretization and concept hierarchy generation : It covers discretization and concept hi-\\nerarchy generation for numeric data (including binning, cl ustering, histogram analysis), and for\\ncategorical data (automatic generation of concept hierarc hies).\\n3.Data Warehousing and OLAP for Data Mining. This unit introduces the concept of a data\\nwarehouse and its associated dimensional data model. It the n introduces basic OLAP-style analysis\\non the data cube.\\n(a)Concept and architecture of data warehouse\\n(b)The dimensional data model : including dimensions and measures; star schema, snowﬂake\\nschema, and fact constellations; data cube concept; concep t hierarchies in the cube.\\n(c)OLAP Operations. OLAP operations in the multidimensional data model (drill- down, roll-up,\\nslice and dice, pivot)\\n4.Association, correlation, and frequent pattern analysis. This unit covers the concepts and\\ntechniques for association, correlation, and frequent pat tern analysis, including the following topics.\\n(a)Basic concepts : frequent patterns, associations, support and conﬁdence o f association rules,\\ncorrelation measure, other objective functions or measure s, a typical application scenario: market\\nbasket analysis.\\n(b)Frequent pattern mining methods : (1) the Apriori algorithm, (2) improvements to Apriori,\\n(3) mining for max-patterns, closed patterns, and top- kpatterns.\\n(c)Mining various kinds of frequent patterns : (1) multilevel and multidimensional association\\nrules, (2) quantitative association rules, and (3) correla tion analysis.\\n(d)Applications of association rules : (1) Web log analysis, (2) usage of association rules as\\nclassiﬁers\\n5.Classiﬁcation. This unit covers the concepts and techniques for classiﬁcat ion analysis, including the\\nfollowing topics.\\n(a)Basic concepts : classiﬁcation\\n(b)Evaluation of classiﬁcation : (1) evaluation metric, (2) validation for model selection , (3)\\noverﬁtting, (4) comparing classiﬁers based on cost-beneﬁt and ROC curves\\n(c)Bayesian classiﬁcation : (1) foundation: Bayes theorem, (2) Naive Bayesian classiﬁ cation meth-\\nods\\n(d)Decision tree and decision rule induction : (1) attribute selection and reduction, (2) basic\\ntop-down classiﬁcation-tree induction schema, (3) pre/po st-pruning uninformative subtrees, (4)\\nextraction of rules from classiﬁcation trees, (5) decision rule induction.\\n(e)Linear models for classiﬁcation : (1) linear discriminant analysis, (2) classiﬁcation by SV M\\n(Support Vector Machine) analysis\\n(f)Basic concepts of nonlinear classiﬁcation : (1) neural network, (2) SVM with nonlinear\\nkernels\\n4(g)Classiﬁcation by lazy evaluation : (1) k-nearest neighbor classiﬁer: basic idea and error\\nbounds, (2) locally weighted learning\\n(h)Emsemble classiﬁer : Basic ideas why ensemble construction helps, basics of: we ighted voting,\\nbagging, boosting.\\n6.Cluster and Outlier Analysis. This unit covers the concepts and techniques for cluster and outlier\\nanalysis, including the following topics.\\n(a)Concept of cluster analysis\\n(b)Types of data and for dissimilarity computation : Interval-scaled variables, binary variables,\\nnominal, ordinal, and ratio-scaled variables, and variabl es of mixed types.\\n(c)A categorization of major clustering methods\\n(d)Partition-based clustering :k-means and k-medoids algorithms, and scalable partitioning\\nmethods.\\n(e)Hierarchical clustering : agglomerative and divisive hierarchical clustering meth ods, micro-\\nclusters: integrated and scalable hierarchical clusterin g methods.\\n(f)Density-based clustering : concept of density-based clustering, scalable mining of c lustering\\nstructures, clustering based on density distribution func tions.\\n(g)Model-based clustering : (1) The EM Algorithm, (2) neural network approach (SOM)\\n(h)Outlier analysis : Concepts and basic outlier detection methods.\\n7.Mining Time-Series and Sequence Data. This unit covers the techniques for mining time-series\\nand sequence data, with the following topics.\\n(a)Regression analysis : (1) simple and multiple linear regression, (2) nonlinear r egression, (3)\\nlogistic regression, (4) regression trees, (5) regression using Support Vector Machine, (6) other\\nregression models.\\n(b)Trend analysis : A statistical approach\\n(c)Sequential pattern mining : Mining diﬀerent kinds of sequential patterns, sequential pattern\\nmining methods, constraint-based sequential pattern mini ng, closed sequential patterns, from\\nsequential patterns to partially ordered patterns.\\n8.Text Mining and Web Mining. This unit covers the techniques for mining text and Web data,\\nincluding the following topics.\\n(a)Mining text databases : (1) Text data analysis and information retrieval, (2) keyw ord-based\\nassociation analysis, (3) document classiﬁcation, (4) tex t clustering analysis\\n(b)Mining the World-Wide Web : (1) Mining the Web’s link structures to identify authorita tive\\nWeb page, (2) automatic classiﬁcation of Web documents, (3) construction of a multilayered Web\\ninformation base, (4) mining social networks, (5) Web resou rce discovery, (6) Web usage mining.\\n9.Visual Data Mining. This unit covers the visual data mining techniques, includi ng the following\\ntopics.\\n(a)Data visualization\\n(b)Visualization of data mining results\\n(c)Visual data mining : visual classiﬁer, projection pursuits, class-preservin g projections, visualiz-\\ning class-structure of high-dimensional data, class tours\\n510.Data Mining: Industry eﬀorts and social impacts\\n(a)Social impact of data mining\\n(b)Data mining and privacy\\n(c)Standardization eﬀorts\\n(d)Data mining system products\\n4.2 Advanced Topics (Course II)\\n1.Advanced Data Preprocessing. This unit will cover advanced data reduction methods.\\n(a)Advanced data reduction methods : (1) dimensionality reduction (feature or attribute sub-\\nset reduction), (2) numerosity reduction (regression, his togram, clustering, sampling, singular\\nvalue decomposition (SVD), and discretization), and (3) da ta compression (lossless versus lossy\\ncompression, Fourier and wavelet transformation, and prin cipal component analysis).\\n2.Data Warehousing, OLAP, and Data Generalization : This unit covers advanced material in\\ndata warehousing, OLAP, and data generalization\\n(a)The multidimensional data model\\n(b)Implementations of data warehouses : data integration, indexing OLAP data (bitmap index),\\neﬃcient processing of OLAP queries, metadata repository, d ata warehouse back-end tools and\\nutilities.\\n(c)Eﬃcient computation of data cubes : categorization of measures: distributive, algebraic, an d\\nholistic measures, cube computation methods, iceberg cube s, top-down and bottom-up computa-\\ntion, computing closed and approximate data cubes.\\n(d)Other data generalization approaches : Attribute-oriented induction, mining class compar-\\nisons: discriminating between diﬀerent classes.\\n(e)Exploration of data warehouse and data mining : Discovery-driven exploration of data\\ncubes, complex aggregation at multiple granularity, cube g radient analysis, from on-line analytical\\nprocessing to on-line analytical mining.\\n3.Advanced association, correlation, and frequent pattern a nalysis.\\n(a)Advanced frequent pattern mining methods : (1) vertical format mining, (2) pattern-growth\\nalgorithm, (3) mining closed patterns and max-patterns\\n(b)Constraint-based association mining : (1) rule- and query-guided association mining, (2)\\nanti-monotonicity, monotonicity, succinctness in constr ained mining, (3) convertible constraints.\\n(c)Extensions and applications of frequent pattern mining : (1) iceberg cube computation,\\n(2) fascicles and semantic data compression, (3) frequent p attern-based classiﬁcation and cluster\\nanalysis\\n4.Advanced Classiﬁcation.\\n(a)Bayesian belief networks : methods for (advanced) choosing BBN structure and trainin g\\nBayesian belief networks\\n(b)Advanced decision tree construction : (1) enhancements to basic classiﬁcation tree induc-\\ntion, (2) scalable algorithms for classiﬁcation tree induc tion, (3) integrating data warehousing\\ntechniques and classiﬁcation tree induction, (4) classiﬁc ation with partially labeled data\\n(c)Neural network approach for classiﬁcation : (1) a multi-layer feed-forward neural network,\\n(2) deﬁning a network topology, (3) back-propagation, (4) i nterpretability of classiﬁcation results.\\n6(d)Kernel methods : (1) kernel logistic regression, (2) kernel discriminant a nalysis, (3) advanced\\nSVM kernel methods.\\n(e)Introduction to learning theory : PAC-learnability, empirical, true and structural risk, V C-\\ntheory.\\n(f)Ensemble construction : Weighted voting, bagging, weak learner, boosting, AdaBoo st\\n(g)Other classiﬁcation methods : (1) case-based reasoning, (2) genetic algorithms, (3) rou gh set\\napproach, (4) fuzzy set approach\\n5.Advanced cluster analysis.\\n(a)Grid-based clustering : A statistical information grid approach, clustering by wa velet analysis,\\nclustering high-dimensional space.\\n(b)Clustering high-dimensional data : Subspace clustering, frequent pattern-based clustering ,\\nclustering by wavelet analysis.\\n(c)Advanced outlier analysis : Statistical-based outlier detection, distance-based ou tlier detection,\\ndeviation-based outlier detection, analysis of local outl iers.\\n(d)Collaborative ﬁltering :\\n6.Advanced Time-Series and Sequential Data Mining. This unit covers the advanced techniques\\nfor mining sequential data, including the following topics .\\n(a)Similarity search in time-series analysis :\\n(b)Hidden Markov models\\n(c)Periodicity analysis : Transformation-based approach, mining partial periodic ity.\\n(d)Sequence segmentation : Hidden Markov model and Variable Markov model for sequence seg-\\nmentation.\\n(e)Sequence classiﬁcation and clustering : (1)q-gram based methods, keyword-based methods;\\n(2) (high order) Markov chain, hidden Markov model; (3) suﬃx tree, probabilistic suﬃx tree, and\\nprobabilistic automata.\\n7.Mining Data Streams : This unit covers the techniques for mining stream data, inc luding the fol-\\nlowing topics.\\n(a)What is stream data?\\n(b)Basic tools: Chernoﬀ bounds, reservoir sampling\\n(c)Stream sample counting and frequent pattern analysis\\n(d)Classiﬁcation of data streams\\n(e)Clustering data streams\\n(f)Online sensor data analysis\\n8.Mining Spatial, Spatiotemporal, and Multimedia data. This unit covers the techniques for\\nmining spatial, spatiotemporal, and multimedia data, incl uding the following topics.\\n(a)Mining spatial and spatiotemporal databases : (1) Spatial data cube construction and spa-\\ntial OLAP, (2) spatial association and co-location analysi s, (3) spatial clustering methods, (4)\\nspatial classiﬁcation and spatial trend analysis, (5) spat iotemporal data miming, (6) mining mov-\\ning objects and trajectories.\\n(b)Mining multimedia databases : (1) multidimensional analysis of multimedia data, (2) sim ilar-\\nity search in multimedia data, (3) classiﬁcation and regres sion analysis of multimedia data, (4)\\nmining association and correlation in multimedia data, (5) clustering multimedia data\\n7(c)Mining object databases : (1) multidimensional analysis of complex objects, (2) gen eralization\\non complex structured and semi-structured data, (3) method ology for mining complex object\\ndatabases: aggregation, approximation, and progressive r eﬁnement.\\n9.Mining Biological Data : This unit covers the techniques for mining biological data , including the\\nfollowing topics.\\n(a)Mining DNA, RNA, and proteins : (1) Mining motif patterns, (2) searching homology in\\nlarge databases, (3) phylogenetic and functional predicti on.\\n(b)Mining gene expression data : (1) clustering gene expression, e.g., for gene regulatory net-\\nworks, (2) classifying gene expression, e.g., for disease- sensitive gene discovery.\\n(c)Mining mass spectrometry data\\n(d)Mining and integrating knowledge from biomedical literatu re\\n(e)Mining inter-domain associations\\n10.Text mining. This module will cover work that applies known mining techni ques to the text media,\\nemphasizing the new issues which arise.\\n(a)Text representation : Set-of-words, bag-of-words, vector-space model; the iss ue of large raw\\ndimensionality\\n(b)Dimensionality reduction : PCA, SVD, latent semantic indexing\\n(c)Text clustering : agglomerative, k-means, EM; eﬀect of a large number of noise dimensions,\\npartial supervision\\n(d)Feature selection in high dimensions\\n(e)Naive Bayes classiﬁcation : Poor density estimates, small-degree Bayesian belief net work in-\\nduction\\n(f)Discriminative learning : maximum entropy, logistic regression, and support vector learning\\n(g)Shallow linguistics : Phrase detection, part-of-speech tagging, named entity e xtraction, word\\nsense disambiguation\\n11.Hypertext and Web mining. This module will cover work that is speciﬁc to analyzing hype rmedia,\\ni.e., involving hierarchical tagging languages and hyperl inks in conjunction with text.\\n(a)Web modeling : The Web as an evolving, collaborative, populist social net work: aggregate\\ngraph-structure of the Web, preferential attachment linki ng models and experimental validation\\n(b)Link mining and social network analysis : Links as endorsement: PageRank and HITS\\nalgorithms to identify authoritative Web pages; connectio ns with bibliometry\\n(c)The PageRank algorithm : Integrating page content and page layout with link structu re; topic-\\nsensitive PageRanks; Google\\n(d)Mining by exploiting text and links : Exploiting text and links for better clustering and\\nclassiﬁcation; uniﬁed probabilistic models for text and li nks\\n(e)Structured data extraction : Information extraction, exploiting markup structure to e xtract\\nstructured data from pages meant for human consumption\\n(f)Multidimensional Web databases : Automatic construction of multilayered Web information\\nbase; discovering entities and relations on the Web (WebKB)\\n(g)Exploration and resource discovery on the Web : reinforcement learning, other approaches\\n(h)Web usage mining and adaptive Web sites : Reorganizing Web sites by mining log data\\n812.Data Mining Languages, Standards, and System Architecture s.This unit covers the issues\\nrelated to data mining languages, standards, and system arc hitectures, including the following topics.\\n(a)Data mining primitives : what deﬁnes a data mining task? task-relevant data, the kin d of\\nknowledge to be mined, background knowledge: concept hiera rchies, user-speciﬁed constraints,\\ninterestingness measures, presentation of discovered pat terns\\n(b)Data mining languages, user interfaces, and standardizati on eﬀorts\\n(c)Architectures of data mining systems\\n13.Data Mining Applications. This unit covers the issues related to domain-speciﬁc data m ining ap-\\nplications, including the following topics. (Note: Some of these themes, if concrete and good materials\\nare available, should go into the Foundations part as case st udies.)\\n(a)Data mining for ﬁnancial data analysis\\n(b)Data mining for the retail industry\\n(c)Data mining for the telecommunication industry\\n(d)Data mining for intrusion detection\\n(e)Data mining in scientiﬁc and statistical applications\\n(f)Data mining in software engineering and computer system ana lysis\\n14.Data Mining and Society. This unit covers the issues related to social impacts of data mining,\\nincluding the following topics.\\n(a)Social impacts of data mining\\n(b)Data mining vs. data security and privacy\\n(c)Privacy-preserving data mining\\n15.Trends in Data Mining. This unit covers the major trends in data mining, including t he following\\ntopics.\\n(a)Setting solid theoretical foundations for data mining\\n(b)Mining deep in speciﬁc applications\\n(c)Ubiquitous and invisible data mining\\n(d)Integrated data and information systems\\n5 Diﬀerent course modules and educational goals\\nSince the course can be taught in diﬀerent ﬁelds, such as comp uter science, business, and statistics, and with\\ndiﬀerent emphases, such as database, information systems, and machine learning, we should not expect the\\nmaterial will be covered in full spectrum with similar empha sis. We plan to insert some modules based on\\nthe feedbacks of instructors who have taught materials in sp eciﬁc ﬁelds.\\n96 Laboratories and exercises\\nLaboratories and exercises give students an opportunity to carry out experiments that illustrate topics in a\\nrealistic setting and at the same time learn the speciﬁcs of t he software used. Students may also be assigned\\nto work on projects too large to be completed during a single c lass period. Laboratories can provide time for\\nindependent project work and programming assignments with reporting similar to that done in other topics\\nin computer science.\\nThe lab projects can be categorized into several categories , and more innovative ideas and suggestions\\nare encouraged.\\n1. Learn to use data mining systems by using some data mining a nd data warehousing softwares. Typical\\nsuch softwares may include Microsoft SQLServer 2005 (Analy sis manager), Oracle 10g (data mining\\npart), IBM Intelligent-Miner, and statistics analysis sof tware tools.\\n2. Implement some data mining functions, including associa tion mining, classiﬁcation, clustering, sequen-\\ntial pattern mining, text-mining, Web mining, bio-mining, spatial data mining packages. Some open\\nor partially open source data mining systems, such as Weka, I lliMine, and so on can be used for data\\nmining algorithm extension and data mining application exp loration.\\n3. Implementation, reﬁnement, and performance comparison of several diﬀerent data mining methods.\\n4. Proposal, implementation and testing of new data mining a lgorithms and functions.\\n5. Using some sample data sets to implement and test data mini ng functions, such as KDD CUP data\\nsets, UC-Irvine Machine Learning/KDD Repository, DBLP dat abase, and other selected Web data\\nsets.\\n10'}, {'document_name': 'grossman98-Data-minin-research-opportunities.pdf', 'file_path': '../data\\\\Folder2\\\\grossman98-Data-minin-research-opportunities.pdf', 'content': 'Data Mining Research: Opportunities and Challenges\\nA Report of three NSF Workshops on Mining Large, Massive, and Distributed\\nData*\\nRobert Grossman**, Simon Kasif, Reagan Moore, David Rocke, and Jeff Ullman \\nJanuary 21, 1998 (Draft 8.4.5)\\n*These workshops were supported in part by the National Science Foundation under grant IRI-9802160\\n(PI: Robert Grossman) from the Information and Data Management Program, grant DMS-9714104 from\\nthe Algebra and Number Theory Program, and grant DMS-9705599 (PI: David Rocke) from the\\nStatistics and Probability Program. All opinions, findings, conclusions and recommendations in any\\nmaterial resulting from these workshops are those of the workshops’ participants, and do not necessarily\\nreflect the views of the National Science Foundation.\\n**Robert Grossman is the editor of this report. Comments for future versions are welcome.\\n1. Executive Summary\\nA group of researchers met in Chicago in July, 1997 and in La Jolla in March, 1997 and February, 1998\\nto discuss the current state of the art of data mining and data intensive computing and the opportunities\\nand challenges for the future. The focus of the discussions was on mining large, massive, and distributed\\ndata sets. Here are the main conclusions of the workshops:\\nThe field of data mining and knowledge discovery is emerging as a new, fundamental research\\narea with important applications to science, engineering, medicine, business, and education. Data\\nmining attempts to formulate, analyze and implement basic induction processes that facilitate the\\nextraction of meaningful information and knowledge from unstructured data. Data mining extracts\\npatterns, changes, associations and anomalies from large data sets. Work in data mining ranges\\nfrom theoretical work on the principles of learning and mathematical representations of data to\\nbuilding advanced engineering systems that perform information filtering on the web, find genes\\nin DNA sequences, help understand trends and anomalies in economics and education, and detect\\nnetwork intrusion. Data mining is also a promising computational paradigm that enhances\\ntraditional approaches to discovery and increases the opportunities for breakthroughs in the\\nunderstanding of complex physical and biological systems. Researchers from many intellectual\\ncommunities have much to contribute to this field. These include the communities of machine\\nlearning, statistics, databases, visualization and graphics, optimization, computational\\nmathematics, and the theory of algorithms. \\nThe amount of digital data has been exploding during the past decade, while the number of\\nscientists, engineers, and analysts available to analyze the data has been static. To bridge this gap\\nrequires the solution of fundamentally new research problems, which can be grouped into the\\nfollowing broad challenges: A) developing algorithms and systems to mine large, massive and\\nhigh dimensional data sets; B) developing algorithms and systems to mine new types of data; C)\\ndeveloping algorithms, protocols, and other infrastructure to mine distributed data; and D)\\nimproving the ease of use of data mining systems; E) developing appropriate privacy and securitymodels for data mining.\\nThere is an important need for support by government and business of basic, applied,\\nmultidisciplinary and interdisciplinary research in data mining and knowledge discovery in order\\nto respond to these challenges. \\nThere is an important experimental component to data mining and knowledge discovery which\\nrequires the creation and maintenance of appropriate systems, computational infrastructures and\\ntest beds.\\n2. What is Data Mining?\\nData mining is the semi-automatic discovery of patterns, associations, changes, anomalies, rules, and\\nstatistically significant structures and events in data. That is, data mining attempts to extract knowledge\\nfrom data. \\nData mining differs from traditional statistics in several ways: formal statistical inference is assumption\\ndriven in the sense that a hypothesis is formed and validated against the data. Data mining in contrast is\\ndiscovery driven in the sense that patterns and hypothesis are automatically extracted from data. Said\\nanother way, data mining is data driven, while statistics is human driven. The branch of statistics that\\ndata mining resembles most is exploratory data analysis, although this field, like most of the rest of\\nstatistics, has been focused on data sets far smaller than most that are the target of data mining\\nresearchers.\\nData mining also differs from traditional statistics in that sometimes the goal is to extract qualitative\\nmodels which can easily be translated into logical rules or visual representations; in this sense data\\nmining is human centered and is sometimes coupled with human-computer interfaces research. \\nData mining is a step in the data mining process, which is an interactive, semi-automated process which\\nbegins with raw data. Results of the data mining process may be insights, rules, or predictive models.\\nThe field of data mining draws upon several roots, including statistics, machine learning, databases, and\\nhigh performance computing.\\nIn this report, we are primarily concerned with large data sets, massive data sets, and distributed data\\nsets. By large, we mean data sets which are too large to fit into the memory of a single workstation. By\\nmassive, we mean data sets which are too large to fit onto the disks of a single workstation or a small\\ncluster of workstations. Instead, massive clusters or tertiary storage such as tape are required. By\\ndistributed, we mean data sets which are geographically distributed.\\nThe focus on large data sets is not an just an engineering challenge; it is an essential feature of induction\\nof expressive representations from raw data. It is only by analyzing large data sets that we can produce\\naccurate logical descriptions that can be translated automatically into powerful predictive mechanisms.\\nOtherwise, statistical and machine learning principles suggest the need for substantial user input\\n(specifying meta-knowledge necessary to acquire highly predictive models from small data sets). \\n3. Recent Research AchievementsThe opportunities today in data mining rest solidly on a variety of research achievements, the majority\\nof which were the result of government sponsored research. In this section, we mention a few of the\\nmore important ones. Note that several of them are interdisciplinary in nature, resting on discoveries\\nmade by researchers from different disciplines working together collaboratively. Neural Networks.  Neural networks are systems inspired by the human brain. A basic example is\\nprovided by a back propagation network which consists of input nodes, output nodes, and intermediate\\nnodes called hidden nodes. Initially, the nodes are connected with random weights. During the training,\\na gradient descent algorithm is used to adjust the weights so that the output nodes correctly classify data\\npresented to the input nodes. The algorithm was invented independently by several groups of\\nresearchers.\\nTree-based Classifiers.  A tree is a convenient way to break a large data sets into smaller ones. By\\npresenting a learning set to the root and asking questions at each interior node, the data at the leaves can\\noften be analyzed very simply. For example, a classifier to predict the likelihood that a credit card\\ntransaction is fraudulent may use an interior node to divide a training data set into two sets, depending\\nupon whether or not five or fewer transactions were processed during the previous hour. After a series of\\nsuch questions, each leaf can be labeled fraud/no-fraud by using a simple majority vote. Tree based\\nclassifiers were independently invented in information theory, statistics, pattern recognition and machine\\nlearning. \\nGraphical Models and Hierarchical Probabilistic Representations.  A directed graph is a good means of\\norganizing information about qualitative knowledge about conditional independence and causality\\ngleamed from domain experts. Graphical models generalize generalize Markov models and hidden\\nMarkov models, which have proved themselves to be a powerful modeling tool. Graphical models were\\nindependently invented by computational probabilists and artificial intelligence researchers studying\\nuncertainty. Ensemble Learning.  Rather than use data mining to build a single predictive model, it is often better to\\nbuild a collection or ensemble of models and to combine them, say with a simple, efficient voting\\nstrategy. This simple idea has now been applied in a wide variety of contexts and applications. In some\\ncircumstances, this technique is known to reduce variance of the predictions and therefore to decrease\\nthe overall error of the model. Linear Algebra.  Scaling data mining algorithms often depends critically upon scaling underlying\\ncomputations in linear algebra. Recent work in parallel algorithms for solving linear system and\\nalgorithms for solving sparse linear systems in high dimensions are important for a variety of data\\nmining applications, ranging from text mining to detecting network intrusions.Large Scale Optimization.  Some data mining algorithms can be expressed as large-scale, often\\nnon-convex, optimization problems. Recent work has provided parallel and distributed methods for\\nlarge-scale continuous and discrete optimization problems, including heuristic search methods for\\nproblems too large to be solved exactly.High Performance Computing and Communication.  Data mining requires statistically intensive\\noperations on large data sets. These types of computations would not be practical without the emergence\\nof powerful SMP workstations and high performance clusters of workstations supporting protocols for\\nhigh performance computing such as MPI and MPIO. Distributed data mining can require moving largeamounts of data between geographically separated sites, something which is now possible with the\\nemergence of wide area high performance networks.Databases, Data Warehouses, and Digital Libraries.  The most time consuming part of the data mining\\nprocess is preparing data for data mining. This step can be stream-lined in part if the data is already in a\\ndatabase, data warehouse, or digital library, although mining data across different databases, for\\nexample, is still a challenge. Some algorithms, such as association algorithms, are closely connected to\\ndatabases, while some of the primitive operations being built into tomorrow’s data warehouses should\\nprove useful for some data mining applications.\\nVisualization of Massive Data Sets.  Massive data sets, often generated by complex simulation programs,\\nrequired graphical visualization methods for best comprehension. Recent advances in multi-scale\\nvisualization allow the rendering to be done far more quickly and in parallel, making these visualization\\ntasks practical.\\n4. New Applications\\nThe discipline of data mining is driven in part by new applications which require new capabilities not\\ncurrently being supplied by today’s technology. These new applications can be naturally divided into\\nthree broad categories.\\na.Business & E-commerce Data.  Back-office, front-office, and network applications produce large\\namounts of data about business processes. Using this data for effective decision making remains a\\nfundamental challenge. \\nb.Scientific, Engineering & Health Care Data.  Scientific data and meta-data tend to be more\\ncomplex in structure than business data. In addition, scientists and engineers are making increasing\\nuse of simulation and of systems with application domain knowledge.\\nc.Web Data.  The data on the web is growing not only in volume but also in complexity. Web data\\nnow includes not only text and image, but also streaming data and numerical data. \\nIn this section, we describe several such applications from each category.Business Transactions.  Today, businesses are consolidating and more and more businesses have millions\\nof customers and billions of their transactions. They need to understand risks (Is this transaction\\nfraudulent? Will this customer pay their bills?) and opportunities (What is the expected profit of this\\ncustomer? What product is this customer most likely to buy next?).Electronic Commerce.  Not only does electronic commerce produce large data sets in which the analysis\\nof marketing patterns and risk patterns is critical, but unlike some of the applications above, it is also\\nimportant to do this in real or near-real time, in order to meet the demands of on-line transactions.\\nGenomic Data.  Genomic sequencing and mapping efforts have produced a number of databases which\\nare accessible over the web. In addition, there are also a wide variety of other on-line databases,\\nincluding those containing information about diseases, cellular function, and drugs. Finding\\nrelationships between these data sources, which are largely unexplored, is another fundamental data\\nmining challenge. Recently, scalable techniques have been developed for comparing whole genomes.Sensor Data.  Satellites, buoys, balloons, and a variety of other sensors produce voluminous amounts of\\ndata about the earth’s atmosphere, oceans, and lands. A fundamental challenge is to understand the\\nrelationships, including causal relationships amongst this data. For example, do industrial pollutants\\naffect global warming? There are also large terabyte to petabyte data sets being produced by sensors and\\ninstruments in other disciplines, such as astronomy, high energy physics, and nuclear physics. \\nSimulation Data.  Simulation is now accepted as a third mode of science, supplementing theory and\\nexperiment. Today, not only do experiments produce huge data sets, but so do simulations. Data mining,\\nand more generally data intensive computing, is proving to be a critical link between theory, simulation,\\nand experiment. Health Care Data.  Health care has been the most rapidly growing segment of the nation’s GDP for some\\ntime. Hospitals, health care organizations, insurance companies, and the federal government have large\\ncollections of data about patients, their health care problems, the clinical procedures used, their costs,\\nand the outcomes. Understanding relationships in this data is critical for a wide variety of problems,\\nranging from determining what procedures and clinical protocols are most effective to how best to\\ndeliver health care to the most people in an era of diminishing resources.\\nMulti-media Documents.  Few people are satisfied with today’s technology for retrieving documents on\\nthe web, yet the number of documents and the number of people accessing these documents is growing\\nexplosively. In addition, it is becoming easier and and easier to archive multi-media data, including\\naudio, images, and video data, but harder and harder to extract meaningful information from the archives\\nas the volume grows. \\nThe Data Web.  Today the web is primarily oriented toward documents and their multi-media extensions.\\nHTML has proved itself to be a simple, yet powerful language for supporting this. Tomorrow the\\npotential exists for the web to prove equally important for working with data. The Extensible Markup\\nLanguage (XML) is an emerging language for working with data in networked environments. As this\\ninfrastructure grows, data mining is expected to be a critical enabling technology for the emerging data\\nweb.\\n5. Success Stories\\nIn this section, we briefly describe some success stories involving data mining and knowledge\\ndiscovery.\\nAssociation Rules.  Suppose we have a collection of items. The data for many applications consists of\\nmultiple transactions, where each transaction consists of one or more items. A basic example is provided\\nby a supermarket, where the items are the products offered for sale and the transactions are purchases,\\nconsisting of one or more products purchased by an individual at a given time. A fundamental problem\\nis to uncover associations: which products tend to be purchased together. There has been a lot of recent\\nwork on this problem and a variety of algorithms have been developed which can be discover\\nassociations, even in very large data sets, with just a few passes over the data. A variety of commercial\\ndata mining systems support association rules and they are now routinely applied to a range of problems\\nfrom database marketing to product placement for supermarkets. In addition, association rules\\nalgorithms have spurred new research in a variety of areas from databases to complexity theory. \\nFraud Detection.  Although relatively few credit card transactions are fraudulent, the sheer volume oftransactions means that over $500M are lost each year in this way. A variety of data mining techniques\\nhave been used to develop fraud systems which can detect fraudulent credit card transactions in\\nnear-real time. This problem is challenging due to the size of the data sets, the rarity of the events of\\ninterest, and the performance requirements for near-real time detection. Data mining has also improved\\nfraud detection in other application areas, including telcom fraud and insurance fraud. \\nAstronomical Data.  Traditionally, the search for new galaxies, stars, and quasars has primarily been\\ndone by astronomers visually examining individual photographic plates. Classification algorithms from\\ndata mining have recently been used to automate this process yielding new astronomical discoveries.\\nThe classification algorithms are applied to derived attributes produced by image processing, such as the\\nbrightness, area, and morphology of sky objects. The approach has also proved useful for detecting new\\nobjects too faint to be observed by a manual analysis or traditional computational techniques. For the\\n2nd Palomar Observatory Sky Survey, this approach resulted in over a three-fold increase in the size of\\nthe catalog.\\nGenomic Data.  Genomic data is stored all over the world, in a variety of formats and managed by a\\nvariety of applications and systems. Recently, systems have been developed which allow discoveries to\\nbe made involving information distributed over several systems. In particular, the new systems have\\nenabled for the first time whole genome comparison, gene identification, and whole genome functional\\ninterpretation and analysis. The techniques developed for analyzing genomic and other types of\\nscientific data can be expected to to play a role on analyzing a broad range of biological data.Distributed Data Mining. Traditionally, data mining has required that the relevant data be warehoused in\\na single location. Recently, distributed data mining systems have exploited wide area, high performance\\nnext networks, such as the NSF vBNS network, to mine large amounts of distributed scientific and\\nhealth care data. Recently, these systems have set records for the sustained movement of very large\\namounts of data over wide area networks. Separately, a prototype has been developed exploiting\\ndistributed data mining to improve the detection of credit card fraud.\\nText Mining.  Recently, data mining has been combined with algorithms from information retrieval to\\nimprove the precision and recall of queries on very large collections of documents. In particular, some\\nof these algorithms have proved useful on multi-lingual collections and others have shown their worth\\non querying using concepts instead of key words.\\n6. Trends that Effect Data Mining\\nIn this section, we describe five external trends which promise to have a fundamental impact on data\\nmining.Data Trends.  Perhaps the most fundamental external trend is the explosion of digital data during the past\\ntwo decades. During this period, the amount of data probably has grown between six to ten orders of\\nmagnitude. Much of this data is accessible via networks. On the other hand, during this same period the\\nnumber of scientists, engineers, and other analysts available to analyze this data has remained relatively\\nconstant. For example, the number of new Ph.D.’s in statistics graduating each year has remained\\nrelatively constant during this period. Only one conclusion is possible: either most of the data is destined\\nto be write-only, or techniques, such as data mining, must be developed, which can automate, in part, the\\nanalysis of this data, filter irrelevant information, and extract meaningful knowledge.Hardware Trends.  Data mining requires numerically and statistically intensive computations on large\\ndata sets. The increasing memory and processing speed of workstations enables the mining of data sets\\nusing current algorithms and techniques that were too large to be mined just a few years ago. In addition,\\nthe commoditization of high performance computing through SMP workstations and high performance\\nworkstation clusters enables attacking data mining problems that were accessible using only the largest\\nsupercomputers of a few years ago.Network Trends.  The next generation internet (NGI) will connect sites at OC-3 (155 MBits/sec) speeds\\nand higher. This is over 100 times faster than the connectivity provided by current networks. With this\\ntype of connectivity, it becomes possible to correlate distributed data sets using current algorithms and\\ntechniques. In addition, new protocols, algorithms, and languages are being developed to facilitate\\ndistributed data mining using current and next generation networks.\\nScientific Computing Trends.  As mentioned above, scientists and engineers today view simulation as a\\nthird mode of science. Data mining and knowledge discovery serves an important role linking the three\\nmodes of science: theory, experiment and simulation, especially for those cases in which the experiment\\nor simulation results in large data sets.Business Trends.  Today businesses must be more profitable, react quicker, and offer higher quality\\nservices than ever before, and do it all using fewer people and at lower cost. With these types of\\nexpectations and constraints, data mining becomes a fundamental technology, enabling businesses to\\nmore accurately predict opportunities and risks generated by their customers and their customers’\\ntransactions.\\n7. Research Challenges\\nIn this section, we describe some of the major research challenges identified by the three workshops.\\nThe research challenges are arranged into five broad areas: A) improving the scalability of data mining\\nalgorithms, B) mining non-vector data, C) mining distributed data, D) improving the ease of use of data\\nmining systems and environments, and E) privacy and security issues for data mining.\\nA. Scaling data mining algorithms.  Most data mining algorithms today assume that the data fits into\\nmemory. Although success on large data sets is often claimed, usually this is the result of sampling large\\ndata sets until they fit into memory. A fundamental challenge is to scale data mining algorithms as \\n1.the number of records or observations increases; \\n2.the number of attributes per observation increases; \\n3.the number of predictive models or rule sets used to analyze a collection of observations increases;\\n4.and, as the demand for interactivity and real-time response increases. \\nNot only must distributed, parallel, and out-of-memory versions of current data mining algorithms be\\ndeveloped, but genuinely new algorithms are required. For example, association algorithms today can\\nanalyze out-of-memory data with one or two passes, while requiring only some auxiliary data be kept in\\nmemory. B. Extending data mining algorithms to new data types.  Today, most data mining algorithms work with\\nwith vector-valued data. It is an important challenge to extend data mining algorithms to work with\\nother data types, including 1) time series and process data, 2) unstructured data, such as text, 3)semi-structured data, such as HTML and XML documents, 4) multi-media and collaborative data, 5)\\nhierarchical and multi-scale data, and 6) and collection-valued data. \\nC. Developing distributed data mining algorithms.  Today most data mining algorithms require bringing\\nall together data to be mined in a single, centralized data warehouse. A fundamental challenge is to\\ndevelop distributed versions of data mining algorithms so that data mining can be done while leaving\\nsome of the data in place. In addition, appropriate protocols, languages, and network services are\\nrequired for mining distributed data to handle the meta-data and mappings required for mining\\ndistributed data. As wireless and pervasive computing environments become more common, algorithms\\nand systems for mining the data produced by these types of systems must also be developed.D. Ease of Use.  Data mining today is at best a semi-automated process and perhaps destined to always\\nremain so. On the other hand, a fundamental challenge is to develop data mining systems which are\\neasier to use, even by casual users. Relevant techniques include improving user interface, supporting\\ncasual browsing and visualization of massive and distributed data sets, developing techniques and\\nsystems to manage the meta-data required for data mining, and developing appropriate languages and\\nprotocols for providing casual access to data. In addition, the development of data mining and\\nknowledge discovery environments  which address the process  of collecting, processing, mining, and\\nvisualizing data, as well as the collaborative and reporting aspects necessary when working with data\\nand information derived from it, is another important fundamental challenge.E. Privacy and Security.  Data mining can be a powerful means of extracting useful information from\\ndata. As more and more digital data becomes available, the potential for misuse of data mining grows. A\\nfundamental challenge is to develop privacy and security models and protocols appropriate for data\\nmining and to ensure that next generation data mining systems are designed from the ground up to\\nemploy these models and protocols.\\n8. Testbeds and Infrastructure\\nExperimental studies will play a critical role in advancing the field of data mining. Developed testbeds\\nfor high performance and distributed data mining is essential for progress in the field. \\nThe requirements for data mining testbeds are different than those for general purpose high performance\\ncomputing testbeds. For example, the computing resources for data mining testbeds are as much\\ndisk-oriented as processor-oriented; the network resources must be able move data sets and data\\nelements between geographically distributed sites with guaranteed quality of service; and a variety of\\ngeneral purpose and specialized data mining software must be available.\\nPerhaps the two most difficult challenges in creating data mining testbeds and national resources in data\\nmining are assembling a) the appropriate data sets and b) the required interdisciplinary and\\nmultidisciplinary teams. \\n9. Findings and Recommendations\\nIn this section, we list some of the major findings of these three workshops.\\nFor all interested parties:Data mining and knowledge discovery is a new emerging discipline with both a scientific and\\nengineering component that is of strategic importance for the U.S. and of critical importance to future\\ninformation access technologies. All interested parties are encouraged to work towards the maturation of\\ndata mining and knowledge discovery, towards its establishment as a scientific and engineering\\ndiscipline in its own right, and towards the evolution of a community that includes the relevant traditions\\nand disciplines and puts them together in the proper context.\\nFor the federal government:  \\n1.Create programs which encourage the emergence of data mining and knowledge discovery as an\\nindependent discipline.\\n2.Support interdisciplinary and multidisciplinary research projects. Many advances in data mining\\nrequire teams of mathematicians and statisticians, computer scientists, and application domain\\nscientists working together to create the appropriate data sets and the required algorithms and\\nsoftware to analyze them. \\n3.Support basic research in computer and information sciences that underlies data mining, including\\nmachine learning, knowledge systems, data bases, high performance computing, high performance\\nnetworking, and digital libraries. \\n4.Support basic research in mathematics and statistics that underlies data mining, including statistics,\\nprobability, applied mathematics, logic, discrete mathematics, analysis and dynamical systems,\\nlinear algebra, and computational geometry and algebra.\\n5.Support data mining testbeds. The hardware, software, data and consulting requirements for data\\nmining often out-strip the resources of individual scientists and small research groups. Supporting\\nnational resources and testbeds for data mining is important in order to provide the proper\\nexperimental infrastructure required for next generation data mining experiments.\\nFor companies:\\n1.Support applied research in data mining.\\n2.Work to develop, implement and support appropriate privacy and security models for data mining\\nsystems.\\n3.Create sanitized versions of real data sets for use by data mining researchers.\\n4.Support joint research projects between industry and universities. Support collaborative testbeds\\nand demonstration projects. \\nFor scientists and engineers:\\n1.As new data is collected and archived, support emerging protocols, languages, and standards to\\nfacilitate the future analysis and mining of the data, especially by scientists and engineers from\\nother disciplines.2.As new data is collected and as new systems are built to manage it, ensure that the best available\\nprivacy and security models are used to protect inadvertent disclosures of private information.\\n3.Provide long-term maintenance and access to data sets created by scientists and engineers, as well\\nas to the knowledge and information extracted from them.\\n10. Conclusions\\nData mining and knowledge discovery are emerging as a new discipline with important applications to\\nscience, engineering, health care, education, and business. Data mining rests firmly on 1) research\\nadvances obtained during the past two decades in a variety of areas and 2) more recent technological\\nadvances in computing, networking and sensors. Data mining is driven by the explosion of digital data\\nand the scarcity of scientists, engineers, and domain experts available to analyze it.\\nData mining is beginning to contribute research advances of its own, by providing scalable extensions\\nand advances to work in associations, ensemble learning, graphical models, techniques for on-line\\ndiscovery, and algorithms for the exploration of massive and distributed data sets.\\nAdvances in data mining requires a) supporting single investigators working in data mining and the\\nunderlying research domains supporting data mining; b) supporting inter-disciplinary and\\nmulti-disciplinary research groups working on important basic and applied data mining problems; and c)\\nsupporting the appropriate testbeds for mining large, massive and distributed data sets.\\nAppropriate privacy and security models for data mining must be developed and implemented.\\n11. References\\nReferences for the material above can be found in the Supplement to this report, which will be\\nforthcoming. \\n12. Acknowledgements\\nThe editors would like to thank Usama Fayyad for his comments on an earlier draft of this report.\\nRobert Grossman is at the National Center for Data Mining at the University of Illinois at Chicago and\\nMagnify, Inc. Simon Kasif is at the National Center for Data Mining and the Department of Electrical\\nEngineering and Computer Science at the University of Illinois at Chicago. Reagan Moore is at the San\\nDiego Supercomputer Center. David Rocke is at the Center for Image Processing and Integrated\\nComputing at the University of California at Davis. Jeff Ullman is at the Department of Computer\\nScience at Stanford University. \\nAppendix A. M3D-97, Chicago\\nThis M3D-97 Workshop took place on July 12-15, 1997 in Chicago and was supported by NSF grant\\nDMS-9714104 from the Algebra and Number Theory Program. Listed below are the speakers and the\\ntitles of their talks. 1.Michael Berry, University of Tennessee, \"Dynamic Information Management using Latent\\nSemantic Indexing\" \\n2.Herbert Edelsbrunner, University of Illinois at Urbanna Champaign, \"Constructing Shapes from\\nPoints in Dimension 3 and Beyond\" \\n3.John Elder, ELDER Research, \"Fusing Diverse Algorithms\" \\n4.Christos Faloutsos, University of Maryland at College Park, \"Applications, Requirements and\\nDatabase Tools for Massive Data Mining\" \\n5.Usama Fayyad, Microsoft, \"Data Mining and KDD: So What’s New?\" \\n6.Robert Grossman, University of Illinois at Chicago & Magnify, Inc. \"Dynamic Similarity: Mining\\nCollections of Trajectories\" \\n7.Peter Jones, Yale University, \"On the Structure of Low Dimensional Sets\" \\n8.Michael Jordan, MIT, \"Graphical models and variational approximation\" \\n9.Simon Kasif, University of Illinois at Chicago, \"A Computational Framework for Data Mining:\\nData Structures and Algorithms for Efficient Probabilistic Inference\" \\n10.Heikki Mannila, University of Helsinki, \"Association rules, episode rules and frequent sets:\\nalgorithms and applications\" \\n11.Vince Poor, Princeton University, \"Quickest Detection: Time Optimal Methods for Statistical\\nChange Detection\" \\n12.J. Ross Quinlan, University of Sydney, \"Tree-Based Classifiers and Extensions\" \\n13.Eric Ristad, Princeton University, Maximum Entropy Modeling for Discrete Domains\" \\n14.Dan Roth, Weizman Institute of Science, \"Learning and Managing Knowledge in Large Scale\\nNaural Language Inferences\" \\n15.Stuart Russell, University of California at Berkeley, \"Adaptive Probabilistic Networks\" \\n16.Fred Warner, Yale University, \"Adapted Waveform Analysis as a Tool for Data Transcription,\\nRudimentary Modeling and Feature Extraction\" \\nAppendix B. M3D2-98, La Jolla\\nThe M3D2-98 workshop took place on February 5-6, 1998 in La Jolla, California and was supported by\\nNSF grant IRI-9802160 from the Information and Data Management (IDM) Program. The individuals\\nlisted below participated in workshop. Discussions took place in two break out groups: 1) Research\\nIssues and Fundamental Challenges, and 2) Testbeds and Infrastructure.\\nStuart Bailey, University of Illinois at Chicago\\nScott Baden, University of California, San Diego \\nChaitanya Baru, San Diego Supercomputing Center\\nDon Benton, University of Pennsylvania\\nPeter Buneman, University of Pennsylvania\\nAlok Choudhary, Northwestern University\\nThomas Dietterich, Oregon State University\\nMarcio Faerman, University of California, San Diego\\nRobert Grossman, University of Illinois at Chicago and Magnify\\nBob Hollebeek, University of Pennsylvania\\nChandrik Kamath, Lawrence Livermore National Laboratory\\nCarl Kesselman, University of Southern California\\nReagan Moore, San Diego Supercomputing Center\\nRon Musick, Lawrence Livermore National Laboratory\\nPavlos Protopapas, University of PennsylvaniaArcot Rajasekar, San Diego Supercomputing Center\\nDavid Rocke, University of California, Davis\\nJoel Saltz, University of Maryland \\nVivek Sharma, University of California, San Diego \\nTerry Smith, University of California, Santa Barbara\\nPadhraic Smyth, University of California, Irvine\\nPaul Stolorz, Jet Propulsion Laboratory\\nJeff Ullman, Stanford University\\nRoy Williams, Caltech\\nMaria Zemankdova, NSF\\nThe following talks were given:\\n1.Robert Grossman, University of Illinois at Chicago and Magnify, Inc. \\n& Reagan Moore, San Diego Supercomputing Center, \"Managing and Mining Massive Data Sets:\\nIntroduction.\" \\n2.Thomas Dietterich, Oregon State University, \"Scaling Up Machine Learning for Data Mining\\nApplications.\" \\n3.Carl Kesselman, University of Southern California, \"An Overview of Infrastructures for Wide\\nArea High Performance Computation.\" \\n4.Jeff Ullman, Stanford University, \"Association-Rule Mining.\" \\n5.Padhraic Smyth, University of California -Irvine & Jet Propulsion Laboratory, \"Fundamental\\nChallenges in Data Mining.\" \\nAppendix C. Approaches to the Analysis and Visualization of Massive Data Sets, La\\nJolla\\nThe Data Mining and Visualization Workshop was held on March 14-15, 1997 in La Jolla and was\\nsupported by NSF grant DMS-9705599 from the Statistics and Probability Program. Listed below are\\nthe speakers and the titles of their talks. \\n1.William Eddy, Carnegie Mellon University, \"Interaction with Massive Data Sets via an Index\" \\n2.Dan Gusfield, University of California at Davis, \"Extracting the Essence From Collections of\\nMolecular Sequences; a Problem Statement\"  \\n3.Bernd Hamann, University of California at Davis, \"Issues Regarding the Hierarchical\\nRepresentation of Large Data Sets for Analysis and Visualization\" \\n4.Ken Joy, University of California at Davis, \"Hierarchical Reduction Methods for Massive Data\\nSets\"  \\n5.Giovanni Marchisio, Mathsoft, Inc., \"Document-term Matrix Decomposition for Intelligent\\nInformation Retrieval\" \\n6.Nelson Max, Lawrence Livermore National Laboratory, \"Visualizing Global Climate and Finite\\nElement Simulations\" \\n7.Reagan Moore, San Diego Supercomputer Center, \"Information Based Computing\" \\n8.Robert Moorhead, Mississippi State University, \"Visualization of Air/Sea Model Data\" \\n9.Emanuel Parzen, Texas A&M University, \"Comparison Density and Quantile Statistical Methods\\nand Massive Data Set Analysis\" \\n10.Tom Prince, California Institute of Technology, \"Digital Sky\" \\n11.Jim Quinn, University of California at Davis, \"Strategies for Integrating Interagency Data onBiodiversity and Water Issues\" \\n12.David Rocke, University of California at Davis, \"Partitioning and Subsampling to Uncover Subtle\\nStructure in Massive Data Sets\"  \\n13.Hanan Samet, University of Maryland, \"Sorting in Space\" \\n14.David Scott, Rice University, \"Statistics and Massive Data Sets: A New Look at the Method of\\nMoments and Maximum Likelihood\" \\n15.David Shanno, Rutgers University, \"Topics in Very Large Scale Optimization\" \\n16.Elizabeth Thompson, University of Washington, \"Monte Carlo Likelihood in Some Problems of\\nGenetic Analysis\" \\n17.Ed Wegman, George Mason University, \"Thoughts on Statistical Data Mining\" \\n18.David Woodruff, University of California at Davis, \"Heuristic Search Applications\" '}, {'document_name': 's11761-019-00265-x.pdf', 'file_path': '../data\\\\Folder2\\\\s11761-019-00265-x.pdf', 'content': 'Service Oriented Computing and Applications (2019) 13:105–107\\nhttps://doi.org/10.1007/s11761-019-00265-x\\nEDITORIAL\\nResearch challenges of big data\\nMuhammad Younas1\\nReceived: 3 June 2019 / Accepted: 5 June 2019 / Published online: 14 June 2019\\n© Springer-Verlag London Ltd., part of Springer Nature 2019\\nAbstract\\nBig data is characterised by new characteristics such as 3Vs (V olume, V elocity, V ariety), and/or 5Vs (V olume, V elocity, V ariety,V eracity, and V alue). Due to the distinguishing characteristics of big data, it is commonly stored and processed using NoSQL\\n(Not Only SQL) database systems. Big data has been utilised in various applications and services ranging from E-commerce\\nthrough to social media to public sector and governmental organisations. The goal of this editorial note is to provide a concisesummary of the big data characteristics, models, and technologies and to identify some of the crucial research challenges that\\nare open for further research.\\n1 Characteristics of big data\\nBig data refers to the large volume of complex, (semi) struc-\\ntured, and unstructured data that are generated in a largesize and that arrive (in a system) at a higher speed so thatit can be analysed for better decision making and strategic\\norganisation and business moves. But the process of man-\\naging (only) large volume of data is not new. For example,one of the top-ranking database conferences on V ery Large\\nDatabases (VLDB) has been running for more than 40 years.\\nThe proceedings of VLDB include a number of articles thatprovide useful solutions for managing large volume of com-\\nplex data. But the concept of big data has gained popularity\\nwith the new applications and new characteristics such as 3Vs(V olume, V elocity, V ariety), and/or 5Vs (V olume, V elocity,V ariety, V eracity, and V alue). Figure 1[1] shows a generic\\nview of the 5Vs characteristics and applications of big data.\\nThese are brieﬂy described as follows [ 2]:\\nVo l u m e This refers to the massive amount of data which are\\nbeing generated, gathered, and processed, for example, inthe size of petabytes, exabytes, and zettabytes. For instance,\\nTwitter receives/processes millions of tweets on a regular\\nbasis. Similarly, Facebook routinely handles millions of postsand images. Google receives more than a billion search\\nqueries. Further, millions of data records are gathered from\\nB Muhammad Y ounas\\nm.younas@brookes.ac.uk\\n1School of Engineering, Computing and Mathematics, OxfordBrookes University, Oxford, UKsensor technologies associated with transportation, weather,\\nenvironmental systems, and so on.\\nV elocity This refers to the speed at which data are gener-\\nated, processed, and moved between different systems and\\ndevices. Examples include the speed of social media posts;\\nonline transactions and fraud checking; live transportationdata received from buses, trains, aeroplanes, etc.\\nVa r i e t y This refers to the different types of data that can be\\nused (together) for achieving desired information or results.\\nTypes and format of big data include structured, semi-\\nstructured, and unstructured data.\\nV eracity This refers to the quality of data such as correctness,\\nconsistency, trust, security, and reliability. For example, dataare not stale or out of date for a given purpose. Similarly, data\\nshould be correct and consistent and it should be generated\\nby a trusted system.\\nVa l u e This refers to the different types of beneﬁts that can be\\nderived from processing and analysing big data. Examples\\ninclude, monetary value, social value, research/education\\nvalue, and so on.\\n2 Big data models and technologies\\nClassical relational models and SQL technologies do notappropriately cater for the needs of big data due to its dis-\\ntinguishing characteristics as illustrated above. Thus, storing\\nand processing of big data require new data models and newtechnologies. The most commonly used data models for big\\n123106 Service Oriented Computing and Applications (2019) 13:105–107\\nFig. 1 Big data characteristics and applications\\nFig. 2 Big data models and technologies\\ndata are document model; key-value model; column model;\\nand graph model.\\nBig data is commonly stored and processed using cloud-\\nbased NoSQL systems such as Riak, MongoDB, Google\\nCloud Big Table, and Amazon DynamoDB. As shown inFig. 2[1], CouchDB, MongoDB, and Azure Cosmos DB\\ngenerally follow the document model. Key-value model\\nis followed by NoSQL databases such as Riak, Amazon\\nDynamoDB, and Cassandra. Column model is implementedin MariaDB, Apache HBASE, and Google Cloud Big Table.\\nGraph-based models are adopted in Neo4j, TITAN, and Ori-\\nentDB. Note that this is rather a broad classiﬁcation and someof these NoSQL systems may belong to different (or multi-\\nple) data models.\\n3 Big data challenges\\nFrom the above discussion, it is observed that big data is char-\\nacterised by new characteristics, new data models, and newdatabase technologies. All such new developments have been\\ngreatly beneﬁting companies and organisations in variousdimensions such as time and cost saving, intelligent deci-\\nsion making, effective product design and development, and\\nhelping in customer relationships, to name but a few. Despitesigniﬁcant developments in big data systems, various chal-lenges are still open for further research. For instance, past\\nliterature has identiﬁed various challenges related to big data\\n[3]. This editorial provides a brief description of some of the\\ncrucial research challenges of big data.\\n\\x81NoSQL databases are predominantly used to store and pro-\\ncess big data. Such databases provide key beneﬁts such asefﬁciency, scalability, and availability in storing and pro-\\ncessing big data. However, they do not provide appropriate\\nsupport for transactions, data normalisation, and integrityconstraints which affect the consistency of big data [ 4,5].\\nThus, the current models and techniques implemented in\\nNoSQL databases should be re-examined so that they canbe used in applications/services that demand strong data\\nconsistency in addition to high efﬁciency, scalability, and\\navailability.\\n\\x81A number of NoSQL databases have been designed and\\ndeveloped. Different NoSQL systems are implemented\\nusing different big data models and technologies. They also\\nprovide varying level of QoS with respect to performance,availability, and scalability. This makes the selection of a\\nNoSQL database difﬁcult—i.e. which NoSQL system is\\nchosen for a particular use or application of a big data.This requires the design and development of a new bench-\\nmark which users/developers can use to select appropriate\\nNoSQL database that effectively meets their needs.\\n\\x81Data as a Service (DaaS) has emerged as a new plat-\\nform in order to facilitate the provisioning of data over the\\nInternet and cloud. DaaS is generally based on web ser-\\nvices and service-oriented computing (SOC) technologies.DaaS aims to consolidate and organise data in a centralised\\nplace in order to enable location transparency as well as\\nsharing of data across different systems and services. How-ever, existing models and architectures of web services\\nand SOC may fall short of meeting the requirements of\\nDaaS provisioning over the Internet and cloud. Thus, newmodels, methods, and architectures should be developedin order to further materialise the beneﬁts of DaaS.\\n\\x81Internet of Things (IoT) is one of the major platforms\\n(and a source) for big data given that millions of thingsor devices are generating and consuming a large volume\\nof big data. However, resource scarcity is one of the major\\nissues associated with the IoT devices as they do not havethe capabilities of collecting, storing, analysing, and shar-\\ning big data in (real) time. Thus, new solutions are required\\nto be developed in order to effectively conjoin IoT and bigdata.\\n123Service Oriented Computing and Applications (2019) 13:105–107 107\\nReferences\\n1. Y ounas M (2018) Transactional services for NoSQL big data\\nsystems. In: Keynote talk at the 6th international conference on mul-timedia computing and systems (ICMCS 2018), Rabat, Morocco,10–12 May 2018\\n2. Nguyen TL (2018) A framework for ﬁve big v’s of big data and\\norganizational culture in ﬁrms. In: Proceedings of the IEEE interna-tional conference on big data (Big Data 2018), Seattle, W A, USA,10–13 Dec 2018\\n3. Jin X, Wah BW, Cheng X, Wang Y (2015) Signiﬁcance and chal-\\nlenges of big data research. Int J Big Data Res 2:59–644. González-Aparicio MT, Y ounas M, Tuya J, Casado R (2018) Testing\\nof transactional services in NoSQL key-value databases. Int J FutureGener Comput Syst 80:384–399\\n5. Padhye V , Tripathi A (2015) Scalable transaction management with\\nsnapshot isolation for NoSQL data storage systems. IEEE TransServ Comput 8:121–135\\nPublisher’s Note Springer Nature remains neutral with regard to juris-\\ndictional claims in published maps and institutional afﬁliations.\\n123'}]\n"
     ]
    }
   ],
   "source": [
    "print(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to crawled_data.json\n"
     ]
    }
   ],
   "source": [
    "output_file = \"crawled_data.json\"  # Replace with your desired output path\n",
    "save_crawled_data_to_json(pdf_documents, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
